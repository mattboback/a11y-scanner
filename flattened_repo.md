# Repository: a11y_scanner_v1
Generated: 2025-10-31 00:51:32 | Files: 475 | Size: 16.77 MB

_428 file(s) omitted from content section; see tree for details._

## Tree
```
.
├── data/
│   ├── reports/
│   │   ├── Charitize_20251029_171326.html (omitted)
│   │   ├── Flat_20251029_171334.html (omitted)
│   │   └── latest.html (omitted)
│   ├── results/
│   │   ├── play-tailwind-1.0.0_404.html.json (omitted)
│   │   ├── play-tailwind-1.0.0_about.html.json (omitted)
│   │   ├── play-tailwind-1.0.0_blog-details.html.json (omitted)
│   │   ├── play-tailwind-1.0.0_blog-grids.html.json (omitted)
│   │   ├── play-tailwind-1.0.0_contact.html.json (omitted)
│   │   ├── play-tailwind-1.0.0_index.html.json (omitted)
│   │   ├── play-tailwind-1.0.0_pricing.html.json (omitted)
│   │   ├── play-tailwind-1.0.0_signin.html.json (omitted)
│   │   ├── play-tailwind-1.0.0_signup.html.json (omitted)
│   │   ├── violation-color-contrast-8f547102-4458-4034-bf84-204c9299871f.png (omitted)
│   │   ├── violation-color-contrast-90258bf0-0b0b-41bb-a824-d12de21e9440.png (omitted)
│   │   ├── violation-color-contrast-9ddc1748-8090-4e40-ab0f-313f289be323.png (omitted)
│   │   ├── violation-color-contrast-b2d03782-47d1-426d-8098-6e3beab15e50.png (omitted)
│   │   ├── violation-color-contrast-b5fd5fa0-6fe0-4314-9744-35d5d400599a.png (omitted)
│   │   ├── violation-heading-order-16760585-8af8-4665-99ab-1c4a28fefa32.png (omitted)
│   │   ├── violation-heading-order-6d8db64e-2698-4413-8015-6439196c8f0c.png (omitted)
│   │   ├── violation-heading-order-8d5e0571-43ae-4aa3-add3-b01e97585973.png (omitted)
│   │   ├── violation-heading-order-94ac5e15-5df3-4f3c-b6b8-27036e1d1822.png (omitted)
│   │   ├── violation-heading-order-b00d5b64-fc8b-4b2d-b6af-d0c69be65bd7.png (omitted)
│   │   ├── violation-heading-order-d817203f-1a12-42a8-8408-78f83467946e.png (omitted)
│   │   ├── violation-heading-order-ffb1948e-ba17-4036-817f-aaf4094842ad.png (omitted)
│   │   ├── violation-landmark-one-main-10404aaf-96fb-41d3-9c44-431841dfc0ad.png (omitted)
│   │   ├── violation-landmark-one-main-3d03ed08-b3d8-4779-a825-d46a414883d3.png (omitted)
│   │   ├── violation-landmark-one-main-4a540338-afe6-4d49-a205-2e1ececa6be7.png (omitted)
│   │   ├── violation-landmark-one-main-50307501-36de-40c3-bb1f-aba62bc305e8.png (omitted)
│   │   ├── violation-landmark-one-main-50aef5b5-fe48-4e0b-893b-63185160da4d.png (omitted)
│   │   ├── violation-landmark-one-main-5c91375d-e505-4547-b24f-e81af5f81a3d.png (omitted)
│   │   ├── violation-landmark-one-main-8e48dded-3e8d-464b-bca7-c31455956c27.png (omitted)
│   │   ├── violation-landmark-one-main-d5df063c-72ac-4e5a-a4cb-755170e8ab4c.png (omitted)
│   │   ├── violation-landmark-one-main-d9f5d467-da44-4c53-8331-2e02b96efbc1.png (omitted)
│   │   ├── violation-landmark-one-main-eb679de7-a7ad-439c-b043-422fa32e0d90.png (omitted)
│   │   ├── violation-landmark-one-main-ef8593ea-3f3a-4057-a1ac-f204c9bd38c5.png (omitted)
│   │   ├── violation-landmark-one-main-f8211f32-e425-4e2c-866a-1bae436a3293.png (omitted)
│   │   ├── violation-link-name-4b46f1f5-35ed-4754-aa12-45f45b577c7c.png (omitted)
│   │   ├── violation-link-name-4f756432-cbe5-4810-90de-450046cfbcbf.png (omitted)
│   │   ├── violation-link-name-6cf29a44-c738-42f9-ac81-07d85353b216.png (omitted)
│   │   ├── violation-link-name-b5f1aff3-3623-434a-8d5e-f8da4587761b.png (omitted)
│   │   ├── violation-link-name-def6666b-2072-40d1-8734-699587384a00.png (omitted)
│   │   ├── violation-region-2173d242-47f3-4fa9-af11-2a64efef5c00.png (omitted)
│   │   ├── violation-region-31a2fd71-e885-439d-89b4-af53747735ae.png (omitted)
│   │   ├── violation-region-794f3776-d2ac-457e-b409-352a097f256a.png (omitted)
│   │   ├── violation-region-95029645-d52a-4564-8886-e85ec01ed13b.png (omitted)
│   │   ├── violation-region-a692976d-05bd-40ad-b9d4-1bcffe444b4e.png (omitted)
│   │   ├── violation-region-b6b32f25-cc6f-4909-9123-57bc7697c9e9.png (omitted)
│   │   ├── violation-region-ccfe0d76-ebcf-4047-90d0-588ddc67f2b1.png (omitted)
│   │   ├── violation-region-d0e5b327-fe43-42d8-a05c-53d7153b2fd1.png (omitted)
│   │   ├── violation-region-e5b85761-bf60-4532-8c4e-694f3bd318c5.png (omitted)
│   │   ├── violation-region-f4254845-bd9b-42e0-983e-9c861106f742.png (omitted)
│   │   ├── violation-region-f48eae7a-7bf2-46fb-8877-ad575e0b2025.png (omitted)
│   │   └── violation-region-f521b09a-546c-4ca4-b092-29f50b8a3b62.png (omitted)
│   ├── scan/
│   │   └── play-tailwind-1.0.0/
│   │       ├── assets/
│   │       │   ├── css/
│   │       │   │   ├── animate.css (omitted)
│   │       │   │   └── swiper-bundle.min.css (omitted)
│   │       │   ├── images/
│   │       │   │   ├── about/
│   │       │   │   │   ├── about-image-01.jpg (omitted)
│   │       │   │   │   └── about-image-02.jpg (omitted)
│   │       │   │   ├── blog/
│   │       │   │   │   ├── article-author-01.png (omitted)
│   │       │   │   │   ├── article-author-02.png (omitted)
│   │       │   │   │   ├── article-author-03.png (omitted)
│   │       │   │   │   ├── article-author-04.png (omitted)
│   │       │   │   │   ├── author-01.png (omitted)
│   │       │   │   │   ├── bannder-ad.png (omitted)
│   │       │   │   │   ├── blog-01.jpg (omitted)
│   │       │   │   │   ├── blog-02.jpg (omitted)
│   │       │   │   │   ├── blog-03.jpg (omitted)
│   │       │   │   │   ├── blog-details-01.jpg (omitted)
│   │       │   │   │   ├── blog-footer-01.jpg (omitted)
│   │       │   │   │   ├── blog-footer-02.jpg (omitted)
│   │       │   │   │   ├── dotted-shape.svg (omitted)
│   │       │   │   │   └── quote-bg.svg (omitted)
│   │       │   │   ├── brands/
│   │       │   │   │   ├── ayroui-white.svg (omitted)
│   │       │   │   │   ├── ayroui.svg (omitted)
│   │       │   │   │   ├── graygrids-white.svg (omitted)
│   │       │   │   │   ├── graygrids.svg (omitted)
│   │       │   │   │   ├── lineicons-white.svg (omitted)
│   │       │   │   │   ├── lineicons.svg (omitted)
│   │       │   │   │   ├── tailgrids-white.svg (omitted)
│   │       │   │   │   ├── tailgrids.svg (omitted)
│   │       │   │   │   ├── uideck-white.svg (omitted)
│   │       │   │   │   └── uideck.svg (omitted)
│   │       │   │   ├── footer/
│   │       │   │   │   ├── shape-1.svg (omitted)
│   │       │   │   │   └── shape-3.svg (omitted)
│   │       │   │   ├── hero/
│   │       │   │   │   ├── brand.svg (omitted)
│   │       │   │   │   └── hero-image.jpg (omitted)
│   │       │   │   ├── logo/
│   │       │   │   │   ├── favicon.svg (omitted)
│   │       │   │   │   ├── logo-white.svg (omitted)
│   │       │   │   │   └── logo.svg (omitted)
│   │       │   │   ├── team/
│   │       │   │   │   ├── dotted-shape.svg (omitted)
│   │       │   │   │   ├── shape-2.svg (omitted)
│   │       │   │   │   ├── team-01.png (omitted)
│   │       │   │   │   ├── team-02.png (omitted)
│   │       │   │   │   ├── team-03.png (omitted)
│   │       │   │   │   └── team-04.png (omitted)
│   │       │   │   ├── testimonials/
│   │       │   │   │   ├── author-01.jpg (omitted)
│   │       │   │   │   ├── author-02.jpg (omitted)
│   │       │   │   │   ├── author-03.jpg (omitted)
│   │       │   │   │   └── icon-star.svg (omitted)
│   │       │   │   ├── 404.svg (omitted)
│   │       │   │   └── favicon.png (omitted)
│   │       │   └── js/
│   │       │       ├── main.js (omitted)
│   │       │       ├── swiper-bundle.min.js (omitted)
│   │       │       └── wow.min.js (omitted)
│   │       ├── src/
│   │       │   ├── css/
│   │       │   │   └── tailwind.css (omitted)
│   │       │   └── input.css (omitted)
│   │       ├── 404.html (omitted)
│   │       ├── about.html (omitted)
│   │       ├── blog-details.html (omitted)
│   │       ├── blog-grids.html (omitted)
│   │       ├── contact.html (omitted)
│   │       ├── index.html (omitted)
│   │       ├── LICENSE (omitted)
│   │       ├── package-lock.json (omitted)
│   │       ├── package.json (omitted)
│   │       ├── pricing.html (omitted)
│   │       ├── README.md (omitted)
│   │       ├── signin.html (omitted)
│   │       └── signup.html (omitted)
│   └── site_tmp/
│       ├── about.html (omitted)
│       └── index.html (omitted)
├── docker/
│   ├── Dockerfile (omitted)
│   └── Dockerfile.test (omitted)
├── docs/
│   ├── architecture-overview.md (omitted)
│   ├── architecture.md (omitted)
│   └── development-guide.md (omitted)
├── examples/
│   ├── ci-github-actions.yml (omitted)
│   ├── docker-compose.yml (omitted)
│   └── nginx.conf (omitted)
├── scripts/
│   ├── complete_setup.sh
│   ├── create_test_site.sh
│   ├── e2e_test_audit.py
│   ├── run_golden_tests.py
│   └── test_in_docker.sh
├── src/
│   ├── a11y_scanner.egg-info/
│   │   ├── dependency_links.txt
│   │   ├── entry_points.txt
│   │   ├── PKG-INFO
│   │   ├── requires.txt
│   │   ├── SOURCES.txt
│   │   └── top_level.txt
│   └── scanner/
│       ├── container/
│       │   ├── __init__.py
│       │   ├── integration.py
│       │   ├── manager.py
│       │   └── runner.py
│       ├── core/
│       │   ├── __init__.py
│       │   ├── logging_setup.py
│       │   └── settings.py
│       ├── reporting/
│       │   ├── __init__.py
│       │   └── jinja_report.py
│       ├── services/
│       │   ├── __init__.py
│       │   ├── html_discovery_service.py
│       │   ├── http_service.py
│       │   ├── playwright_axe_service.py
│       │   └── zip_service.py
│       ├── templates/
│       │   ├── __init__.py
│       │   └── a11y_report.html.j2
│       ├── utils/
│       │   ├── __init__.py
│       │   └── json_utils.py
│       ├── web/
│       │   ├── __init__.py
│       │   └── server.py
│       ├── __init__.py
│       ├── main.py
│       └── pipeline.py
├── test_data/
│   ├── reports/
│   │   └── test_report.html (omitted)
│   └── results/
│       ├── sample1.json (omitted)
│       ├── sample2.json (omitted)
│       ├── sample3.json (omitted)
│       ├── violation-color-contrast-87654321-4321-8765-4321-876543218765.png (omitted)
│       ├── violation-image-alt-11111111-1111-1111-1111-111111111111.png (omitted)
│       └── violation-image-alt-12345678-1234-5678-1234-567812345678.png (omitted)
├── tests/
│   ├── assets/
│   │   └── html_sets/
│   │       ├── 1/
│   │       │   ├── golden_results/
│   │       │   │   └── report.json (omitted)
│   │       │   ├── about.html (omitted)
│   │       │   ├── cart.js (omitted)
│   │       │   ├── component.css (omitted)
│   │       │   ├── index.html (omitted)
│   │       │   ├── layout.css (omitted)
│   │       │   ├── script.js (omitted)
│   │       │   ├── style.css (omitted)
│   │       │   └── utils.js (omitted)
│   │       ├── 2/
│   │       │   ├── golden_results/
│   │       │   │   └── report.json (omitted)
│   │       │   ├── nest/
│   │       │   │   ├── ll.htm (omitted)
│   │       │   │   ├── ll.html (omitted)
│   │       │   │   └── tl.htm (omitted)
│   │       │   ├── hehe.htm (omitted)
│   │       │   ├── lol.html (omitted)
│   │       │   ├── sss.ht (omitted)
│   │       │   └── test.html (omitted)
│   │       ├── 3/
│   │       │   ├── golden_results/
│   │       │   │   └── report.json (omitted)
│   │       │   ├── mor_test.html (omitted)
│   │       │   └── test.html (omitted)
│   │       ├── 4/
│   │       │   ├── golden_results/
│   │       │   │   └── report.json (omitted)
│   │       │   ├── index.html (omitted)
│   │       │   └── style.css (omitted)
│   │       ├── 5/
│   │       │   ├── golden_results/
│   │       │   │   └── report.json (omitted)
│   │       │   ├── about.html (omitted)
│   │       │   ├── contact.html (omitted)
│   │       │   ├── index.html (omitted)
│   │       │   ├── product-detail.html (omitted)
│   │       │   ├── products.html (omitted)
│   │       │   └── style.css (omitted)
│   │       ├── 6/
│   │       │   ├── golden_results/
│   │       │   │   └── report.json (omitted)
│   │       │   ├── blog.html (omitted)
│   │       │   ├── contact.html (omitted)
│   │       │   ├── features.html (omitted)
│   │       │   ├── index.html (omitted)
│   │       │   ├── pricing.html (omitted)
│   │       │   ├── script.js (omitted)
│   │       │   └── style.css (omitted)
│   │       ├── 7/
│   │       │   ├── golden_results/
│   │       │   │   └── report.json (omitted)
│   │       │   ├── src/
│   │       │   │   ├── assets/
│   │       │   │   │   └── stellaris-logo.svg (omitted)
│   │       │   │   ├── js/
│   │       │   │   │   ├── animation.js (omitted)
│   │       │   │   │   ├── main.js (omitted)
│   │       │   │   │   └── ui.js (omitted)
│   │       │   │   └── styles/
│   │       │   │       ├── compiled/
│   │       │   │       │   └── style.css (omitted)
│   │       │   │       ├── _base.scss (omitted)
│   │       │   │       ├── _components.scss (omitted)
│   │       │   │       ├── _variables.scss (omitted)
│   │       │   │       └── main.scss (omitted)
│   │       │   ├── about.html (omitted)
│   │       │   ├── index.html (omitted)
│   │       │   └── package.json (omitted)
│   │       ├── Charitize/
│   │       │   ├── Charitize-1.0.0/
│   │       │   │   ├── css/
│   │       │   │   │   ├── bootstrap.min.css (omitted)
│   │       │   │   │   └── style.css (omitted)
│   │       │   │   ├── img/
│   │       │   │   │   ├── about.jpg (omitted)
│   │       │   │   │   ├── bg-footer.jpg (omitted)
│   │       │   │   │   ├── bg.jpg (omitted)
│   │       │   │   │   ├── carousel-1.jpg (omitted)
│   │       │   │   │   ├── carousel-2.jpg (omitted)
│   │       │   │   │   ├── donation-1.jpg (omitted)
│   │       │   │   │   ├── donation-2.jpg (omitted)
│   │       │   │   │   ├── donation-3.jpg (omitted)
│   │       │   │   │   ├── event-1.jpg (omitted)
│   │       │   │   │   ├── event-2.jpg (omitted)
│   │       │   │   │   ├── event-3.jpg (omitted)
│   │       │   │   │   ├── gallery-1.jpg (omitted)
│   │       │   │   │   ├── gallery-2.jpg (omitted)
│   │       │   │   │   ├── gallery-3.jpg (omitted)
│   │       │   │   │   ├── gallery-4.jpg (omitted)
│   │       │   │   │   ├── gallery-5.jpg (omitted)
│   │       │   │   │   ├── gallery-6.jpg (omitted)
│   │       │   │   │   ├── team-1.jpg (omitted)
│   │       │   │   │   ├── team-2.jpg (omitted)
│   │       │   │   │   ├── team-3.jpg (omitted)
│   │       │   │   │   ├── testimonial-1.jpg (omitted)
│   │       │   │   │   ├── testimonial-2.jpg (omitted)
│   │       │   │   │   └── testimonial-3.jpg (omitted)
│   │       │   │   ├── js/
│   │       │   │   │   └── main.js (omitted)
│   │       │   │   ├── lib/
│   │       │   │   │   ├── animate/
│   │       │   │   │   │   ├── animate.css (omitted)
│   │       │   │   │   │   └── animate.min.css (omitted)
│   │       │   │   │   ├── counterup/
│   │       │   │   │   │   └── counterup.min.js (omitted)
│   │       │   │   │   ├── easing/
│   │       │   │   │   │   ├── easing.js (omitted)
│   │       │   │   │   │   └── easing.min.js (omitted)
│   │       │   │   │   ├── owlcarousel/
│   │       │   │   │   │   ├── assets/
│   │       │   │   │   │   │   ├── ajax-loader.gif (omitted)
│   │       │   │   │   │   │   ├── owl.carousel.css (omitted)
│   │       │   │   │   │   │   ├── owl.carousel.min.css (omitted)
│   │       │   │   │   │   │   ├── owl.theme.default.css (omitted)
│   │       │   │   │   │   │   ├── owl.theme.default.min.css (omitted)
│   │       │   │   │   │   │   ├── owl.theme.green.css (omitted)
│   │       │   │   │   │   │   ├── owl.theme.green.min.css (omitted)
│   │       │   │   │   │   │   └── owl.video.play.png (omitted)
│   │       │   │   │   │   ├── LICENSE (omitted)
│   │       │   │   │   │   ├── owl.carousel.js (omitted)
│   │       │   │   │   │   └── owl.carousel.min.js (omitted)
│   │       │   │   │   ├── waypoints/
│   │       │   │   │   │   ├── links.php (omitted)
│   │       │   │   │   │   └── waypoints.min.js (omitted)
│   │       │   │   │   └── wow/
│   │       │   │   │       ├── wow.js (omitted)
│   │       │   │   │       └── wow.min.js (omitted)
│   │       │   │   ├── scss/
│   │       │   │   │   ├── bootstrap/
│   │       │   │   │   │   └── scss/
│   │       │   │   │   │       ├── forms/
│   │       │   │   │   │       │   ├── _floating-labels.scss (omitted)
│   │       │   │   │   │       │   ├── _form-check.scss (omitted)
│   │       │   │   │   │       │   ├── _form-control.scss (omitted)
│   │       │   │   │   │       │   ├── _form-range.scss (omitted)
│   │       │   │   │   │       │   ├── _form-select.scss (omitted)
│   │       │   │   │   │       │   ├── _form-text.scss (omitted)
│   │       │   │   │   │       │   ├── _input-group.scss (omitted)
│   │       │   │   │   │       │   ├── _labels.scss (omitted)
│   │       │   │   │   │       │   └── _validation.scss (omitted)
│   │       │   │   │   │       ├── helpers/
│   │       │   │   │   │       │   ├── _clearfix.scss (omitted)
│   │       │   │   │   │       │   ├── _colored-links.scss (omitted)
│   │       │   │   │   │       │   ├── _position.scss (omitted)
│   │       │   │   │   │       │   ├── _ratio.scss (omitted)
│   │       │   │   │   │       │   ├── _stretched-link.scss (omitted)
│   │       │   │   │   │       │   ├── _text-truncation.scss (omitted)
│   │       │   │   │   │       │   └── _visually-hidden.scss (omitted)
│   │       │   │   │   │       ├── mixins/
│   │       │   │   │   │       │   ├── _alert.scss (omitted)
│   │       │   │   │   │       │   ├── _border-radius.scss (omitted)
│   │       │   │   │   │       │   ├── _box-shadow.scss (omitted)
│   │       │   │   │   │       │   ├── _breakpoints.scss (omitted)
│   │       │   │   │   │       │   ├── _buttons.scss (omitted)
│   │       │   │   │   │       │   ├── _caret.scss (omitted)
│   │       │   │   │   │       │   ├── _clearfix.scss (omitted)
│   │       │   │   │   │       │   ├── _color-scheme.scss (omitted)
│   │       │   │   │   │       │   ├── _container.scss (omitted)
│   │       │   │   │   │       │   ├── _deprecate.scss (omitted)
│   │       │   │   │   │       │   ├── _forms.scss (omitted)
│   │       │   │   │   │       │   ├── _gradients.scss (omitted)
│   │       │   │   │   │       │   ├── _grid.scss (omitted)
│   │       │   │   │   │       │   ├── _image.scss (omitted)
│   │       │   │   │   │       │   ├── _list-group.scss (omitted)
│   │       │   │   │   │       │   ├── _lists.scss (omitted)
│   │       │   │   │   │       │   ├── _pagination.scss (omitted)
│   │       │   │   │   │       │   ├── _reset-text.scss (omitted)
│   │       │   │   │   │       │   ├── _resize.scss (omitted)
│   │       │   │   │   │       │   ├── _table-variants.scss (omitted)
│   │       │   │   │   │       │   ├── _text-truncate.scss (omitted)
│   │       │   │   │   │       │   ├── _transition.scss (omitted)
│   │       │   │   │   │       │   ├── _utilities.scss (omitted)
│   │       │   │   │   │       │   └── _visually-hidden.scss (omitted)
│   │       │   │   │   │       ├── utilities/
│   │       │   │   │   │       │   └── _api.scss (omitted)
│   │       │   │   │   │       ├── _accordion.scss (omitted)
│   │       │   │   │   │       ├── _alert.scss (omitted)
│   │       │   │   │   │       ├── _badge.scss (omitted)
│   │       │   │   │   │       ├── _breadcrumb.scss (omitted)
│   │       │   │   │   │       ├── _button-group.scss (omitted)
│   │       │   │   │   │       ├── _buttons.scss (omitted)
│   │       │   │   │   │       ├── _card.scss (omitted)
│   │       │   │   │   │       ├── _carousel.scss (omitted)
│   │       │   │   │   │       ├── _close.scss (omitted)
│   │       │   │   │   │       ├── _containers.scss (omitted)
│   │       │   │   │   │       ├── _dropdown.scss (omitted)
│   │       │   │   │   │       ├── _forms.scss (omitted)
│   │       │   │   │   │       ├── _functions.scss (omitted)
│   │       │   │   │   │       ├── _grid.scss (omitted)
│   │       │   │   │   │       ├── _helpers.scss (omitted)
│   │       │   │   │   │       ├── _images.scss (omitted)
│   │       │   │   │   │       ├── _list-group.scss (omitted)
│   │       │   │   │   │       ├── _mixins.scss (omitted)
│   │       │   │   │   │       ├── _modal.scss (omitted)
│   │       │   │   │   │       ├── _nav.scss (omitted)
│   │       │   │   │   │       ├── _navbar.scss (omitted)
│   │       │   │   │   │       ├── _offcanvas.scss (omitted)
│   │       │   │   │   │       ├── _pagination.scss (omitted)
│   │       │   │   │   │       ├── _popover.scss (omitted)
│   │       │   │   │   │       ├── _progress.scss (omitted)
│   │       │   │   │   │       ├── _reboot.scss (omitted)
│   │       │   │   │   │       ├── _root.scss (omitted)
│   │       │   │   │   │       ├── _spinners.scss (omitted)
│   │       │   │   │   │       ├── _tables.scss (omitted)
│   │       │   │   │   │       ├── _toasts.scss (omitted)
│   │       │   │   │   │       ├── _tooltip.scss (omitted)
│   │       │   │   │   │       ├── _transitions.scss (omitted)
│   │       │   │   │   │       ├── _type.scss (omitted)
│   │       │   │   │   │       ├── _utilities.scss (omitted)
│   │       │   │   │   │       ├── _variables.scss (omitted)
│   │       │   │   │   │       ├── bootstrap-grid.scss (omitted)
│   │       │   │   │   │       ├── bootstrap-reboot.scss (omitted)
│   │       │   │   │   │       ├── bootstrap-utilities.scss (omitted)
│   │       │   │   │   │       └── bootstrap.scss (omitted)
│   │       │   │   │   └── bootstrap.scss (omitted)
│   │       │   │   ├── 404.html (omitted)
│   │       │   │   ├── about.html (omitted)
│   │       │   │   ├── charity-organization-website-template.jpg (omitted)
│   │       │   │   ├── contact.html (omitted)
│   │       │   │   ├── donation.html (omitted)
│   │       │   │   ├── event.html (omitted)
│   │       │   │   ├── feature.html (omitted)
│   │       │   │   ├── index.html (omitted)
│   │       │   │   ├── LICENSE.txt (omitted)
│   │       │   │   ├── READ-ME.txt (omitted)
│   │       │   │   ├── service.html (omitted)
│   │       │   │   ├── team.html (omitted)
│   │       │   │   └── testimonial.html (omitted)
│   │       │   └── golden_results/
│   │       │       └── report.json (omitted)
│   │       ├── Flat/
│   │       │   ├── Flat-1.0.0/
│   │       │   │   ├── assets/
│   │       │   │   │   ├── css/
│   │       │   │   │   │   ├── animate.css (omitted)
│   │       │   │   │   │   ├── bootstrap-5.0.0-alpha-2.min.css (omitted)
│   │       │   │   │   │   ├── lindy-uikit.css (omitted)
│   │       │   │   │   │   └── LineIcons.2.0.css (omitted)
│   │       │   │   │   ├── fonts/
│   │       │   │   │   │   ├── LineIcons.eot (omitted)
│   │       │   │   │   │   ├── LineIcons.svg (omitted)
│   │       │   │   │   │   ├── LineIcons.ttf (omitted)
│   │       │   │   │   │   ├── LineIcons.woff (omitted)
│   │       │   │   │   │   └── LineIcons.woff2 (omitted)
│   │       │   │   │   ├── img/
│   │       │   │   │   │   ├── about/
│   │       │   │   │   │   │   └── about-3/
│   │       │   │   │   │   │       └── about-img.jpg (omitted)
│   │       │   │   │   │   ├── clients/
│   │       │   │   │   │   │   └── brands.svg (omitted)
│   │       │   │   │   │   ├── feature/
│   │       │   │   │   │   │   └── feature-2-1.svg (omitted)
│   │       │   │   │   │   ├── hero/
│   │       │   │   │   │   │   └── hero-2/
│   │       │   │   │   │   │       ├── hero-img.svg (omitted)
│   │       │   │   │   │   │       └── paattern.svg (omitted)
│   │       │   │   │   │   ├── logo/
│   │       │   │   │   │   │   └── logo.svg (omitted)
│   │       │   │   │   │   ├── pricing/
│   │       │   │   │   │   │   └── pricing-1/
│   │       │   │   │   │   │       ├── pricing-1.svg (omitted)
│   │       │   │   │   │   │       ├── pricing-2.svg (omitted)
│   │       │   │   │   │   │       └── pricing-3.svg (omitted)
│   │       │   │   │   │   └── team/
│   │       │   │   │   │       └── team-1/
│   │       │   │   │   │           ├── team-1.png (omitted)
│   │       │   │   │   │           ├── team-2.png (omitted)
│   │       │   │   │   │           ├── team-3.png (omitted)
│   │       │   │   │   │           └── team-4.png (omitted)
│   │       │   │   │   └── js/
│   │       │   │   │       ├── bootstrap.5.0.0.alpha-2-min.js (omitted)
│   │       │   │   │       ├── count-up.min.js (omitted)
│   │       │   │   │       ├── main.js (omitted)
│   │       │   │   │       └── wow.min.js (omitted)
│   │       │   │   ├── index.html (omitted)
│   │       │   │   └── license.txt (omitted)
│   │       │   └── golden_results/
│   │       │       └── report.json (omitted)
│   │       └── play-tailwind/
│   │           └── play-tailwind-1.0.0/
│   │               ├── assets/
│   │               │   ├── css/
│   │               │   │   ├── animate.css (omitted)
│   │               │   │   └── swiper-bundle.min.css (omitted)
│   │               │   ├── images/
│   │               │   │   ├── about/
│   │               │   │   │   ├── about-image-01.jpg (omitted)
│   │               │   │   │   └── about-image-02.jpg (omitted)
│   │               │   │   ├── blog/
│   │               │   │   │   ├── article-author-01.png (omitted)
│   │               │   │   │   ├── article-author-02.png (omitted)
│   │               │   │   │   ├── article-author-03.png (omitted)
│   │               │   │   │   ├── article-author-04.png (omitted)
│   │               │   │   │   ├── author-01.png (omitted)
│   │               │   │   │   ├── bannder-ad.png (omitted)
│   │               │   │   │   ├── blog-01.jpg (omitted)
│   │               │   │   │   ├── blog-02.jpg (omitted)
│   │               │   │   │   ├── blog-03.jpg (omitted)
│   │               │   │   │   ├── blog-details-01.jpg (omitted)
│   │               │   │   │   ├── blog-footer-01.jpg (omitted)
│   │               │   │   │   ├── blog-footer-02.jpg (omitted)
│   │               │   │   │   ├── dotted-shape.svg (omitted)
│   │               │   │   │   └── quote-bg.svg (omitted)
│   │               │   │   ├── brands/
│   │               │   │   │   ├── ayroui-white.svg (omitted)
│   │               │   │   │   ├── ayroui.svg (omitted)
│   │               │   │   │   ├── graygrids-white.svg (omitted)
│   │               │   │   │   ├── graygrids.svg (omitted)
│   │               │   │   │   ├── lineicons-white.svg (omitted)
│   │               │   │   │   ├── lineicons.svg (omitted)
│   │               │   │   │   ├── tailgrids-white.svg (omitted)
│   │               │   │   │   ├── tailgrids.svg (omitted)
│   │               │   │   │   ├── uideck-white.svg (omitted)
│   │               │   │   │   └── uideck.svg (omitted)
│   │               │   │   ├── footer/
│   │               │   │   │   ├── shape-1.svg (omitted)
│   │               │   │   │   └── shape-3.svg (omitted)
│   │               │   │   ├── hero/
│   │               │   │   │   ├── brand.svg (omitted)
│   │               │   │   │   └── hero-image.jpg (omitted)
│   │               │   │   ├── logo/
│   │               │   │   │   ├── favicon.svg (omitted)
│   │               │   │   │   ├── logo-white.svg (omitted)
│   │               │   │   │   └── logo.svg (omitted)
│   │               │   │   ├── team/
│   │               │   │   │   ├── dotted-shape.svg (omitted)
│   │               │   │   │   ├── shape-2.svg (omitted)
│   │               │   │   │   ├── team-01.png (omitted)
│   │               │   │   │   ├── team-02.png (omitted)
│   │               │   │   │   ├── team-03.png (omitted)
│   │               │   │   │   └── team-04.png (omitted)
│   │               │   │   ├── testimonials/
│   │               │   │   │   ├── author-01.jpg (omitted)
│   │               │   │   │   ├── author-02.jpg (omitted)
│   │               │   │   │   ├── author-03.jpg (omitted)
│   │               │   │   │   └── icon-star.svg (omitted)
│   │               │   │   ├── 404.svg (omitted)
│   │               │   │   └── favicon.png (omitted)
│   │               │   └── js/
│   │               │       ├── main.js (omitted)
│   │               │       ├── swiper-bundle.min.js (omitted)
│   │               │       └── wow.min.js (omitted)
│   │               ├── src/
│   │               │   ├── css/
│   │               │   │   └── tailwind.css (omitted)
│   │               │   └── input.css (omitted)
│   │               ├── 404.html (omitted)
│   │               ├── about.html (omitted)
│   │               ├── blog-details.html (omitted)
│   │               ├── blog-grids.html (omitted)
│   │               ├── contact.html (omitted)
│   │               ├── index.html (omitted)
│   │               ├── LICENSE (omitted)
│   │               ├── package-lock.json (omitted)
│   │               ├── package.json (omitted)
│   │               ├── pricing.html (omitted)
│   │               ├── README.md (omitted)
│   │               ├── signin.html (omitted)
│   │               └── signup.html (omitted)
│   ├── services/
│   │   └── test_playwright_axe_service.py
│   ├── test_api.py
│   ├── test_html_discovery_service.py
│   ├── test_http_service.py
│   ├── test_pipeline.py
│   ├── test_reporting.py
│   ├── test_settings.py
│   └── test_zip_service.py
├── CHANGELOG.md (omitted)
├── CODE_OF_CONDUCT.md (omitted)
├── CONTRIBUTING.md (omitted)
├── docker-compose.yml
├── LICENSE (omitted)
├── Makefile
├── pyproject.toml (omitted)
├── QUICKSTART.md
├── README.md
├── scan_live_site.py
├── SECURITY.md (omitted)
└── uv.lock (omitted)
```

## Files

### Root (./)

<FILE path="docker-compose.yml">

```yaml
services:
  scanner:
    build:
      context: .
      dockerfile: docker/Dockerfile
    volumes:
      - ./data:/home/pwuser/data
    shm_size: "2gb"

  scanner-debug:
    build:
      context: .
      dockerfile: docker/Dockerfile
    volumes:
      - ./data:/home/pwuser/data
    shm_size: "2gb"
    entrypoint: ["tail", "-f", "/dev/null"]
```

</FILE>

---

<FILE path="Makefile">

```makefile
# Makefile — uv + Docker workflow
.PHONY: help install docker-prepare scan-local integration live-scan clean serve test test-unit test-integration test-coverage golden-generate golden-test golden-compare

help:
	@echo "Targets:"
	@echo "  install         Install project dependencies with uv"
	@echo "  docker-prepare  Build/rebuild the cached Docker image"
	@echo "  scan-local      Package sample site and run scanner in Docker"
	@echo "  integration     Run integration suite in Docker"
	@echo "  live-scan       Run scan_live_site.py in Docker (uses container entrypoint)"
	@echo "  serve           Run the long-lived FastAPI server in Docker (port 8008)"
	@echo "  test            Run all tests in Docker (recommended)"
	@echo "  test-unit       Run unit tests only in Docker"
	@echo "  test-integration Run integration tests only in Docker"
	@echo "  test-coverage   Run tests with coverage report in Docker"
	@echo "  golden-generate Generate/update golden test files from test ZIPs"
	@echo "  golden-test     Run regression tests against golden files"
	@echo "  golden-compare  Compare current results with golden files only"
	@echo "  clean           Remove data artifacts"

install:
	@echo "Installing dependencies with uv..."
	uv sync --all-extras

docker-prepare: install
	uv run python -m scanner.container.runner prepare

scan-local: install
	./scripts/create_test_site.sh
	uv run python -m scanner.container.runner run

integration: install
	uv run python -m scanner.container.integration

# Note: live-scan uses the same container entrypoint (scanner.main).
# To run scan_live_site.py specifically inside the container, you can
# temporarily switch the container ENTRYPOINT, or keep scan_live_site
# as a separate command you exec inside. For simplicity we keep main.
live-scan: install
	@echo "Running main pipeline (see scan_live_site.py for a live variant)"
	uv run python -m scanner.container.runner run

serve: install
	@echo "Starting FastAPI server at http://127.0.0.1:8008 (Ctrl+C to stop)"
	uv run python -m scanner.container.runner serve --port 8008

# Test targets (Docker-based, recommended)
test:
	@echo "Running all tests in Docker..."
	./scripts/test_in_docker.sh all

test-unit:
	@echo "Running unit tests in Docker..."
	./scripts/test_in_docker.sh unit

test-integration:
	@echo "Running integration tests in Docker..."
	./scripts/test_in_docker.sh integration

test-coverage:
	@echo "Running tests with coverage in Docker..."
	./scripts/test_in_docker.sh coverage

golden-generate: install
	@echo "Generating golden test files from test ZIPs..."
	uv run python scripts/run_golden_tests.py --generate

golden-test: install
	@echo "Running regression tests against golden files..."
	uv run python scripts/run_golden_tests.py

golden-compare: install
	@echo "Comparing results with golden files (scan only)..."
	uv run python scripts/run_golden_tests.py --compare-only

clean:
	rm -rf data/scan data/results data/unzip data/live_results data/reports
	mkdir -p data/unzip data/results data/scan data/live_results data/reports
```

</FILE>

---

<FILE path="QUICKSTART.md">

```markdown
# A11y Scanner - Quick Start Guide

## Installation

```bash
# Clone the repo
git clone https://github.com/mattboback/a11y-scanner.git
cd a11y-scanner

# Install dependencies
make install

# Build Docker image
make docker-prepare
```

## Scanning Your Site

### Option 1: Scan Static Site (ZIP file)

1. **Prepare your site** - Create a ZIP file of your HTML files:
   ```bash
   # Put your HTML files in a folder, then zip it
   zip -r my-site.zip my-site/
   ```

2. **Place the ZIP in the input directory**:
   ```bash
   cp my-site.zip data/unzip/site.zip
   ```

3. **Run the scan**:
   ```bash
   make scan-local
   ```

4. **View results**:
   - Open `data/reports/latest.html` in your browser
   - Screenshots and violations are in `data/results/`

### Option 2: Scan Live Website

```bash
# Set environment variables
export A11Y_BASE_URL="https://example.com"
export A11Y_PAGES="/,/about,/contact,/services"

# Run scan
make live-scan
```

Results go to `data/live_results/`

### Option 3: API Server (Programmatic)

```bash
# Start the server (runs in Docker)
make serve

# Upload a ZIP to scan
curl -X POST http://localhost:8008/api/scan/zip \
  -F "file=@my-site.zip"

# View results at
# http://localhost:8008/reports/latest.html
```

## Output Structure

```
data/
├── reports/
│   └── latest.html          ← Open this in your browser
├── results/
│   ├── page1.html.json      ← Raw JSON report
│   ├── page2.html.json
│   ├── violation-*.png      ← Screenshots of violations
│   └── ...
├── unzip/                   ← Your input ZIP goes here
└── scan/                    ← Extracted HTML files
```

## Understanding the Report

**Summary Section:**
- Pages Scanned: Number of HTML files found
- Total Violations: Count of all accessibility issues
- Raw Artifacts: Links to JSON reports

**Violations by Rule:**
- **Critical** (red) - Must fix (WCAG Level A)
- **Serious** (orange) - Should fix (WCAG Level AA)
- **Moderate** (gold) - Nice to fix (best practices)
- **Minor** (yellow) - Low impact items

Each violation shows:
- **Page**: Which file the issue is in
- **Selector**: CSS selector to find the element
- **HTML Snippet**: The problematic code
- **Visual Reference**: Screenshot highlighting the issue

## Docker Requirements

- Docker or Podman installed
- ~2GB RAM
- ~2GB disk space

## Common Issues

**"Must run inside container"**
- API endpoints only work via Docker. Use `make serve` instead of direct curl.

**Missing images in report**
- Screenshots are generated automatically. If missing, check `data/results/` directory.

**Port already in use**
- Edit Makefile or use: `make serve PORT=8080`

## Next Steps

- Fix violations based on the report
- Re-run scans to verify fixes
- Integrate into CI/CD pipeline
- Check axe-core docs via "Documentation →" link in report

---

For detailed documentation, see [README.md](README.md)
```

</FILE>

---

<FILE path="README.md">

```markdown
# a11y-scanner

> A containerized web accessibility scanner using Playwright and axe-core for comprehensive WCAG compliance testing.

[![CI Status](https://github.com/mattboback/a11y-scanner/actions/workflows/ci.yml/badge.svg)](https://github.com/mattboback/a11y-scanner/actions)
[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)

---

## What is a11y-scanner?

**a11y-scanner** is a Python-based accessibility testing tool that automates WCAG compliance checks for web applications. It combines the power of [axe-core](https://github.com/dequelabs/axe-core) (the industry-leading accessibility rules engine) with [Playwright](https://playwright.dev/) (modern browser automation) to provide:

- 🔍 **Comprehensive scanning** of static sites, multi-page applications, and single pages
- 📊 **Rich HTML reports** with violation screenshots and remediation guidance
- 🐳 **Docker-first architecture** for consistent, reproducible results
- 🔌 **REST API** for integration into CI/CD pipelines
- 🔒 **Security-hardened** with Zip Slip protection, SSRF prevention, and input validation

Perfect for developers, QA teams, and accessibility specialists who need automated a11y testing in their workflows.

---

## ✨ Features

### Core Capabilities

- **Multi-format Input**: Scan from ZIP archives, local directories, or live URLs
- **Browser-based Testing**: Real browser rendering via Playwright (Chromium/Firefox/WebKit)
- **axe-core Integration**: Industry-standard WCAG 2.1 Level A/AA rule engine
- **Visual Evidence**: Automatic screenshots of violating elements with red highlighting
- **JSON + HTML Reports**: Machine-readable data and human-friendly visualizations
- **Browser Reuse**: Context manager pattern for 40-80% faster multi-page scans

### Security Features

- **Zip Slip Protection** (CWE-22): Path traversal validation prevents malicious archives
- **SSRF Prevention**: Blocks localhost and private IP ranges in URL scanning
- **Input Validation**: File size limits (100MB), MIME type checking, extension validation
- **Container Isolation**: Read-only source mounts, controlled data volumes
- **Optional API Authentication**: Token-based auth via `A11Y_API_TOKEN` environment variable

### Developer Experience

- **Three Run Modes**: CLI, API server, or Docker container orchestration
- **CI/CD Ready**: GitHub Actions examples, exit codes for violation detection
- **Flexible Configuration**: Environment variables for screenshots, paths, tokens
- **Detailed Logging**: Structured logs with configurable verbosity
- **Type Hinted**: Full type annotations for better IDE support

---

## 🚀 Quick Start

### Prerequisites

- Python 3.10+ ([download](https://www.python.org/downloads/))
- Docker 20.10+ or Podman 3.4+ ([get Docker](https://docs.docker.com/get-docker/))
- 2GB RAM minimum, 4GB recommended

### Installation

```bash
# Clone the repository
git clone https://github.com/mattboback/a11y-scanner.git
cd a11y-scanner

# Create virtual environment
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate

# Install with development dependencies
pip install -e ".[dev]"

# Prepare Docker image (one-time, ~2-5 minutes)
python -m scanner.container.runner prepare
```

### Run Your First Scan

```bash
# Create a sample HTML file
mkdir -p data/unzip
cat > data/unzip/index.html << 'EOF'
<!DOCTYPE html>
<html lang="en">
<head><title>Test Page</title></head>
<body>
    <h1>Sample Page</h1>
    <img src="photo.jpg">  <!-- Missing alt text - violation! -->
    <button>Click</button>
</body>
</html>
EOF

# Package as ZIP
cd data/unzip && zip -r ../site.zip . && cd ../..

# Run the scan
python -m scanner.container.runner run

# View the report
open data/reports/latest.html  # macOS
# Or: xdg-open data/reports/latest.html  # Linux
# Or: start data/reports/latest.html     # Windows
```

You should see a violation report for the missing `alt` attribute! 🎉

---

## 📖 Usage

### Mode 1: CLI (Scan ZIP Files)

The primary mode for scanning packaged sites:

```bash
# Scan a ZIP file
python -m scanner.container.runner run

# Custom paths
python -m scanner.container.runner run \
    --zip-path /path/to/site.zip \
    --output-dir /path/to/results

# Disable screenshots for faster scans
A11Y_NO_SCREENSHOTS=1 python -m scanner.container.runner run
```

**Expected output:**
```
✓ Docker image ready
✓ Scanning site.zip...
✓ Found 3 pages
✓ Scanned 3 pages
⚠ Found 12 violations
✓ Report: data/reports/latest.html
```

### Mode 2: API Server

Long-running service for programmatic access:

```bash
# Start the API server (runs on port 8008)
python -m scanner.container.runner serve

# In another terminal, scan via API
curl -X POST http://localhost:8008/api/scan/zip \
    -H "Content-Type: multipart/form-data" \
    -F "file=@data/unzip/site.zip"

# Response:
# {
#   "status": "success",
#   "pages_scanned": 3,
#   "total_violations": 12,
#   "report_path": "data/reports/latest.html",
#   "results_dir": "data/results"
# }
```

**With authentication:**
```bash
# Generate a secure token
export A11Y_API_TOKEN=$(openssl rand -base64 32)

# Start server with auth
python -m scanner.container.runner serve

# Use token in requests
curl -X POST http://localhost:8008/api/scan/zip \
    -H "X-API-Key: $A11Y_API_TOKEN" \
    -F "file=@site.zip"
```

### Mode 3: Scan Live URLs

Scan a running website:

```bash
# Single URL
python scan_live_site.py https://example.com

# Multiple pages (coming soon)
# python scan_live_site.py https://example.com/page1 https://example.com/page2
```

---

## 🖥️ Platform Support

| Platform | Support Status | Notes |
|----------|----------------|-------|
| **Linux** | ✅ Fully Supported | Ubuntu 20.04+, Debian 11+, Fedora 35+ |
| **macOS** | ✅ Fully Supported | macOS 11+ (Intel & Apple Silicon) |
| **Windows** | ⚠️ Supported via WSL2 | Native Windows support planned |
| **Docker** | ✅ Recommended | Docker 20.10+ or Podman 3.4+ |

### System Requirements

- **RAM**: 2GB minimum, 4GB recommended
- **Disk**: 2GB for Docker images + scan artifacts
- **CPU**: 2 cores minimum (parallel scanning planned for v1.1)
- **Network**: Internet access for Docker image pull (one-time setup)

---

## 🌍 Real-World Examples

### CI/CD Integration (GitHub Actions)

Automatically scan on every push:

```yaml
# .github/workflows/accessibility.yml
name: Accessibility Audit

on:
  push:
    branches: [main]
  pull_request:

jobs:
  a11y-scan:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install scanner
        run: |
          pip install -e .
          python -m scanner.container.runner prepare

      - name: Build and package site
        run: |
          npm ci && npm run build
          mkdir -p data/unzip
          cd dist && zip -r ../data/unzip/site.zip .

      - name: Run accessibility scan
        run: python -m scanner.container.runner run

      - name: Upload report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: accessibility-report
          path: data/reports/latest.html

      - name: Fail on violations
        run: |
          count=$(jq -s 'map(.violations | length) | add' data/results/*.json)
          if [ "$count" -gt 0 ]; then
            echo "::error::Found $count accessibility violations"
            exit 1
          fi
```

### Docker Compose for Teams

Shared accessibility scanner service:

```yaml
# docker-compose.yml
version: '3.8'

services:
  a11y-scanner:
    image: mattboback/a11y-scanner:latest
    container_name: team-a11y-scanner
    ports:
      - "8008:8008"
    volumes:
      - ./scans:/worksrc/data
    environment:
      - A11Y_API_TOKEN=${SCANNER_API_TOKEN}
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8008/healthz"]
      interval: 30s
      timeout: 10s
      retries: 3

# Usage:
# 1. export SCANNER_API_TOKEN=$(openssl rand -base64 32)
# 2. docker-compose up -d
# 3. curl -H "X-API-Key: $SCANNER_API_TOKEN" \
#        -F "file=@site.zip" \
#        http://localhost:8008/api/scan/zip
```

### Scheduled Weekly Audits

Monitor production site automatically:

```yaml
# .github/workflows/weekly-audit.yml
name: Weekly A11y Audit

on:
  schedule:
    - cron: '0 9 * * 1'  # Every Monday at 9 AM

jobs:
  scan-production:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Install and scan
        run: |
          pip install -e .
          python -m scanner.container.runner prepare
          python scan_live_site.py https://yoursite.com

      - name: Create issue if violations found
        if: failure()
        uses: actions/github-script@v7
        with:
          script: |
            github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: '🚨 Weekly A11y Scan Found Violations',
              body: 'Check the workflow artifacts for the full report.',
              labels: ['accessibility', 'automated']
            })
```

---

## ⚡ Performance Benchmarks

Real-world scanning performance on a 4-core, 16GB RAM development machine:

| Site Size | Pages | Violations | Scan Time | Memory |
|-----------|-------|------------|-----------|---------|
| Small | 10 | 45 | ~15s | 400MB |
| Medium | 50 | 200 | ~1m 30s | 600MB |
| Large | 200 | 800 | ~6m | 1.2GB |

### Optimization Tips

- **Browser Reuse**: 40-80% faster on multi-page sites (automatically enabled in pipeline)
- **Disable Screenshots**: Set `A11Y_NO_SCREENSHOTS=1` for 2x faster scans
- **Parallel Scanning**: Coming in v1.1 with `--workers 4` flag

---

## 🛠️ Troubleshooting

### Docker Permission Issues

**Problem:** `docker: Got permission denied while trying to connect to the Docker daemon`

**Solution (Linux):**
```bash
sudo usermod -aG docker $USER
newgrp docker  # Or log out and back in
```

### Podman Socket Not Found

**Problem:** `Cannot connect to Podman socket`

**Solution:**
```bash
systemctl --user start podman.socket
systemctl --user enable podman.socket
podman version  # Verify
```

### Port Already in Use

**Problem:** `Address already in use: 8008`

**Solution:**
```bash
# Use different port
python -m scanner.container.runner serve --port 8009

# Or find and kill process
lsof -ti:8008 | xargs kill -9  # macOS/Linux
```

### Slow First Build

**Problem:** Docker image build takes 5+ minutes

**Expected:** This is normal for the first build. Subsequent builds use cache and complete in seconds. Run `python -m scanner.container.runner prepare` once during setup.

### Screenshots Not Capturing

**Problem:** Violation screenshots are missing or blank

**Common Causes:**
1. JavaScript-heavy pages (already using `networkidle` wait)
2. CSP violations (check browser console with `--verbose`)
3. Memory limits (increase Docker memory: `shm_size: "2gb"`)

**Workaround:** Disable screenshots if not needed:
```bash
export A11Y_NO_SCREENSHOTS=1
python -m scanner.container.runner run
```

### Windows-Specific Issues

**Problem:** Path errors on Windows

**Solution:** Use WSL2 (Windows Subsystem for Linux):
```powershell
wsl --install  # Install WSL2
# Inside WSL2:
cd /path/to/a11y-scanner
python -m venv .venv
source .venv/bin/activate
pip install -e ".[dev]"
```

### Getting Help

1. **Check existing issues**: [GitHub Issues](https://github.com/mattboback/a11y-scanner/issues)
2. **Ask in discussions**: [GitHub Discussions](https://github.com/mattboback/a11y-scanner/discussions)
3. **Review documentation**: See [`docs/`](docs/) folder
4. **Enable debug logging**:
   ```python
   from scanner.core.logging_setup import setup_logging
   import logging
   setup_logging(level=logging.DEBUG)
   ```

---

## ❓ FAQ

**Q: How does this compare to browser extensions like axe DevTools?**

A: Browser extensions are great for manual testing, but a11y-scanner is designed for automation:
- ✅ Runs in CI/CD without manual intervention
- ✅ Scans entire sites in batch
- ✅ Self-hosted for security/compliance
- ✅ Integrates into development workflows

**Q: Does this replace manual accessibility testing?**

A: **No.** Automated tools catch ~30-40% of accessibility issues. You still need:
- Manual keyboard navigation testing
- Screen reader testing (NVDA, JAWS, VoiceOver)
- User testing with people with disabilities

**Q: Can I scan sites behind authentication?**

A: Not directly yet. Current workarounds:
1. Export static HTML after authentication
2. Use a browser extension to save authenticated pages
3. Contribute authentication support (see [Contributing](#-contributing))

**Q: Is this WCAG 2.1 AA compliant?**

A: a11y-scanner **tests for** WCAG violations using axe-core, which covers many WCAG 2.1 Level A and AA criteria. It's a tool to help **achieve** compliance, not a certification.

**Q: Can I customize the rules?**

A: Currently uses axe-core's default ruleset. Custom rules are planned for v1.2. You can disable specific rules by forking and modifying the axe configuration in `src/scanner/services/playwright_axe_service.py`.

**Q: Why Docker? Can I run without it?**

A: Docker ensures consistent browser environments across platforms:
- ✅ No Playwright dependency version mismatches
- ✅ Reproducible results in CI/CD
- ✅ Works the same on Linux, macOS, Windows (via WSL2)

You *can* run Playwright natively for development, but Docker is recommended for production/CI use.

**Q: How much does this cost?**

A: a11y-scanner is **free and open source** (MIT license). You only pay for:
- Infrastructure (servers, CI minutes if using cloud providers)
- Optional: Commercial support (not yet available)

**Q: Can I contribute?**

A: **Yes!** See [CONTRIBUTING.md](CONTRIBUTING.md). We welcome:
- 🐛 Bug reports and fixes
- ✨ Feature requests and implementations
- 📝 Documentation improvements
- 💡 Use cases and examples

---

## 🤝 Contributing

We love contributions! See [CONTRIBUTING.md](CONTRIBUTING.md) for:
- Development setup
- Code style guidelines (Black, Ruff)
- Testing requirements (pytest, coverage)
- Commit conventions (Conventional Commits)
- PR process

**Quick start for contributors:**
```bash
git clone https://github.com/mattboback/a11y-scanner.git
cd a11y-scanner
python -m venv .venv && source .venv/bin/activate
pip install -e ".[dev]"
pytest  # Run tests
black . # Format code
ruff check .  # Lint
```

---

## 📄 License

This project is licensed under the **MIT License** - see [LICENSE](LICENSE) for details.

---

## 🌟 Acknowledgments

- **[axe-core](https://github.com/dequelabs/axe-core)** by Deque Systems - Industry-leading accessibility rules engine
- **[Playwright](https://playwright.dev/)** by Microsoft - Modern browser automation
- **[axe-playwright-python](https://github.com/abhinaba-ghosh/axe-playwright-python)** - Python bindings for axe in Playwright

---

## 📞 Contact & Support

- **GitHub**: [@mattboback](https://github.com/mattboback)
- **Issues**: [Report a bug](https://github.com/mattboback/a11y-scanner/issues)
- **Discussions**: [Ask questions](https://github.com/mattboback/a11y-scanner/discussions)
- **Security**: matthewboback@gmail.com (for security vulnerabilities only)
- **Website**: [matthewboback.com](https://matthewboback.com)

---

**⭐ Star this repo** to stay updated on new releases and features!

Made with ❤️ by [Matthew Boback](https://matthewboback.com)
```

</FILE>

---

<FILE path="scan_live_site.py">

```python
import logging
import os
import sys

from scanner.core.logging_setup import setup_logging
from scanner.core.settings import Settings
from scanner.reporting.jinja_report import build_report
from scanner.services.playwright_axe_service import PlaywrightAxeService

IN_CONTAINER_ENV = "A11Y_SCANNER_IN_CONTAINER"
IN_CONTAINER_VALUE = "1"

# Configure target via environment to avoid hardcoding third-party sites.
# e.g. A11Y_BASE_URL="https://example.com" A11Y_PAGES="/,/about,/contact"
BASE_URL = os.environ.get("A11Y_BASE_URL", "").strip()
PAGES_TO_SCAN = [
    p.strip() for p in os.environ.get("A11Y_PAGES", "/").split(",") if p.strip()
]

log = logging.getLogger(__name__)


def _assert_docker_context() -> None:
    if os.environ.get(IN_CONTAINER_ENV) != IN_CONTAINER_VALUE:
        print(
            "\n[ERROR] This CLI is Docker-only.\nRun via the container runner instead:\n"
            "  python -m scanner.container.runner prepare\n"
            "  python -m scanner.container.runner run\n",
            file=sys.stderr,
        )
        sys.exit(2)


def create_safe_filename(base_url: str, page_path: str) -> str:
    domain = base_url.replace("https://", "").replace("http://", "")
    path_part = "root" if page_path == "/" else page_path.strip("/").replace("/", "_")
    return f"{domain}_{path_part}.json"


def main():
    _assert_docker_context()
    setup_logging(level=logging.INFO)

    if not BASE_URL:
        log.error(
            "BASE_URL is not set. Set A11Y_BASE_URL environment variable (e.g. https://example.com)."
        )
        sys.exit(2)

    log.info("--- Starting Live A11y Site Scanner ---")
    log.info("Target site: %s", BASE_URL)

    settings = Settings()
    live_results_dir = settings.data_dir / "live_results"
    live_results_dir.mkdir(parents=True, exist_ok=True)
    log.info("Results will be saved in: %s", live_results_dir.resolve())
    reports_dir = settings.data_dir / "reports"
    reports_dir.mkdir(parents=True, exist_ok=True)

    total_violations_count = 0
    try:
        with PlaywrightAxeService() as axe_service:
            for page_path in PAGES_TO_SCAN:
                url_to_scan = f"{BASE_URL}{page_path}"
                report_filename = create_safe_filename(BASE_URL, page_path)
                report_path = live_results_dir / report_filename
                log.info("--- Scanning page: %s ---", url_to_scan)
                try:
                    violations = axe_service.scan_url(url_to_scan, report_path)
                    if violations:
                        log.warning(
                            "Found %d violation(s) on %s", len(violations), url_to_scan
                        )
                        total_violations_count += len(violations)
                    else:
                        log.info("✅ No violations found on %s", url_to_scan)
                except Exception as e:
                    log.error("Failed to scan %s: %s", url_to_scan, e, exc_info=True)
                    continue

        output_html = reports_dir / "latest.html"
        build_report(
            live_results_dir, output_html, title="Accessibility Report (Live Site)"
        )
        log.info("Consolidated HTML report generated at: %s", output_html)
        log.info("--- Live Scan Finished ---")

        pages_count = len(PAGES_TO_SCAN)
        if total_violations_count > 0:
            print("\n--- Accessibility Scan Summary ---")
            print(
                f"Found a total of {total_violations_count} accessibility violation(s)."
            )
            print(f"Scanned {pages_count} page(s).")
            print(f"Detailed JSON reports: {live_results_dir.resolve()}")
            print(f"HTML report available at: {output_html}")
        else:
            print(
                "\n✅ Excellent! No accessibility violations were found on the scanned pages."
            )
            print(f"Full report available at: {output_html}")
        sys.exit(0)
    except Exception:
        log.exception("An unexpected error occurred during the live scan.")
        sys.exit(1)


if __name__ == "__main__":
    main()
```

</FILE>

---

### Entering Directory: 'scripts/'

<FILE path="scripts/complete_setup.sh">

```bash
#!/usr/bin/env bash
# complete_setup.sh - Full project setup and validation

set -e

echo "🚀 a11y-scanner Setup Script"
echo "=============================="
echo ""

# 1. Check Python version
echo "1️⃣  Checking Python version..."
if ! command -v python3.11 &> /dev/null; then
    echo "❌ Python 3.11 not found. Install with: sudo pacman -S python311"
    exit 1
fi
echo "✓ Python 3.11 found"

# 2. Create virtual environment
echo ""
echo "2️⃣  Creating virtual environment..."
if [ -d ".venv" ]; then
    echo "  Removing existing .venv..."
    rm -rf .venv
fi
python3.11 -m venv .venv
source .venv/bin/activate
echo "✓ Virtual environment created"

# 3. Install dependencies
echo ""
echo "3️⃣  Installing dependencies..."
pip install --upgrade pip > /dev/null
pip install -e ".[dev]"
echo "✓ Dependencies installed"

# 4. Create missing scripts
echo ""
echo "4️⃣  Creating missing scripts..."
if [ ! -f "scripts/create_test_site.sh" ]; then
    cat > scripts/create_test_site.sh <<'SCRIPT'
#!/usr/bin/env bash
set -e
PROJECT_ROOT="$(cd "$(dirname "${BASH_SOURCE[0]}")/.." && pwd)"
DATA_DIR="$PROJECT_ROOT/data"
UNZIP_DIR="$DATA_DIR/unzip"
SITE_DIR="$DATA_DIR/site_tmp"
mkdir -p "$UNZIP_DIR" "$SITE_DIR"
cat > "$SITE_DIR/index.html" <<'EOF'
<!doctype html>
<html lang="en">
<head><meta charset="utf-8"><title>Test</title></head>
<body><h1>Test</h1><img src="logo.png"><p>Content</p></body>
</html>
EOF
cd "$SITE_DIR"
zip -r "$UNZIP_DIR/site.zip" . -q
echo "✓ Created: $UNZIP_DIR/site.zip"
SCRIPT
    chmod +x scripts/create_test_site.sh
    echo "✓ Created scripts/create_test_site.sh"
else
    echo "✓ scripts/create_test_site.sh already exists"
fi

# 5. Fix linting issues
echo ""
echo "5️⃣  Fixing code style..."
black src tests > /dev/null 2>&1
ruff check src tests --fix --quiet || true
echo "✓ Code formatted"

# 6. Run tests
echo ""
echo "6️⃣  Running tests..."
pytest -q -k "not test_playwright_axe_service"
echo "✓ Tests passed"

echo ""
echo "✅ Setup complete!"
echo ""
echo "Next steps:"
echo "  1. Run: ./update_user_info.sh"
echo "  2. Review and commit changes"
echo "  3. Test Docker: python -m scanner.container.runner prepare"
```

</FILE>

---

<FILE path="scripts/create_test_site.sh">

```bash
#!/usr/bin/env bash
# Script to create a sample test site for scanning

set -e

PROJECT_ROOT="$(cd "$(dirname "${BASH_SOURCE[0]}")/.." && pwd)"
DATA_DIR="$PROJECT_ROOT/data"
UNZIP_DIR="$DATA_DIR/unzip"
SITE_DIR="$DATA_DIR/site_tmp"

echo "Creating test site..."

# Create directories
mkdir -p "$UNZIP_DIR"
mkdir -p "$SITE_DIR"

# Create sample HTML with accessibility issues
cat > "$SITE_DIR/index.html" <<'EOF'
<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <title>Sample Test Site</title>
  <style>
    .low-contrast { color: #999; background: #f0f0f0; }
  </style>
</head>
<body>
  <h1>Sample Page</h1>
  <img src="logo.png">
  <p class="low-contrast">Low contrast text</p>
  <button>Click me</button>
</body>
</html>
EOF

cat > "$SITE_DIR/about.html" <<'EOF'
<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <title>About Page</title>
</head>
<body>
  <h1>About</h1>
  <img src="team.jpg">
  <p>Information about us</p>
</body>
</html>
EOF

# Create ZIP file
cd "$SITE_DIR"
zip -r "$UNZIP_DIR/site.zip" . -q

echo "✓ Created: $UNZIP_DIR/site.zip"
echo "✓ Test site ready for scanning"
```

</FILE>

---

<FILE path="scripts/e2e_test_audit.py">

```python
#!/usr/bin/env python3
"""
E2E Test & Report Audit Script for a11y-scanner.

- Runs scanner on each test set in tests/assets/html_sets/N
- Zips site files, scans, generates report
- Compares aggregate JSON to golden files
- Audits HTML report: structure, content, screenshots, self-a11y

Requires: pip install -e ".[dev,test]" (includes beautifulsoup4, lxml)
Assumes: Docker running, golden files up-to-date.
"""

import argparse
import json
import logging
import subprocess
import subprocess as sp  # For jq fallback check
import sys
from difflib import unified_diff
from pathlib import Path
from zipfile import ZIP_DEFLATED, ZipFile

# External deps for auditing
from bs4 import BeautifulSoup

# Import your project modules
from scanner.container.integration import (
    _clean_data_dirs,
    _slurp_raw_reports,
    _unified_diff_str,
    find_project_root,
)
from scanner.container.manager import ContainerManager
from scanner.core.logging_setup import setup_logging
from scanner.reporting.jinja_report import build_report

# Setup logging (reuse your setup)
setup_logging(level=logging.INFO)
logger = logging.getLogger(__name__)

# Constants
TESTS_DIR = Path(__file__).parent.parent / "tests/assets/html_sets"
DATA_DIR = Path(__file__).parent.parent / "data"
GOLDEN_SUFFIX = "golden_results/report.json"
REPORT_PATH = DATA_DIR / "reports/latest.html"
ZIP_PATH = DATA_DIR / "unzip/site.zip"
RESULTS_DIR = DATA_DIR / "results"


def has_jq() -> bool:
    """Check if jq is available for JSON diffing."""
    try:
        sp.run(["jq", "--version"], check=True, capture_output=True)
        return True
    except (subprocess.CalledProcessError, FileNotFoundError):
        logger.warning(
            "jq not found; using Python difflib for JSON comparison (slower but functional)"
        )
        return False


def zip_test_set(test_dir: Path, zip_path: Path) -> None:
    """Create ZIP from test set files (exclude golden_results)."""
    zip_path.parent.mkdir(parents=True, exist_ok=True)
    with ZipFile(zip_path, "w", ZIP_DEFLATED) as zf:
        for p in test_dir.rglob("*"):
            if "golden_results" in p.parts:
                continue
            if p.is_file():
                arcname = p.relative_to(test_dir)
                zf.write(p, arcname)
                logger.debug(f"Zipped: {arcname}")
    logger.info(
        f"ZIP created: {zip_path} ({len([p for p in test_dir.rglob('*') if p.is_file() and 'golden_results' not in p.parts])} files)"
    )


def run_scanner() -> int:
    """Run the scanner via container runner."""
    logger.info("Running scanner: python -m scanner.container.runner run")
    try:
        result = subprocess.run(
            [sys.executable, "-m", "scanner.container.runner", "run"],
            cwd=Path(__file__).parent.parent,
            capture_output=True,
            text=True,
            check=True,
        )
        logger.info(f"Scanner output: {result.stdout}")
        return 0
    except subprocess.CalledProcessError as e:
        logger.error(f"Scanner failed: {e.stderr}")
        return e.returncode


def aggregate_and_compare_results(test_name: str, golden_path: Path) -> bool:
    """Aggregate JSON results and compare to golden."""
    actual_list = _slurp_raw_reports(RESULTS_DIR)
    actual_str = json.dumps(actual_list, indent=2, sort_keys=True)

    try:
        with open(golden_path, encoding="utf-8") as f:
            golden_str = f.read()
    except FileNotFoundError:
        logger.error(f"Golden file missing: {golden_path}")
        return False

    if actual_str.strip() == golden_str.strip():
        logger.info(f"JSON Comparison for {test_name}: PASS")
        return True

    # Diff
    if has_jq():
        # Use jq for pretty diff (optional)
        diff_cmd = ["jq", "-S", "."]  # Sort keys for diff
        actual_sorted = sp.run(
            diff_cmd + [str(RESULTS_DIR / "*.json")],
            capture_output=True,
            text=True,
            cwd=Path(__file__).parent.parent,
        ).stdout
        golden_sorted = sp.run(
            ["jq", "-S", "."], input=golden_str, capture_output=True, text=True
        ).stdout
        diff = "\n".join(
            unified_diff(
                golden_sorted.splitlines(),
                actual_sorted.splitlines(),
                fromfile="golden",
                tofile="actual",
            )
        )
    else:
        diff = _unified_diff_str(golden_str, actual_str, "golden", "actual")

    logger.error(f"JSON Mismatch for {test_name}:\n{diff}")
    return False


def count_violations_by_impact(results_dir: Path) -> dict[str, int]:
    """Count violations by impact from JSON files."""
    counts = {"critical": 0, "serious": 0, "moderate": 0, "minor": 0, "unknown": 0}
    pages_scanned = 0
    total_violations = 0
    screenshot_count = 0

    for json_file in results_dir.glob("*.json"):
        try:
            with open(json_file) as f:
                data = json.load(f)
            pages_scanned += 1
            for v in data.get("violations", []):
                impact = v.get("impact", "unknown").lower()
                counts[impact] = counts.get(impact, 0) + 1
                total_violations += 1
                if v.get("screenshot_path"):
                    screenshot_count += 1
        except Exception as e:
            logger.warning(f"Skipping invalid JSON {json_file}: {e}")

    logger.info(
        f"Stats: Pages={pages_scanned}, Total Violations={total_violations}, Screenshots={screenshot_count}"
    )
    logger.info(f"By Impact: {counts}")
    return {
        "pages_scanned": pages_scanned,
        "total_violations": total_violations,
        "screenshots": screenshot_count,
        "by_impact": counts,
    }


def audit_report(report_path: Path, expected_stats: dict) -> bool:
    """Audit the generated HTML report."""
    if not report_path.exists():
        logger.error("Report not generated!")
        return False

    with open(report_path, encoding="utf-8") as f:
        soup = BeautifulSoup(f.read(), "lxml")

    audit_issues = []
    score = 100  # Start perfect, deduct for issues

    # 1. Basic Structure
    title = soup.find("title")
    if not title or "Accessibility Report" not in title.text:
        audit_issues.append("Invalid/missing title")
        score -= 10

    generated_at = soup.find("time", {"datetime": True})
    if not generated_at:
        audit_issues.append("Missing generated_at timestamp")
        score -= 5

    # 2. Stats Match JSON
    pages_elem = soup.find("span", {"id": "pages-scanned"})
    violations_elem = soup.find("span", {"id": "total-violations"})
    if pages_elem:
        try:
            parsed_pages = int(pages_elem.text.strip())
            if parsed_pages != expected_stats["pages_scanned"]:
                audit_issues.append(
                    f"Pages mismatch: report={parsed_pages}, expected={expected_stats['pages_scanned']}"
                )
                score -= 10
        except ValueError:
            audit_issues.append("Invalid pages count in report")
            score -= 5

    if violations_elem:
        try:
            parsed_violations = int(violations_elem.text.strip())
            if parsed_violations != expected_stats["total_violations"]:
                audit_issues.append(
                    f"Violations mismatch: report={parsed_violations}, expected={expected_stats['total_violations']}"
                )
                score -= 10
        except ValueError:
            audit_issues.append("Invalid violations count in report")
            score -= 5

    # 3. Rule Groups & Impacts
    rule_groups = soup.find_all("div", {"class": lambda x: x and "rule-group" in x})
    if expected_stats["total_violations"] > 0:
        if len(rule_groups) == 0:
            audit_issues.append("No rule groups found (expected violations)")
            score -= 20
        else:
            impacts_in_report = {}
            for group in rule_groups:
                impact_class = group.get("class")
                impact = next(
                    (
                        c.replace("impact-", "")
                        for c in impact_class
                        if c.startswith("impact-")
                    ),
                    "unknown",
                )
                count_elem = group.find("span", {"class": "violation-count"})
                count = int(count_elem.text.strip()) if count_elem else 0
                impacts_in_report[impact] = impacts_in_report.get(impact, 0) + count
            # Loose match (allow for grouping diffs)
            for impact, exp_count in expected_stats["by_impact"].items():
                rep_count = impacts_in_report.get(impact, 0)
                if abs(rep_count - exp_count) > 1:  # Tolerance for minor diffs
                    audit_issues.append(
                        f"Impact {impact} mismatch: report={rep_count}, expected={exp_count}"
                    )
                    score -= 5
    else:
        no_violations = soup.find("div", {"id": "no-violations"})
        if not no_violations:
            audit_issues.append("No 'no violations' message in empty report")
            score -= 10

    # 4. Screenshots
    img_tags = soup.find_all("img", {"src": lambda x: x and x.endswith(".png")})
    linked_screenshots = len(img_tags)
    if linked_screenshots != expected_stats["screenshots"]:
        audit_issues.append(
            f"Screenshot count mismatch: report={linked_screenshots}, expected={expected_stats['screenshots']}"
        )
        score -= 10

    # Verify screenshot files exist and are linked correctly (relative paths)
    base_dir = report_path.parent
    for img in img_tags:
        src = img.get("src")
        if src:
            full_path = (base_dir / ".." / src).resolve()  # Relative to results/
            if not full_path.exists():
                audit_issues.append(f"Missing screenshot file: {full_path}")
                score -= 5
            # Basic a11y: Alt text?
            if not img.get("alt"):
                audit_issues.append(f"Missing alt text on screenshot: {src}")
                score -= 2

    # 5. Self-A11y Audit of Report (Basic)
    headings = soup.find_all(["h1", "h2", "h3"])
    if len(headings) < 3:  # Expect at least summary, rules, etc.
        audit_issues.append("Insufficient headings for structure")
        score -= 5
    links = soup.find_all("a", href=True)
    broken_links = [
        link
        for link in links
        if link["href"].startswith("http") and "dequeuniversity" not in link["href"]
    ]  # Spot-check WCAG links
    if broken_links:
        audit_issues.append(f"Potential broken links: {len(broken_links)}")
        score -= 5

    # Output
    logger.info(f"Report Audit for {report_path.name}: Score={score}%")
    if audit_issues:
        logger.error(f"Audit Issues: {audit_issues}")
        return False
    logger.info("Report Audit: PASS")
    return True


def run_single_test(test_dir: Path) -> bool:
    """Run e2e for one test set."""
    test_name = test_dir.name
    logger.info(f"--- E2E Test & Audit: Test Set {test_name} ---")

    # Clean & Prep
    _clean_data_dirs(DATA_DIR)
    project_root = find_project_root()
    manager = ContainerManager(project_root=project_root)
    manager.ensure_image()  # Build if needed

    # ZIP
    zip_test_set(test_dir, ZIP_PATH)

    # Scan
    exit_code = run_scanner()
    if exit_code != 0:
        logger.error(f"Scanner failed for {test_name}: Exit {exit_code}")
        return False

    # Generate Report
    try:
        build_report(RESULTS_DIR, REPORT_PATH, title=f"Test Report - {test_name}")
    except Exception as e:
        logger.error(f"Report generation failed for {test_name}: {e}")
        return False

    # Stats from JSON
    expected_stats = count_violations_by_impact(RESULTS_DIR)

    # Compare JSON
    golden_path = test_dir / GOLDEN_SUFFIX
    json_pass = aggregate_and_compare_results(test_name, golden_path)

    # Audit Report
    report_pass = audit_report(REPORT_PATH, expected_stats)

    # Cleanup (optional: keep for manual inspection)
    # shutil.rmtree(RESULTS_DIR)
    # shutil.rmtree(DATA_DIR / "reports")
    # shutil.rmtree(DATA_DIR / "scan")
    # os.unlink(ZIP_PATH)

    overall_pass = json_pass and report_pass
    status = "✅ PASSED" if overall_pass else "❌ FAILED"
    logger.info(f"Test Set {test_name}: {status}")
    return overall_pass


def main():
    parser = argparse.ArgumentParser(description="E2E Test & Audit Script")
    parser.add_argument("--test-set", type=str, help="Run single test set (e.g., '1')")
    args = parser.parse_args()

    test_dirs = [d for d in TESTS_DIR.iterdir() if d.is_dir() and d.name.isdigit()]
    if args.test_set:
        test_dirs = [TESTS_DIR / args.test_set]
        if not test_dirs[0].exists():
            logger.error(f"Test set {args.test_set} not found!")
            sys.exit(1)

    if not test_dirs:
        logger.error("No test sets found in tests/assets/html_sets/")
        sys.exit(1)

    failures = []
    overall_stats = {
        "total_tests": len(test_dirs),
        "total_violations": 0,
        "total_screenshots": 0,
    }

    for test_dir in sorted(test_dirs, key=lambda p: int(p.name)):
        pass_test = run_single_test(test_dir)
        if not pass_test:
            failures.append(test_dir.name)
        # Accumulate stats (from count_violations_by_impact)
        # Note: You'd need to capture and sum from each run; for simplicity, log per test

    logger.info("\n--- Summary ---")
    logger.info(f"Tests Run: {overall_stats['total_tests']}")
    if failures:
        logger.error(f"Failures: {', '.join(failures)}")
        sys.exit(1)
    logger.info("All e2e tests & audits passed! 🎉")


if __name__ == "__main__":
    main()
```

</FILE>

---

<FILE path="scripts/run_golden_tests.py">

```python
#!/usr/bin/env python3
"""
Golden Test Runner for A11y Scanner
======================================
This script automates the process of:
1. Extracting test site ZIPs from tests/ directory
2. Running accessibility scans on each site
3. Generating golden test files for regression testing
4. Producing HTML reports for review

Usage:
    python scripts/run_golden_tests.py [--generate] [--sites SITE1,SITE2,...]

    --generate   : Generate new golden files (overwrites existing)
    --sites      : Run specific sites (comma-separated, defaults to all)
    --no-docker  : Run scans without Docker (local mode)
"""

from __future__ import annotations

import argparse
import difflib
import json
import logging
import shutil
import subprocess
import sys
from datetime import datetime
from pathlib import Path
from zipfile import ZipFile

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
)
logger = logging.getLogger(__name__)


def find_project_root() -> Path:
    """Find the project root directory."""
    current = Path(__file__).parent
    while current != current.parent:
        if (current / "pyproject.toml").exists():
            return current
        current = current.parent
    raise RuntimeError("Could not find project root")


def extract_test_zip(zip_path: Path, extract_to: Path) -> bool:
    """Extract a ZIP file to the target directory."""
    try:
        extract_to.mkdir(parents=True, exist_ok=True)
        with ZipFile(zip_path, "r") as zf:
            zf.extractall(extract_to)
        logger.info(f"✓ Extracted {zip_path.name} to {extract_to}")
        return True
    except Exception as e:
        logger.error(f"✗ Failed to extract {zip_path}: {e}")
        return False


def prepare_test_assets(
    project_root: Path, test_zips: list[Path] | None = None
) -> dict[str, Path]:
    """
    Prepare test assets by extracting ZIPs to tests/assets/html_sets/

    Returns:
        Dict mapping site names to their test directories
    """
    test_assets_dir = project_root / "tests" / "assets" / "html_sets"
    test_assets_dir.mkdir(parents=True, exist_ok=True)

    # Find all ZIPs in tests directory
    tests_dir = project_root / "tests"
    if test_zips is None:
        test_zips = sorted(tests_dir.glob("*.zip"))

    test_sites = {}

    for zip_path in test_zips:
        # Extract site name from ZIP (e.g., "Charitize-1.0.0.zip" -> "Charitize")
        site_name = zip_path.stem.rsplit("-", 1)[0]
        test_dir = test_assets_dir / site_name

        # Clean existing directory
        if test_dir.exists():
            logger.info(f"Cleaning existing test directory: {test_dir}")
            shutil.rmtree(test_dir)

        # Extract ZIP
        if extract_test_zip(zip_path, test_dir):
            test_sites[site_name] = test_dir
        else:
            logger.warning(f"Skipping {site_name} due to extraction error")

    return test_sites


def run_scan_for_site(
    project_root: Path, site_name: str, use_docker: bool = True
) -> bool:
    """
    Run an accessibility scan for a specific site.

    Assumes the site ZIP has been extracted to data/unzip/site.zip
    """
    try:
        if use_docker:
            logger.info(f"Running scan for {site_name} in Docker...")
            result = subprocess.run(
                ["make", "scan-local"],
                cwd=project_root,
                capture_output=True,
                text=True,
                timeout=300,
            )
        else:
            logger.info(f"Running scan for {site_name} locally...")
            result = subprocess.run(
                ["uv", "run", "python", "-m", "scanner.container.runner", "run"],
                cwd=project_root,
                capture_output=True,
                text=True,
                timeout=300,
            )

        if result.returncode != 0:
            logger.error(f"Scan failed for {site_name}")
            logger.error(f"STDOUT:\n{result.stdout}")
            logger.error(f"STDERR:\n{result.stderr}")
            return False

        logger.info(f"✓ Scan completed for {site_name}")
        return True

    except subprocess.TimeoutExpired:
        logger.error(f"Scan timeout for {site_name}")
        return False
    except Exception as e:
        logger.error(f"Error running scan for {site_name}: {e}")
        return False


def generate_golden_file(site_name: str, project_root: Path) -> bool:
    """
    Generate golden test file from scan results.

    Collects all JSON reports from data/results/ and saves to golden_results/
    """
    try:
        test_assets_dir = project_root / "tests" / "assets" / "html_sets" / site_name
        results_dir = project_root / "data" / "results"
        golden_dir = test_assets_dir / "golden_results"

        # Create golden_results directory
        golden_dir.mkdir(parents=True, exist_ok=True)

        # Collect and merge all result JSON files
        items = []
        for json_file in sorted(results_dir.glob("*.json")):
            try:
                with json_file.open("r", encoding="utf-8") as f:
                    data = json.load(f)
                    if "scanned_url" not in data:
                        data["scanned_url"] = data.get("url", "")
                    items.append(data)
            except json.JSONDecodeError as e:
                logger.warning(f"Invalid JSON in {json_file}: {e}")
                continue

        # Sort by scanned_url for consistency
        items.sort(key=lambda d: d.get("scanned_url", ""))

        # Write golden file
        golden_file = golden_dir / "report.json"
        with golden_file.open("w", encoding="utf-8") as f:
            json.dump(items, f, indent=2, sort_keys=True)

        logger.info(f"✓ Generated golden file: {golden_file}")
        logger.info(f"  - {len(items)} page(s) scanned")
        return True

    except Exception as e:
        logger.error(f"Error generating golden file for {site_name}: {e}")
        return False


def generate_html_report(site_name: str, project_root: Path) -> bool:
    """
    Generate HTML report from scan results.

    Uses the Jinja report generator to create an HTML report.
    """
    try:
        reports_dir = project_root / "data" / "reports"
        reports_dir.mkdir(parents=True, exist_ok=True)

        logger.info(f"Generating HTML report for {site_name}...")

        # Run the Jinja report generator
        latest_report = project_root / "data" / "reports" / "latest.html"
        result = subprocess.run(
            [
                "uv",
                "run",
                "python",
                "-c",
                f"""
import sys
from pathlib import Path
sys.path.insert(0, str(Path('{project_root}') / 'src'))
from scanner.reporting.jinja_report import build_report
results_dir = Path('{project_root}') / 'data' / 'results'
output_html = Path('{latest_report}')
build_report(results_dir, output_html, 'Accessibility Scan Report')
""",
            ],
            cwd=project_root,
            capture_output=True,
            text=True,
            timeout=60,
        )

        if result.returncode != 0:
            logger.warning(f"HTML report generation had issues: {result.stderr}")
            # Don't fail - report might still exist
        else:
            logger.info(f"✓ HTML report generated")

        # Copy report to site-specific location
        if latest_report.exists():
            site_report = (
                project_root
                / "data"
                / "reports"
                / f"{site_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html"
            )
            shutil.copy(latest_report, site_report)
            logger.info(f"✓ Saved report: {site_report}")
            return True
        else:
            logger.warning(f"No report generated for {site_name}")
            return False

    except Exception as e:
        logger.error(f"Error generating HTML report for {site_name}: {e}")
        return False


def clean_data_dirs(data_dir: Path) -> None:
    """Clean out data directories before scanning."""
    for name in ("unzip", "results", "scan"):
        d = data_dir / name
        if d.exists():
            try:
                shutil.rmtree(d)
            except Exception:
                pass
        d.mkdir(parents=True, exist_ok=True)


def copy_site_to_unzip(site_dir: Path, project_root: Path) -> bool:
    """Copy a test site to data/unzip/site.zip for scanning."""
    try:
        unzip_dir = project_root / "data" / "unzip"
        unzip_dir.mkdir(parents=True, exist_ok=True)

        # Create site.zip from the extracted directory
        zip_path = unzip_dir / "site.zip"
        shutil.make_archive(str(zip_path.with_suffix("")), "zip", site_dir)
        logger.info(f"✓ Created {zip_path}")
        return True

    except Exception as e:
        logger.error(f"Error copying site: {e}")
        return False


def compare_golden_files(site_name: str, project_root: Path) -> bool:
    """
    Compare current scan results with golden file.

    Returns True if they match, False if they differ.
    """
    try:
        test_assets_dir = project_root / "tests" / "assets" / "html_sets" / site_name
        results_dir = project_root / "data" / "results"
        golden_file = test_assets_dir / "golden_results" / "report.json"

        if not golden_file.exists():
            logger.warning(f"No golden file found for {site_name}")
            return False

        # Collect current results
        items = []
        for json_file in sorted(results_dir.glob("*.json")):
            try:
                with json_file.open("r", encoding="utf-8") as f:
                    data = json.load(f)
                    if "scanned_url" not in data:
                        data["scanned_url"] = data.get("url", "")
                    items.append(data)
            except json.JSONDecodeError:
                continue

        items.sort(key=lambda d: d.get("scanned_url", ""))

        # Compare with golden
        actual_str = json.dumps(items, indent=2, sort_keys=True)
        with golden_file.open("r", encoding="utf-8") as f:
            golden_str = f.read()

        if actual_str.strip() == golden_str.strip():
            logger.info(f"✓ {site_name} matches golden file")
            return True
        else:
            logger.warning(f"✗ {site_name} differs from golden file")
            # Show diff
            diff = list(
                difflib.unified_diff(
                    golden_str.splitlines(),
                    actual_str.splitlines(),
                    fromfile="golden",
                    tofile="actual",
                    lineterm="",
                )
            )
            if diff:
                logger.info("Diff (first 50 lines):")
                for line in diff[:50]:
                    logger.info(f"  {line}")
                if len(diff) > 50:
                    logger.info(f"  ... and {len(diff) - 50} more lines")
            return False

    except Exception as e:
        logger.error(f"Error comparing golden files for {site_name}: {e}")
        return False


def run_integration_tests(project_root: Path) -> bool:
    """Run the integration test suite."""
    try:
        logger.info("\nRunning integration test suite...")
        result = subprocess.run(
            ["make", "integration"],
            cwd=project_root,
            capture_output=True,
            text=True,
            timeout=600,
        )

        if result.returncode == 0:
            logger.info("✓ Integration tests passed")
            return True
        else:
            logger.warning("✗ Integration tests failed")
            logger.info(f"Output:\n{result.stdout}")
            return False

    except Exception as e:
        logger.error(f"Error running integration tests: {e}")
        return False


def main(argv: list[str] | None = None) -> int:
    """Main entry point."""
    parser = argparse.ArgumentParser(
        description="Generate golden test files for A11y Scanner",
    )
    parser.add_argument(
        "--generate",
        action="store_true",
        help="Generate new golden files (default: compare with existing)",
    )
    parser.add_argument(
        "--sites",
        help="Comma-separated list of sites to process (default: all)",
    )
    parser.add_argument(
        "--no-docker",
        action="store_true",
        help="Run scans without Docker",
    )
    parser.add_argument(
        "--compare-only",
        action="store_true",
        help="Only compare results with golden files (skip scanning)",
    )

    args = parser.parse_args(argv)

    project_root = find_project_root()
    logger.info(f"Project root: {project_root}")

    # Determine which sites to process
    if args.sites:
        selected_sites = args.sites.split(",")
        test_zips = [
            project_root / "tests" / f"{site.strip()}-*.zip"
            for site in selected_sites
        ]
        # Expand glob patterns
        test_zips = []
        for pattern in [
            project_root / "tests" / f"{site.strip()}*.zip"
            for site in selected_sites
        ]:
            test_zips.extend(sorted(pattern.parent.glob(pattern.name)))
    else:
        test_zips = None

    # Step 1: Prepare test assets (extract ZIPs)
    logger.info("\n=== Step 1: Preparing test assets ===")
    test_sites = prepare_test_assets(project_root, test_zips)

    if not test_sites:
        logger.error("No test sites found. Please ensure ZIP files are in tests/")
        return 1

    logger.info(f"Found {len(test_sites)} test site(s): {', '.join(test_sites.keys())}")

    # Step 2: Run scans and generate results
    success_count = 0

    if not args.compare_only:
        logger.info("\n=== Step 2: Running accessibility scans ===")

        for site_name, site_dir in test_sites.items():
            logger.info(f"\n--- Processing: {site_name} ---")

            # Clean data directories
            clean_data_dirs(project_root / "data")

            # Copy site to scanning location
            if not copy_site_to_unzip(site_dir, project_root):
                logger.error(f"Failed to prepare {site_name} for scanning")
                continue

            # Run scan
            if not run_scan_for_site(project_root, site_name, use_docker=not args.no_docker):
                logger.error(f"Failed to scan {site_name}")
                continue

            # Generate golden file if requested
            if args.generate:
                if generate_golden_file(site_name, project_root):
                    success_count += 1
                else:
                    logger.error(f"Failed to generate golden file for {site_name}")
            else:
                # Compare with existing golden
                if compare_golden_files(site_name, project_root):
                    success_count += 1

            # Generate HTML report
            generate_html_report(site_name, project_root)

    else:
        # Just compare mode
        logger.info("\n=== Comparing with golden files ===")
        for site_name, _ in test_sites.items():
            if compare_golden_files(site_name, project_root):
                success_count += 1

    # Step 3: Run integration tests
    logger.info("\n=== Step 3: Running integration tests ===")
    if run_integration_tests(project_root):
        logger.info("\n✓ All integration tests passed")
    else:
        logger.warning("\n✗ Some integration tests failed (see details above)")

    # Summary
    logger.info("\n" + "=" * 60)
    logger.info("SUMMARY")
    logger.info("=" * 60)
    logger.info(f"Total sites processed: {len(test_sites)}")
    logger.info(f"Successful: {success_count}")
    logger.info(f"Failed: {len(test_sites) - success_count}")

    if args.generate:
        logger.info("\n✓ Golden test files have been generated/updated")
        logger.info(f"  Location: tests/assets/html_sets/*/golden_results/report.json")

    logger.info("\n✓ HTML reports available at: data/reports/")

    if success_count == len(test_sites):
        logger.info("\n✓ All tests completed successfully!")
        return 0
    else:
        logger.warning(f"\n✗ {len(test_sites) - success_count} test(s) failed")
        return 1


if __name__ == "__main__":
    sys.exit(main())
```

</FILE>

---

<FILE path="scripts/test_in_docker.sh">

```bash
#!/usr/bin/env bash
# Script to run tests inside Docker with Playwright browsers

set -e

SCRIPT_DIR="$( cd "$( dirname "${BASH_SOURCE[0]}" )" && pwd )"
PROJECT_ROOT="$(dirname "$SCRIPT_DIR")"

cd "$PROJECT_ROOT"

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
NC='\033[0m' # No Color

echo -e "${YELLOW}=== A11y Scanner: Docker Test Runner ===${NC}\n"

# Parse command line arguments
TEST_TARGET="${1:-all}"
PYTEST_ARGS="${2:-}"

# Build test image with custom dockerignore
echo -e "${YELLOW}[1/3] Building test Docker image...${NC}"

# Temporarily rename dockerignore files to use test version
if [ -f .dockerignore ]; then
  mv .dockerignore .dockerignore.bak
fi
if [ -f .dockerignore.test ]; then
  cp .dockerignore.test .dockerignore
fi

docker build \
  -f docker/Dockerfile.test \
  -t a11y-scanner-test:latest \
  .

BUILD_RESULT=$?

# Restore original dockerignore
rm -f .dockerignore
if [ -f .dockerignore.bak ]; then
  mv .dockerignore.bak .dockerignore
fi

if [ $BUILD_RESULT -ne 0 ]; then
  echo -e "${RED}Failed to build test image${NC}"
  exit 1
fi

echo -e "${GREEN}✓ Test image built${NC}\n"

# Run tests based on target
echo -e "${YELLOW}[2/3] Running tests...${NC}"

case "$TEST_TARGET" in
  unit)
    echo "Running unit tests only (no integration)"
    docker run --rm \
      -v "$PROJECT_ROOT/data:/home/pwuser/data" \
      a11y-scanner-test:latest \
      pytest -v tests/ -k "not integration" $PYTEST_ARGS
    ;;

  integration)
    echo "Running integration tests only"
    docker run --rm \
      -v /var/run/docker.sock:/var/run/docker.sock \
      -v "$PROJECT_ROOT/data:/home/pwuser/data" \
      --user root \
      a11y-scanner-test:latest \
      pytest -v tests/ -k "integration" $PYTEST_ARGS
    ;;

  all)
    echo "Running all tests"
    docker run --rm \
      -v /var/run/docker.sock:/var/run/docker.sock \
      -v "$PROJECT_ROOT/data:/home/pwuser/data" \
      --user root \
      a11y-scanner-test:latest \
      pytest -v $PYTEST_ARGS
    ;;

  coverage)
    echo "Running tests with coverage report"
    docker run --rm \
      -v /var/run/docker.sock:/var/run/docker.sock \
      -v "$PROJECT_ROOT/data:/home/pwuser/data" \
      -v "$PROJECT_ROOT/htmlcov:/home/pwuser/htmlcov" \
      --user root \
      a11y-scanner-test:latest \
      pytest -v --cov=src --cov-report=html --cov-report=term $PYTEST_ARGS
    ;;

  *)
    echo -e "${RED}Unknown test target: $TEST_TARGET${NC}"
    echo "Usage: $0 [unit|integration|all|coverage] [additional pytest args]"
    exit 1
    ;;
esac

TEST_EXIT_CODE=$?

if [ $TEST_EXIT_CODE -eq 0 ]; then
  echo -e "\n${GREEN}[3/3] ✓ All tests passed!${NC}"
else
  echo -e "\n${RED}[3/3] ✗ Tests failed with exit code $TEST_EXIT_CODE${NC}"
  exit $TEST_EXIT_CODE
fi
```

</FILE>

---

### Entering Directory: 'src/a11y_scanner.egg-info/'

<FILE path="src/a11y_scanner.egg-info/dependency_links.txt">

```

```

</FILE>

---

<FILE path="src/a11y_scanner.egg-info/entry_points.txt">

```
[console_scripts]
scanner = scanner.main:main
scanner-api = scanner.web.server:run
scanner-docker = scanner.container.runner:main
scanner-integration = scanner.container.integration:main
```

</FILE>

---

<FILE path="src/a11y_scanner.egg-info/PKG-INFO">

```
Metadata-Version: 2.4
Name: a11y-scanner
Version: 0.4.0
Summary: A containerized web accessibility scanner using Playwright and axe-core for comprehensive WCAG compliance testing.
Author-email: Matt <matthewboback@gmail.com>
License: MIT
Project-URL: Homepage, https://github.com/mattboback/a11y-scanner
Project-URL: Documentation, https://github.com/mattboback/a11y-scanner/blob/main/README.md
Project-URL: Repository, https://github.com/mattboback/a11y-scanner
Project-URL: Issues, https://github.com/mattboback/a11y-scanner/issues
Project-URL: Changelog, https://github.com/mattboback/a11y-scanner/blob/main/CHANGELOG.md
Keywords: accessibility,a11y,wcag,testing,playwright,axe,scanner,compliance,docker
Classifier: Development Status :: 4 - Beta
Classifier: Intended Audience :: Developers
Classifier: Topic :: Software Development :: Testing
Classifier: Topic :: Software Development :: Quality Assurance
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Framework :: Playwright
Classifier: Environment :: Console
Classifier: Operating System :: OS Independent
Requires-Python: >=3.10
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: rich==13.9.4
Requires-Dist: axe-playwright-python==0.1.4
Requires-Dist: playwright==1.54.0
Requires-Dist: docker==7.1.0
Requires-Dist: jinja2==3.1.5
Requires-Dist: fastapi==0.115.6
Requires-Dist: uvicorn[standard]==0.34.2
Requires-Dist: python-multipart==0.0.20
Provides-Extra: test
Requires-Dist: pytest==8.3.4; extra == "test"
Requires-Dist: pyfakefs==5.7.2; extra == "test"
Requires-Dist: pytest-cov==6.0.0; extra == "test"
Requires-Dist: requests==2.32.3; extra == "test"
Requires-Dist: httpx==0.28.1; extra == "test"
Provides-Extra: dev
Requires-Dist: a11y-scanner[test]; extra == "dev"
Requires-Dist: black==24.10.0; extra == "dev"
Requires-Dist: ruff==0.8.4; extra == "dev"
Dynamic: license-file

# a11y-scanner

> A containerized web accessibility scanner using Playwright and axe-core for comprehensive WCAG compliance testing.

[![CI Status](https://github.com/mattboback/a11y-scanner/actions/workflows/ci.yml/badge.svg)](https://github.com/mattboback/a11y-scanner/actions)
[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)

---

## What is a11y-scanner?

**a11y-scanner** is a Python-based accessibility testing tool that automates WCAG compliance checks for web applications. It combines the power of [axe-core](https://github.com/dequelabs/axe-core) (the industry-leading accessibility rules engine) with [Playwright](https://playwright.dev/) (modern browser automation) to provide:

- 🔍 **Comprehensive scanning** of static sites, multi-page applications, and single pages
- 📊 **Rich HTML reports** with violation screenshots and remediation guidance
- 🐳 **Docker-first architecture** for consistent, reproducible results
- 🔌 **REST API** for integration into CI/CD pipelines
- 🔒 **Security-hardened** with Zip Slip protection, SSRF prevention, and input validation

Perfect for developers, QA teams, and accessibility specialists who need automated a11y testing in their workflows.

---

## ✨ Features

### Core Capabilities

- **Multi-format Input**: Scan from ZIP archives, local directories, or live URLs
- **Browser-based Testing**: Real browser rendering via Playwright (Chromium/Firefox/WebKit)
- **axe-core Integration**: Industry-standard WCAG 2.1 Level A/AA rule engine
- **Visual Evidence**: Automatic screenshots of violating elements with red highlighting
- **JSON + HTML Reports**: Machine-readable data and human-friendly visualizations
- **Browser Reuse**: Context manager pattern for 40-80% faster multi-page scans

### Security Features

- **Zip Slip Protection** (CWE-22): Path traversal validation prevents malicious archives
- **SSRF Prevention**: Blocks localhost and private IP ranges in URL scanning
- **Input Validation**: File size limits (100MB), MIME type checking, extension validation
- **Container Isolation**: Read-only source mounts, controlled data volumes
- **Optional API Authentication**: Token-based auth via `A11Y_API_TOKEN` environment variable

### Developer Experience

- **Three Run Modes**: CLI, API server, or Docker container orchestration
- **CI/CD Ready**: GitHub Actions examples, exit codes for violation detection
- **Flexible Configuration**: Environment variables for screenshots, paths, tokens
- **Detailed Logging**: Structured logs with configurable verbosity
- **Type Hinted**: Full type annotations for better IDE support

---

## 🚀 Quick Start

### Prerequisites

- Python 3.10+ ([download](https://www.python.org/downloads/))
- Docker 20.10+ or Podman 3.4+ ([get Docker](https://docs.docker.com/get-docker/))
- 2GB RAM minimum, 4GB recommended

### Installation

```bash
# Clone the repository
git clone https://github.com/mattboback/a11y-scanner.git
cd a11y-scanner

# Create virtual environment
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate

# Install with development dependencies
pip install -e ".[dev]"

# Prepare Docker image (one-time, ~2-5 minutes)
python -m scanner.container.runner prepare
```

### Run Your First Scan

```bash
# Create a sample HTML file
mkdir -p data/unzip
cat > data/unzip/index.html << 'EOF'
<!DOCTYPE html>
<html lang="en">
<head><title>Test Page</title></head>
<body>
    <h1>Sample Page</h1>
    <img src="photo.jpg">  <!-- Missing alt text - violation! -->
    <button>Click</button>
</body>
</html>
EOF

# Package as ZIP
cd data/unzip && zip -r ../site.zip . && cd ../..

# Run the scan
python -m scanner.container.runner run

# View the report
open data/reports/latest.html  # macOS
# Or: xdg-open data/reports/latest.html  # Linux
# Or: start data/reports/latest.html     # Windows
```

You should see a violation report for the missing `alt` attribute! 🎉

---

## 📖 Usage

### Mode 1: CLI (Scan ZIP Files)

The primary mode for scanning packaged sites:

```bash
# Scan a ZIP file
python -m scanner.container.runner run

# Custom paths
python -m scanner.container.runner run \
    --zip-path /path/to/site.zip \
    --output-dir /path/to/results

# Disable screenshots for faster scans
A11Y_NO_SCREENSHOTS=1 python -m scanner.container.runner run
```

**Expected output:**
```
✓ Docker image ready
✓ Scanning site.zip...
✓ Found 3 pages
✓ Scanned 3 pages
⚠ Found 12 violations
✓ Report: data/reports/latest.html
```

### Mode 2: API Server

Long-running service for programmatic access:

```bash
# Start the API server (runs on port 8008)
python -m scanner.container.runner serve

# In another terminal, scan via API
curl -X POST http://localhost:8008/api/scan/zip \
    -H "Content-Type: multipart/form-data" \
    -F "file=@data/unzip/site.zip"

# Response:
# {
#   "status": "success",
#   "pages_scanned": 3,
#   "total_violations": 12,
#   "report_path": "data/reports/latest.html",
#   "results_dir": "data/results"
# }
```

**With authentication:**
```bash
# Generate a secure token
export A11Y_API_TOKEN=$(openssl rand -base64 32)

# Start server with auth
python -m scanner.container.runner serve

# Use token in requests
curl -X POST http://localhost:8008/api/scan/zip \
    -H "X-API-Key: $A11Y_API_TOKEN" \
    -F "file=@site.zip"
```

### Mode 3: Scan Live URLs

Scan a running website:

```bash
# Single URL
python scan_live_site.py https://example.com

# Multiple pages (coming soon)
# python scan_live_site.py https://example.com/page1 https://example.com/page2
```

---

## 🖥️ Platform Support

| Platform | Support Status | Notes |
|----------|----------------|-------|
| **Linux** | ✅ Fully Supported | Ubuntu 20.04+, Debian 11+, Fedora 35+ |
| **macOS** | ✅ Fully Supported | macOS 11+ (Intel & Apple Silicon) |
| **Windows** | ⚠️ Supported via WSL2 | Native Windows support planned |
| **Docker** | ✅ Recommended | Docker 20.10+ or Podman 3.4+ |

### System Requirements

- **RAM**: 2GB minimum, 4GB recommended
- **Disk**: 2GB for Docker images + scan artifacts
- **CPU**: 2 cores minimum (parallel scanning planned for v1.1)
- **Network**: Internet access for Docker image pull (one-time setup)

---

## 🌍 Real-World Examples

### CI/CD Integration (GitHub Actions)

Automatically scan on every push:

```yaml
# .github/workflows/accessibility.yml
name: Accessibility Audit

on:
  push:
    branches: [main]
  pull_request:

jobs:
  a11y-scan:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install scanner
        run: |
          pip install -e .
          python -m scanner.container.runner prepare

      - name: Build and package site
        run: |
          npm ci && npm run build
          mkdir -p data/unzip
          cd dist && zip -r ../data/unzip/site.zip .

      - name: Run accessibility scan
        run: python -m scanner.container.runner run

      - name: Upload report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: accessibility-report
          path: data/reports/latest.html

      - name: Fail on violations
        run: |
          count=$(jq -s 'map(.violations | length) | add' data/results/*.json)
          if [ "$count" -gt 0 ]; then
            echo "::error::Found $count accessibility violations"
            exit 1
          fi
```

### Docker Compose for Teams

Shared accessibility scanner service:

```yaml
# docker-compose.yml
version: '3.8'

services:
  a11y-scanner:
    image: mattboback/a11y-scanner:latest
    container_name: team-a11y-scanner
    ports:
      - "8008:8008"
    volumes:
      - ./scans:/worksrc/data
    environment:
      - A11Y_API_TOKEN=${SCANNER_API_TOKEN}
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8008/healthz"]
      interval: 30s
      timeout: 10s
      retries: 3

# Usage:
# 1. export SCANNER_API_TOKEN=$(openssl rand -base64 32)
# 2. docker-compose up -d
# 3. curl -H "X-API-Key: $SCANNER_API_TOKEN" \
#        -F "file=@site.zip" \
#        http://localhost:8008/api/scan/zip
```

### Scheduled Weekly Audits

Monitor production site automatically:

```yaml
# .github/workflows/weekly-audit.yml
name: Weekly A11y Audit

on:
  schedule:
    - cron: '0 9 * * 1'  # Every Monday at 9 AM

jobs:
  scan-production:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Install and scan
        run: |
          pip install -e .
          python -m scanner.container.runner prepare
          python scan_live_site.py https://yoursite.com

      - name: Create issue if violations found
        if: failure()
        uses: actions/github-script@v7
        with:
          script: |
            github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: '🚨 Weekly A11y Scan Found Violations',
              body: 'Check the workflow artifacts for the full report.',
              labels: ['accessibility', 'automated']
            })
```

---

## ⚡ Performance Benchmarks

Real-world scanning performance on a 4-core, 16GB RAM development machine:

| Site Size | Pages | Violations | Scan Time | Memory |
|-----------|-------|------------|-----------|---------|
| Small | 10 | 45 | ~15s | 400MB |
| Medium | 50 | 200 | ~1m 30s | 600MB |
| Large | 200 | 800 | ~6m | 1.2GB |

### Optimization Tips

- **Browser Reuse**: 40-80% faster on multi-page sites (automatically enabled in pipeline)
- **Disable Screenshots**: Set `A11Y_NO_SCREENSHOTS=1` for 2x faster scans
- **Parallel Scanning**: Coming in v1.1 with `--workers 4` flag

---

## 🛠️ Troubleshooting

### Docker Permission Issues

**Problem:** `docker: Got permission denied while trying to connect to the Docker daemon`

**Solution (Linux):**
```bash
sudo usermod -aG docker $USER
newgrp docker  # Or log out and back in
```

### Podman Socket Not Found

**Problem:** `Cannot connect to Podman socket`

**Solution:**
```bash
systemctl --user start podman.socket
systemctl --user enable podman.socket
podman version  # Verify
```

### Port Already in Use

**Problem:** `Address already in use: 8008`

**Solution:**
```bash
# Use different port
python -m scanner.container.runner serve --port 8009

# Or find and kill process
lsof -ti:8008 | xargs kill -9  # macOS/Linux
```

### Slow First Build

**Problem:** Docker image build takes 5+ minutes

**Expected:** This is normal for the first build. Subsequent builds use cache and complete in seconds. Run `python -m scanner.container.runner prepare` once during setup.

### Screenshots Not Capturing

**Problem:** Violation screenshots are missing or blank

**Common Causes:**
1. JavaScript-heavy pages (already using `networkidle` wait)
2. CSP violations (check browser console with `--verbose`)
3. Memory limits (increase Docker memory: `shm_size: "2gb"`)

**Workaround:** Disable screenshots if not needed:
```bash
export A11Y_NO_SCREENSHOTS=1
python -m scanner.container.runner run
```

### Windows-Specific Issues

**Problem:** Path errors on Windows

**Solution:** Use WSL2 (Windows Subsystem for Linux):
```powershell
wsl --install  # Install WSL2
# Inside WSL2:
cd /path/to/a11y-scanner
python -m venv .venv
source .venv/bin/activate
pip install -e ".[dev]"
```

### Getting Help

1. **Check existing issues**: [GitHub Issues](https://github.com/mattboback/a11y-scanner/issues)
2. **Ask in discussions**: [GitHub Discussions](https://github.com/mattboback/a11y-scanner/discussions)
3. **Review documentation**: See [`docs/`](docs/) folder
4. **Enable debug logging**:
   ```python
   from scanner.core.logging_setup import setup_logging
   import logging
   setup_logging(level=logging.DEBUG)
   ```

---

## ❓ FAQ

**Q: How does this compare to browser extensions like axe DevTools?**

A: Browser extensions are great for manual testing, but a11y-scanner is designed for automation:
- ✅ Runs in CI/CD without manual intervention
- ✅ Scans entire sites in batch
- ✅ Self-hosted for security/compliance
- ✅ Integrates into development workflows

**Q: Does this replace manual accessibility testing?**

A: **No.** Automated tools catch ~30-40% of accessibility issues. You still need:
- Manual keyboard navigation testing
- Screen reader testing (NVDA, JAWS, VoiceOver)
- User testing with people with disabilities

**Q: Can I scan sites behind authentication?**

A: Not directly yet. Current workarounds:
1. Export static HTML after authentication
2. Use a browser extension to save authenticated pages
3. Contribute authentication support (see [Contributing](#-contributing))

**Q: Is this WCAG 2.1 AA compliant?**

A: a11y-scanner **tests for** WCAG violations using axe-core, which covers many WCAG 2.1 Level A and AA criteria. It's a tool to help **achieve** compliance, not a certification.

**Q: Can I customize the rules?**

A: Currently uses axe-core's default ruleset. Custom rules are planned for v1.2. You can disable specific rules by forking and modifying the axe configuration in `src/scanner/services/playwright_axe_service.py`.

**Q: Why Docker? Can I run without it?**

A: Docker ensures consistent browser environments across platforms:
- ✅ No Playwright dependency version mismatches
- ✅ Reproducible results in CI/CD
- ✅ Works the same on Linux, macOS, Windows (via WSL2)

You *can* run Playwright natively for development, but Docker is recommended for production/CI use.

**Q: How much does this cost?**

A: a11y-scanner is **free and open source** (MIT license). You only pay for:
- Infrastructure (servers, CI minutes if using cloud providers)
- Optional: Commercial support (not yet available)

**Q: Can I contribute?**

A: **Yes!** See [CONTRIBUTING.md](CONTRIBUTING.md). We welcome:
- 🐛 Bug reports and fixes
- ✨ Feature requests and implementations
- 📝 Documentation improvements
- 💡 Use cases and examples

---

## 🤝 Contributing

We love contributions! See [CONTRIBUTING.md](CONTRIBUTING.md) for:
- Development setup
- Code style guidelines (Black, Ruff)
- Testing requirements (pytest, coverage)
- Commit conventions (Conventional Commits)
- PR process

**Quick start for contributors:**
```bash
git clone https://github.com/mattboback/a11y-scanner.git
cd a11y-scanner
python -m venv .venv && source .venv/bin/activate
pip install -e ".[dev]"
pytest  # Run tests
black . # Format code
ruff check .  # Lint
```

---

## 📄 License

This project is licensed under the **MIT License** - see [LICENSE](LICENSE) for details.

---

## 🌟 Acknowledgments

- **[axe-core](https://github.com/dequelabs/axe-core)** by Deque Systems - Industry-leading accessibility rules engine
- **[Playwright](https://playwright.dev/)** by Microsoft - Modern browser automation
- **[axe-playwright-python](https://github.com/abhinaba-ghosh/axe-playwright-python)** - Python bindings for axe in Playwright

---

## 📞 Contact & Support

- **GitHub**: [@mattboback](https://github.com/mattboback)
- **Issues**: [Report a bug](https://github.com/mattboback/a11y-scanner/issues)
- **Discussions**: [Ask questions](https://github.com/mattboback/a11y-scanner/discussions)
- **Security**: matthewboback@gmail.com (for security vulnerabilities only)
- **Website**: [matthewboback.com](https://matthewboback.com)

---

**⭐ Star this repo** to stay updated on new releases and features!

Made with ❤️ by [Matthew Boback](https://matthewboback.com)
```

</FILE>

---

<FILE path="src/a11y_scanner.egg-info/requires.txt">

```
rich==13.9.4
axe-playwright-python==0.1.4
playwright==1.54.0
docker==7.1.0
jinja2==3.1.5
fastapi==0.115.6
uvicorn[standard]==0.34.2
python-multipart==0.0.20

[dev]
a11y-scanner[test]
black==24.10.0
ruff==0.8.4

[test]
pytest==8.3.4
pyfakefs==5.7.2
pytest-cov==6.0.0
requests==2.32.3
httpx==0.28.1
```

</FILE>

---

<FILE path="src/a11y_scanner.egg-info/SOURCES.txt">

```
LICENSE
README.md
pyproject.toml
src/a11y_scanner.egg-info/PKG-INFO
src/a11y_scanner.egg-info/SOURCES.txt
src/a11y_scanner.egg-info/dependency_links.txt
src/a11y_scanner.egg-info/entry_points.txt
src/a11y_scanner.egg-info/requires.txt
src/a11y_scanner.egg-info/top_level.txt
src/scanner/__init__.py
src/scanner/main.py
src/scanner/pipeline.py
src/scanner/container/__init__.py
src/scanner/container/integration.py
src/scanner/container/manager.py
src/scanner/container/runner.py
src/scanner/core/logging_setup.py
src/scanner/core/settings.py
src/scanner/reporting/__init__.py
src/scanner/reporting/jinja_report.py
src/scanner/services/html_discovery_service.py
src/scanner/services/http_service.py
src/scanner/services/playwright_axe_service.py
src/scanner/services/zip_service.py
src/scanner/templates/__init__.py
src/scanner/templates/a11y_report.html.j2
src/scanner/web/server.py
tests/test_api.py
tests/test_html_discovery_service.py
tests/test_http_service.py
tests/test_pipeline.py
tests/test_reporting.py
tests/test_settings.py
tests/test_zip_service.py
```

</FILE>

---

<FILE path="src/a11y_scanner.egg-info/top_level.txt">

```
scanner
```

</FILE>

---

### Entering Directory: 'src/scanner/'

<FILE path="src/scanner/__init__.py">

```python
# empty
```

</FILE>

---

<FILE path="src/scanner/main.py">

```python
# src/scanner/main.py
import json
import logging
import os
import sys

from scanner.core.logging_setup import setup_logging
from scanner.core.settings import Settings
from scanner.pipeline import Pipeline
from scanner.reporting.jinja_report import build_report
from scanner.services.html_discovery_service import HtmlDiscoveryService
from scanner.services.http_service import HttpService
from scanner.services.playwright_axe_service import PlaywrightAxeService
from scanner.services.zip_service import ZipService

log = logging.getLogger(__name__)

IN_CONTAINER_ENV = "A11Y_SCANNER_IN_CONTAINER"
IN_CONTAINER_VALUE = "1"


def _assert_docker_context() -> None:
    """Ensure we are running inside the Docker container."""
    if os.environ.get(IN_CONTAINER_ENV) != IN_CONTAINER_VALUE:
        print(
            "\n[ERROR] This CLI is Docker-only.\n"
            "Run via the container runner instead:\n"
            "  python -m scanner.container.runner prepare\n"
            "  python -m scanner.container.runner run\n",
            file=sys.stderr,
        )
        sys.exit(2)


def main():
    """Main entry point for the scanner application using Playwright."""
    _assert_docker_context()  # hard guard: no bare-metal runs
    setup_logging(level=logging.INFO)
    log.info("--- Starting A11y Scanner with Playwright ---")

    try:
        # 1. Create all dependencies (the "composition root")
        settings = Settings()
        zip_service = ZipService(
            unzip_dir=settings.unzip_dir, scan_dir=settings.scan_dir
        )
        html_service = HtmlDiscoveryService(scan_dir=settings.scan_dir)
        http_service = HttpService()
        axe_service = PlaywrightAxeService()
        # 2. Orchestrate
        pipeline = Pipeline(
            settings=settings,
            zip_service=zip_service,
            html_service=html_service,
            http_service=http_service,
            axe_service=axe_service,
        )
        # 3. Run the pipeline
        results = pipeline.run()
        # 4. Generate consolidated HTML report
        reports_dir = settings.data_dir / "reports"
        reports_dir.mkdir(parents=True, exist_ok=True)
        output_html = reports_dir / "latest.html"

        try:
            build_report(
                settings.results_dir, output_html, title="Accessibility Report"
            )
            log.info("Consolidated HTML report generated at: %s", output_html)
        except Exception as e:
            log.error("Failed to generate HTML report: %s", e)
            # Continue with the rest of the execution, don't fail the entire scan

        # 5. Process results
        log.info("--- Pipeline run finished ---")
        if results:
            print("\n--- Accessibility Scan Results ---")
            print(f"Found {len(results)} accessibility violations:")
            print(json.dumps(results, indent=2))
            print(f"\n✅ Full HTML report available at: {output_html.resolve()}")
        else:
            print("\n✅ No accessibility violations found!")
            print(f"Full report available at: {output_html.resolve()}")

        sys.exit(0)

    except FileNotFoundError:
        log.error("Execution failed: Could not find the input zip file.")
        sys.exit(1)
    except RuntimeError as e:
        log.error("Execution failed: %s", e)
        sys.exit(1)
    except Exception:
        log.exception("An unexpected error occurred during pipeline execution.")
        sys.exit(1)


if __name__ == "__main__":
    main()
```

</FILE>

---

<FILE path="src/scanner/pipeline.py">

```python
# src/scanner/pipeline.py
from __future__ import annotations

import logging
from typing import Any

from scanner.core.settings import Settings
from scanner.services.html_discovery_service import HtmlDiscoveryService
from scanner.services.http_service import HttpService
from scanner.services.playwright_axe_service import PlaywrightAxeService
from scanner.services.zip_service import ZipService

log = logging.getLogger(__name__)

__all__ = ["Pipeline"]


class Pipeline:
    """
    Orchestrates the scanning workflow using the native Python Playwright library.
    """

    def __init__(
        self,
        settings: Settings,
        zip_service: ZipService,
        html_service: HtmlDiscoveryService,
        http_service: HttpService,
        axe_service: PlaywrightAxeService,
    ):
        self.settings = settings
        self.zip_service = zip_service
        self.html_service = html_service
        self.http_service = http_service
        self.axe_service = axe_service

    def run(self) -> list[dict[str, Any]]:
        """
        Orchestrates the full scanning pipeline:
        1. Unzip the source archive
        2. Discover HTML files
        3. Start a local web server
        4. Scan each HTML file with Playwright + axe-core
        5. Stop the web server
        6. Return consolidated results
        """
        log.info("Starting pipeline execution...")
        all_results = []

        try:
            # Step 1: Unzip
            self.zip_service.run()

            # Step 2: Discover HTML files
            html_files = self.html_service.discover_html_files()
            if not html_files:
                log.warning(
                    "No HTML files found in the extracted content. Nothing to scan."
                )
                return []

            # Step 3: Start the server
            self.http_service.start(directory=self.settings.scan_dir)

            # Step 4: Scan each file with a reusable browser
            with self.axe_service:
                for file_info in html_files:
                    relative_path = file_info["relative"]
                    url_to_scan = f"{self.http_service.base_url}/{relative_path}"

                    # Define a unique path for the full report artifact
                    report_filename = (
                        f"{relative_path.as_posix().replace('/', '_')}.json"
                    )
                    report_path = self.settings.results_dir / report_filename

                    try:
                        # The new service directly returns the violations
                        violations = self.axe_service.scan_url(
                            url_to_scan, report_path, source_file=str(relative_path)
                        )
                        if violations:
                            # Add context to each violation for better reporting
                            for violation in violations:
                                violation["scanned_url"] = url_to_scan
                                violation["source_file"] = str(relative_path)
                            all_results.extend(violations)
                    except RuntimeError as e:
                        log.error("Failed to scan %s: %s", url_to_scan, e)
                        continue  # Continue to the next file

            log.info("Pipeline execution completed successfully.")
            return all_results

        except FileNotFoundError as e:
            log.error("Pipeline failed: input zip file not found. %s", e)
            raise
        except Exception:
            log.exception("Pipeline failed due to an unexpected error.")
            raise
        finally:
            # Step 5: Always ensure the server is stopped
            log.info("Pipeline finished. Shutting down HTTP server.")
            self.http_service.stop()
```

</FILE>

---

### Entering Directory: 'src/scanner/container/'

<FILE path="src/scanner/container/__init__.py">

```python
"""
Lightweight container management utilities using the Docker SDK for Python.

This package removes the need for docker-compose and Dockerfiles by:
- pulling a Playwright Python base image,
- mounting the repository and data directories,
- installing the project into a virtualenv inside the container,
- running the scanner as `python -m scanner.main`.

Public entrypoints:
- scanner.container.runner: CLI to run a one-off scan in a container.
- scanner.container.integration: Integration test harness using the container.
"""
```

</FILE>

---

<FILE path="src/scanner/container/integration.py">

```python
from __future__ import annotations

import difflib
import json
import sys
from pathlib import Path
from zipfile import ZIP_DEFLATED, ZipFile

from .manager import ContainerManager, find_project_root


def _zip_test_case(src_dir: Path, zip_path: Path) -> None:
    """
    Recursively zip the contents of `src_dir` (excluding `golden_results`)
    into `zip_path`.
    """
    zip_path.parent.mkdir(parents=True, exist_ok=True)
    with ZipFile(zip_path, "w", ZIP_DEFLATED) as zf:
        for p in src_dir.rglob("*"):
            if "golden_results" in p.parts:
                continue
            if p.is_file():
                arcname = p.relative_to(src_dir)
                zf.write(p, arcname)


def _clean_data_dirs(data_dir: Path) -> None:
    """Remove contents of unzip, results, and scan dirs; recreate them."""
    for name in ("unzip", "results", "scan"):
        d = data_dir / name
        if d.exists():
            for f in sorted(d.rglob("*"), reverse=True):
                try:
                    if f.is_file() or f.is_symlink():
                        f.unlink()
                    else:
                        f.rmdir()
                except Exception:
                    pass
            try:
                d.rmdir()
            except Exception:
                pass
        d.mkdir(parents=True, exist_ok=True)


def _slurp_raw_reports(results_dir: Path) -> list[dict]:
    """
    Emulate: jq -s 'sort_by(.scanned_url)' results/*.json

    Read each per-page JSON report (raw axe report we saved), ensure it has
    a top-level 'scanned_url' (we now write it in PlaywrightAxeService), and
    return a list sorted by that key.
    """
    items: list[dict] = []
    for f in sorted(results_dir.glob("*.json")):
        try:
            with open(f, encoding="utf-8") as fh:
                data = json.load(fh)
            if "scanned_url" not in data:
                data["scanned_url"] = data.get("url", "")
            items.append(data)
        except Exception:
            continue

    items.sort(key=lambda d: d.get("scanned_url", ""))
    return items


def _unified_diff_str(a: str, b: str, fromfile: str, tofile: str) -> str:
    return "\n".join(
        difflib.unified_diff(
            a.splitlines(),
            b.splitlines(),
            fromfile=fromfile,
            tofile=tofile,
            lineterm="",
        )
    )


def main() -> int:
    print("--- A11y Scanner: Integration Test Suite (Docker SDK) ---")
    project_root = find_project_root()
    tests_assets = project_root / "tests" / "assets" / "html_sets"
    data_dir = project_root / "data"
    unzip_dir = data_dir / "unzip"
    results_dir = data_dir / "results"

    if not tests_assets.exists():
        print(f"ERROR: Assets directory not found: {tests_assets}", file=sys.stderr)
        return 1

    manager = ContainerManager(project_root=project_root)
    if hasattr(manager, "ensure_image"):
        manager.ensure_image()
    else:
        manager.ensure_base_image()  # type: ignore[attr-defined]

    failures: list[str] = []

    for test_case_dir in sorted(p for p in tests_assets.iterdir() if p.is_dir()):
        test_case_name = test_case_dir.name
        print(f"\n--- Running Test Case: {test_case_name} ---")

        # 1) Prepare inputs
        print("[PREPARE] Cleaning 'data' directories and creating input zip...")
        _clean_data_dirs(data_dir)
        zip_path = unzip_dir / "site.zip"
        _zip_test_case(test_case_dir, zip_path)

        # 2) Execute
        print("[EXECUTE] Running scanner container...")
        exit_code = manager.run_scanner(stream_logs=False)
        if exit_code != 0:
            print(
                f"[ERROR] Scanner exited with code {exit_code}",
                file=sys.stderr,
            )
            failures.append(test_case_name)
            continue

        # 3) Verify
        print("[VERIFY] Comparing results to golden file...")
        golden_file = test_case_dir / "golden_results" / "report.json"
        if not golden_file.exists():
            print(
                f"❌ FAILURE: Golden file not found for '{test_case_name}'.",
                file=sys.stderr,
            )
            failures.append(test_case_name)
            continue

        actual_list = _slurp_raw_reports(results_dir)
        actual_str = json.dumps(actual_list, indent=2, sort_keys=True)

        try:
            with open(golden_file, encoding="utf-8") as fh:
                golden_str = fh.read()
        except Exception as e:
            print(
                f"❌ FAILURE: Could not read golden file for '{test_case_name}': {e}",
                file=sys.stderr,
            )
            failures.append(test_case_name)
            continue

        if actual_str.strip() == golden_str.strip():
            print(f"✅ SUCCESS: '{test_case_name}' matches the golden file.")
        else:
            print(
                f"❌ FAILURE: '{test_case_name}' does not match golden.",
                file=sys.stderr,
            )
            diff = _unified_diff_str(
                golden_str, actual_str, fromfile="golden", tofile="actual"
            )
            print(diff)
            failures.append(test_case_name)

    if failures:
        print("\n--- FAILURES ---")
        for name in failures:
            print(f"- {name}")
        return 1

    print("\n--- ✅ All integration tests passed successfully! ---")
    return 0


if __name__ == "__main__":
    sys.exit(main())
```

</FILE>

---

<FILE path="src/scanner/container/manager.py">

```python
from __future__ import annotations

import hashlib
import os
import platform
import sys
from dataclasses import dataclass
from pathlib import Path

import docker

DEFAULT_BASE_IMAGE = "mcr.microsoft.com/playwright/python:v1.54.0-jammy"
CACHED_REPO_NAME = "a11y-scanner-cache"
CACHED_VENV_PATH = "/opt/a11y/venv"
IN_CONTAINER_ENV = "A11Y_SCANNER_IN_CONTAINER"
IN_CONTAINER_VALUE = "1"


def find_project_root(start: Path | None = None) -> Path:
    """
    Locate the project root by searching upwards for pyproject.toml.
    Falls back to the current working directory if not found.
    """
    start = start or Path.cwd()
    current = start.resolve()
    for parent in [current] + list(current.parents):
        if (parent / "pyproject.toml").exists():
            return parent
    return current


@dataclass
class ContainerConfig:
    base_image: str = DEFAULT_BASE_IMAGE
    workdir: str = "/worksrc"
    data_subdir: str = "data"
    shm_size: str = "2g"
    env: dict[str, str] | None = None

    def __post_init__(self):
        if self.env is None:
            # Keep output unbuffered and quiet apt dialogs.
            self.env = {
                "PYTHONUNBUFFERED": "1",
                "DEBIAN_FRONTEND": "noninteractive",
            }


class ContainerManager:
    """
    Run the scanner in Docker with a fast path:
      - A cached derived image with python3-venv + your package in /opt/a11y/venv
      - Cache key = sha256(pyproject.toml + contents of src/)
    Fallback slow path (no cache):
      - apt-get python3-venv + pip install on each run

    Also supports running a long-lived API server (FastAPI+Uvicorn) in a container.
    """

    def __init__(
        self,
        project_root: Path | None = None,
        config: ContainerConfig | None = None,
    ):
        self.client = docker.from_env()
        self.project_root = (project_root or find_project_root()).resolve()
        self.config = config or ContainerConfig()

        # Detect Podman engine to avoid unsupported options (e.g., shm_size in host IPC)
        self._is_podman = False
        try:
            ver = self.client.version()
            comps = ver.get("Components") or []
            if any((c.get("Name") or "").lower().startswith("podman") for c in comps):
                self._is_podman = True
        except Exception:
            # Default to Docker-compatible behavior
            self._is_podman = False

        # Host paths
        self.repo_src = self.project_root
        self.data_dir = self.project_root / self.config.data_subdir

        # Container paths
        self.container_workdir = self.config.workdir
        self.container_repo_path = self.container_workdir  # bind repo here (ro)
        self.container_data_path = str(
            Path(self.container_workdir) / self.config.data_subdir
        )

    # ---------- generic helpers ----------

    def _host_uid_gid(self) -> tuple[int | None, int | None]:
        """Return (uid, gid) on Unix; (None, None) on Windows."""
        if platform.system().lower().startswith("win"):
            return (None, None)
        try:
            return (os.getuid(), os.getgid())
        except AttributeError:
            return (None, None)

    def _prepare_host_dirs(self) -> None:
        """
        Ensure host 'data' directory exists before binding it into the container.
        Sets permissive permissions to handle rootless Podman UID mapping.
        """
        self.data_dir.mkdir(parents=True, exist_ok=True)
        # Set 777 on data subdirectories for rootless container compatibility
        for subdir in ["scan", "results", "reports", "unzip", "live_results"]:
            path = self.data_dir / subdir
            path.mkdir(parents=True, exist_ok=True)
            try:
                path.chmod(0o777)
            except Exception:
                pass  # Best effort, continue if chmod fails

    def ensure_image(self) -> None:
        self.ensure_base_image()

    def _volumes(self) -> dict[str, dict[str, str]]:
        """
        Bind mount configuration.
        - repo: read-only at /worksrc (for data dir + visibility)
        - data: read-write at /worksrc/data for inputs/outputs
        """
        # On Podman (rootless + SELinux), require relabeling (":Z") for mounts
        repo_mode = "ro,Z" if self._is_podman else "ro"
        data_mode = "rw,Z" if self._is_podman else "rw"
        return {
            str(self.repo_src): {"bind": self.container_repo_path, "mode": repo_mode},
            str(self.data_dir): {"bind": self.container_data_path, "mode": data_mode},
        }

    def ensure_base_image(self) -> None:
        """Pull the base Playwright Python image if it is not present locally."""
        try:
            self.client.images.get(self.config.base_image)
        except docker.errors.ImageNotFound:
            print(f"[container] Pulling base image: {self.config.base_image}")
            self.client.images.pull(self.config.base_image)

    # ---------- cache key / image name ----------

    def _hash_file(self, path: Path, h: hashlib._Hash) -> None:
        with open(path, "rb") as fh:
            for chunk in iter(lambda: fh.read(1024 * 1024), b""):
                h.update(chunk)

    def _compute_cache_key(self) -> str:
        """
        Compute a stable key using pyproject.toml + src/ tree.
        If either changes, the cache invalidates.
        """
        h = hashlib.sha256()
        pyproject = self.project_root / "pyproject.toml"
        if pyproject.exists():
            self._hash_file(pyproject, h)

        src_root = self.project_root / "src"
        if src_root.exists():
            for p in sorted(src_root.rglob("*")):
                if p.is_file():
                    # skip compiled junk
                    if p.suffix in {".pyc", ".pyo"}:
                        continue
                    self._hash_file(p, h)

        return h.hexdigest()

    def _cached_image_ref(self) -> tuple[str, str, str]:
        """
        Return (repository, tag, full_ref) for the cache image.
        Example:
          repo='a11y-scanner-cache', tag='9f1a0c3d2a10',
          full='a11y-scanner-cache:9f1a0c3d2a10'
        """
        key = self._compute_cache_key()[:12]
        repo = CACHED_REPO_NAME
        tag = key
        return repo, tag, f"{repo}:{tag}"

    def cached_image_exists(self) -> bool:
        _, _, full = self._cached_image_ref()
        try:
            self.client.images.get(full)
            return True
        except docker.errors.ImageNotFound:
            return False

    # ---------- prepare cached image ----------

    def prepare_cached_image(self) -> str:
        """
        Build a derived image with:
          - python3-venv installed
          - your project installed into /opt/a11y/venv
        Returns the full image ref (e.g. a11y-scanner-cache:<sha12>).
        """
        self.ensure_base_image()
        self._prepare_host_dirs()

        repo, tag, full = self._cached_image_ref()
        print(f"[cache] Building cached image {full} ...")

        volumes = self._volumes()

        # Command to install venv + your package into /opt/a11y/venv
        # We copy /worksrc (ro) -> /tmp/src so pip can write metadata.
        cmd = (
            "bash -lc '"
            "set -euo pipefail;"
            "apt-get update -y && "
            "apt-get install -y --no-install-recommends python3-venv && "
            "rm -rf /var/lib/apt/lists/* && "
            "rm -rf /tmp/src && mkdir -p /tmp/src && "
            "cp -a /worksrc/. /tmp/src && rm -rf /tmp/src/data && "
            f"python3 -m venv {CACHED_VENV_PATH} && "
            f"{CACHED_VENV_PATH}/bin/pip install --no-cache-dir /tmp/src && "
            "true'"
        )

        # Run as root, we need apt-get and /opt writes
        run_kwargs = dict(
            command=cmd,
            working_dir=self.container_workdir,
            environment=self.config.env,
            user="root",
            volumes=volumes,
            detach=True,
            auto_remove=False,  # we will commit it
        )
        if not self._is_podman and self.config.shm_size:
            run_kwargs["shm_size"] = self.config.shm_size
        container = self.client.containers.run(self.config.base_image, **run_kwargs)

        # Stream logs
        try:
            for line in container.logs(stream=True, follow=True):
                sys.stdout.buffer.write(line)
                sys.stdout.flush()
        except KeyboardInterrupt:
            print("\n[cache] Interrupted; stopping container...")
            container.stop(timeout=5)

        status = container.wait()
        code = int(status.get("StatusCode", 1))
        if code != 0:
            logs = container.logs().decode("utf-8", errors="ignore")
            container.remove(force=True)
            raise RuntimeError(f"[cache] Prepare failed with exit code {code}\n{logs}")

        # Commit the prepared container as a new image
        print(f"[cache] Committing image: {full}")
        container.commit(repository=repo, tag=tag)
        container.remove()

        print(f"[cache] Cached image ready: {full}")
        return full

    # ---------- run (cached / uncached) ----------

    def _command_uncached(self, chown_uid: int | None, chown_gid: int | None) -> str:
        chown_clause = ""
        if chown_uid is not None and chown_gid is not None:
            chown_clause = f" && chown -R {chown_uid}:{chown_gid} /worksrc/data"

        # Install on every run (slow path)
        return (
            "bash -lc '"
            "set -euo pipefail;"
            "apt-get update -y && "
            "apt-get install -y --no-install-recommends python3-venv && "
            "python3 -m venv /tmp/venv && "
            "rm -rf /tmp/src && mkdir -p /tmp/src && "
            "cp -a /worksrc/. /tmp/src && rm -rf /tmp/src/data && "
            "/tmp/venv/bin/pip install --no-cache-dir /tmp/src && "
            "cd /worksrc && /tmp/venv/bin/python -m scanner.main"
            f"{chown_clause}"
            "'"
        )

    def _command_cached(self) -> str:
        # Use the preinstalled venv from the cached image
        return (
            f"bash -lc 'set -e; cd /worksrc; "
            f"{CACHED_VENV_PATH}/bin/python -m scanner.main'"
        )

    def _command_api_uncached(self) -> str:
        # Slow path for API server
        return (
            "bash -lc '"
            "set -euo pipefail;"
            "apt-get update -y && "
            "apt-get install -y --no-install-recommends python3-venv && "
            "python3 -m venv /tmp/venv && "
            "rm -rf /tmp/src && mkdir -p /tmp/src && "
            "cp -a /worksrc/. /tmp/src && rm -rf /tmp/src/data && "
            "/tmp/venv/bin/pip install --no-cache-dir /tmp/src && "
            "cd /worksrc && /tmp/venv/bin/python -m scanner.web.server'"
        )

    def _command_api_cached(self) -> str:
        # Cached path for API server
        return (
            f"bash -lc 'set -e; cd /worksrc; "
            f"{CACHED_VENV_PATH}/bin/python -m scanner.web.server'"
        )

    def run_scanner(
        self,
        use_cache: bool = True,
        rebuild_cache: bool = False,
        stream_logs: bool = True,
    ) -> int:
        """
        Run the scanner and return its exit code.
        - use_cache: prefer cached image; auto-build if missing or rebuild requested
        - rebuild_cache: force rebuild of cached image
        """
        self._prepare_host_dirs()

        if use_cache:
            if rebuild_cache or not self.cached_image_exists():
                self.prepare_cached_image()
            _, _, cached_ref = self._cached_image_ref()
            return self._run_with_image(
                cached_ref, cached=True, stream_logs=stream_logs
            )
        else:
            # Slow path: base image + apt-get + pip each run
            self.ensure_base_image()
            return self._run_with_image(
                self.config.base_image, cached=False, stream_logs=stream_logs
            )

    def _run_with_image(self, image_ref: str, cached: bool, stream_logs: bool) -> int:
        volumes = self._volumes()

        # Merge env + mark container context for the app guards.
        env = dict(self.config.env or {})
        env[IN_CONTAINER_ENV] = IN_CONTAINER_VALUE

        if cached:
            # Run as host uid:gid so result files are owned by you.
            uid, gid = self._host_uid_gid()
            user = f"{uid}:{gid}" if uid is not None and gid is not None else None
            command = self._command_cached()
        else:
            # Need root for apt-get on the slow path
            user = "root"
            command = self._command_uncached(None, None)

        print(f"[container] Starting scanner container (image: {image_ref})...")
        run_kwargs = dict(
            command=command,
            working_dir=self.container_workdir,
            environment=env,
            user=user,
            volumes=volumes,
            detach=True,
            auto_remove=False,
        )
        if not self._is_podman and self.config.shm_size:
            run_kwargs["shm_size"] = self.config.shm_size
        container = self.client.containers.run(image_ref, **run_kwargs)

        if stream_logs:
            try:
                for line in container.logs(stream=True, follow=True):
                    sys.stdout.buffer.write(line)
                    sys.stdout.flush()
            except KeyboardInterrupt:
                print("\n[container] Interrupted by user, stopping container...")
                container.stop(timeout=5)

        try:
            status = container.wait()
            code = int(status.get("StatusCode", 1))
        except Exception:
            # Some engines (e.g., Podman) may remove container early; fall back to 0
            code = 0
        finally:
            try:
                container.remove(force=True)
            except Exception:
                pass
        print(f"[container] Exit code: {code}")
        return code

    # ---------- API server (long-running) ----------

    def run_api_server(
        self,
        host_port: int = 8008,
        use_cache: bool = True,
        rebuild_cache: bool = False,
        stream_logs: bool = True,
    ) -> int:
        """
        Launch the FastAPI server inside a container and port-forward to host_port.
        Blocks until Ctrl+C. Returns the container exit code.
        """
        self._prepare_host_dirs()
        if use_cache:
            if rebuild_cache or not self.cached_image_exists():
                self.prepare_cached_image()
            _, _, cached_ref = self._cached_image_ref()
            return self._run_api_with_image(
                cached_ref,
                cached=True,
                host_port=host_port,
                stream_logs=stream_logs,
            )
        else:
            self.ensure_base_image()
            return self._run_api_with_image(
                self.config.base_image,
                cached=False,
                host_port=host_port,
                stream_logs=stream_logs,
            )

    def _run_api_with_image(
        self, image_ref: str, cached: bool, host_port: int, stream_logs: bool
    ) -> int:
        volumes = self._volumes()

        env = dict(self.config.env or {})
        env[IN_CONTAINER_ENV] = IN_CONTAINER_VALUE

        if cached:
            uid, gid = self._host_uid_gid()
            user = f"{uid}:{gid}" if uid is not None and gid is not None else None
            command = self._command_api_cached()
        else:
            user = "root"
            command = self._command_api_uncached()

        print(
            f"[container] Starting API server (image: {image_ref}) at http://127.0.0.1:{host_port}"
        )
        run_kwargs = dict(
            command=command,
            working_dir=self.container_workdir,
            environment=env,
            user=user,
            volumes=volumes,
            ports={"8008/tcp": host_port},
            detach=True,
            auto_remove=False,
        )
        if not self._is_podman and self.config.shm_size:
            run_kwargs["shm_size"] = self.config.shm_size
        container = self.client.containers.run(image_ref, **run_kwargs)

        if stream_logs:
            try:
                for line in container.logs(stream=True, follow=True):
                    sys.stdout.buffer.write(line)
                    sys.stdout.flush()
            except KeyboardInterrupt:
                print("\n[container] Stopping API server container...")
                try:
                    container.stop(timeout=5)
                except Exception:
                    pass

        try:
            status = container.wait()
            code = int(status.get("StatusCode", 1))
        except Exception:
            code = 0
        finally:
            try:
                container.remove(force=True)
            except Exception:
                pass
        print(f"[container] API server exit code: {code}")
        return code
```

</FILE>

---

<FILE path="src/scanner/container/runner.py">

```python
from __future__ import annotations

import argparse
import sys
from pathlib import Path

from .manager import ContainerManager


def main(argv: list[str] | None = None) -> int:
    parser = argparse.ArgumentParser(
        description="Run the a11y-scanner in a Playwright container using the Docker SDK (with caching)."
    )
    subparsers = parser.add_subparsers(dest="command", required=True)

    # prepare cache image
    prep = subparsers.add_parser(
        "prepare", help="Build or rebuild the cached image (python3-venv + deps)."
    )
    prep.add_argument(
        "--project-root",
        type=Path,
        default=None,
        help="Path to the project root (where pyproject.toml lives). Defaults to auto-discovery.",
    )

    # run scan (one-off)
    run = subparsers.add_parser(
        "run", help="Run a one-off scan (site.zip -> results) in a container."
    )
    run.add_argument(
        "--project-root",
        type=Path,
        default=None,
        help="Path to the project root (where pyproject.toml lives). Defaults to auto-discovery.",
    )
    run.add_argument(
        "--no-cache",
        action="store_true",
        help="Disable cache (run slow path: apt-get + pip every time).",
    )
    run.add_argument(
        "--rebuild-cache",
        action="store_true",
        help="Force rebuild of the cached image before running.",
    )

    # serve API (long-running)
    serve = subparsers.add_parser(
        "serve", help="Run the FastAPI server in a container and expose port 8008."
    )
    serve.add_argument(
        "--project-root",
        type=Path,
        default=None,
        help="Path to the project root (where pyproject.toml lives). Defaults to auto-discovery.",
    )
    serve.add_argument(
        "--port",
        type=int,
        default=8008,
        help="Host port to bind to the container's 8008/tcp (default: 8008).",
    )
    serve.add_argument(
        "--no-cache",
        action="store_true",
        help="Disable cache (run slow path: apt-get + pip every time).",
    )
    serve.add_argument(
        "--rebuild-cache",
        action="store_true",
        help="Force rebuild of the cached image before running.",
    )

    args = parser.parse_args(argv)

    if args.command == "prepare":
        mgr = ContainerManager(project_root=args.project_root)
        try:
            ref = mgr.prepare_cached_image()
            print(ref)
            return 0
        except Exception as e:
            print(f"ERROR: {e}", file=sys.stderr)
            return 1

    if args.command == "run":
        mgr = ContainerManager(project_root=args.project_root)
        try:
            return mgr.run_scanner(
                use_cache=not args.no_cache,
                rebuild_cache=args.rebuild_cache,
                stream_logs=True,
            )
        except Exception as e:
            print(f"ERROR: {e}", file=sys.stderr)
            return 1

    if args.command == "serve":
        mgr = ContainerManager(project_root=args.project_root)
        try:
            return mgr.run_api_server(
                host_port=args.port,
                use_cache=not args.no_cache,
                rebuild_cache=args.rebuild_cache,
                stream_logs=True,
            )
        except KeyboardInterrupt:
            print("\nInterrupted by user.")
            return 130
        except Exception as e:
            print(f"ERROR: {e}", file=sys.stderr)
            return 1

    parser.print_help()
    return 2


if __name__ == "__main__":
    sys.exit(main())
```

</FILE>

---

### Entering Directory: 'src/scanner/core/'

<FILE path="src/scanner/core/__init__.py">

```python
"""Core configuration and setup for a11y-scanner."""
```

</FILE>

---

<FILE path="src/scanner/core/logging_setup.py">

```python
import logging
import sys


def setup_logging(level=logging.INFO):
    """Configure logging with a consistent format."""
    logging.basicConfig(
        level=level,
        format="%(asctime)s [%(levelname)s] %(name)s - %(message)s",
        handlers=[
            logging.StreamHandler(sys.stdout),
        ],
    )
```

</FILE>

---

<FILE path="src/scanner/core/settings.py">

```python
import logging
from pathlib import Path

logger = logging.getLogger(__name__)
# Basic config in case logging wasn't set up earlier
if not logger.hasHandlers():
    logging.basicConfig(level=logging.INFO, format="%(levelname)s: %(message)s")


class Settings:
    """
    Configuration settings for the scanner application.
    Paths are derived relative to a base path. By default, this is the
    current working directory, making paths portable for CLI tools.
    """

    def __init__(self, root_path: Path | None = None):
        """
        Initializes settings.
        Args:
            root_path: An optional Path object. If provided, this path
                       is used as the base for deriving data directories.
                       If None (default), paths are generated relative to the
                       current working directory (e.g., 'data/scan').
        """
        if root_path is None:
            # Default to relative paths from the CWD. This is more robust for
            # external tools and container environments.
            self._base_path: Path = Path(".")
            logger.debug("Settings initialized using relative base path: '.'")
        else:
            # For tests or specific cases, use the provided path and resolve it.
            self._base_path: Path = root_path.resolve()
            logger.debug(
                "Settings initialized using provided base path: %s", self._base_path
            )

        self._data_dir: Path = self._base_path / "data"
        self._scan_dir: Path = self._data_dir / "scan"
        self._unzip_dir: Path = self._data_dir / "unzip"
        self._results_dir: Path = self._data_dir / "results"

        self._port: int = 8000

    @property
    def base_path(self) -> Path:
        """The base path used for deriving other paths."""
        return self._base_path

    @property
    def data_dir(self) -> Path:
        """Path to the main data directory."""
        return self._data_dir

    @property
    def scan_dir(self) -> Path:
        """Path to the directory for storing extracted scan files."""
        return self._scan_dir

    @property
    def unzip_dir(self) -> Path:
        """Path to the directory containing the zip file to be processed."""
        return self._unzip_dir

    @property
    def results_dir(self) -> Path:
        """Path to the directory for storing scan results."""
        return self._results_dir

    @property
    def port(self) -> int:
        """Port number (currently unused, potential future use)."""
        return self._port

    def __repr__(self):
        # Format paths nicely for representation using repr() for quotes
        return (
            "Settings(\n"
            f"  base_path={str(self.base_path)!r},\n"
            f"  data_dir={str(self.data_dir)!r},\n"
            f"  scan_dir={str(self.scan_dir)!r},\n"
            f"  unzip_dir={str(self.unzip_dir)!r},\n"
            f"  results_dir={str(self.results_dir)!r},\n"
            f"  port={self.port}\n"
            ")"
        )


if __name__ == "__main__":
    # Example usage
    settings = Settings()
```

</FILE>

---

### Entering Directory: 'src/scanner/reporting/'

<FILE path="src/scanner/reporting/__init__.py">

```python
"""Reporting module for a11y_scanner.

This module provides functionality to generate HTML reports from accessibility
scan results. The reports are generated using Jinja2 templates and include:
- Summary statistics
- Grouped violations by rule
- Screenshots of violations
- Links to raw JSON data

Main function:
- build_report: Generate HTML report from JSON scan results
"""

from .jinja_report import ReportModel, build_report, validate_report_json

__all__ = ["build_report", "validate_report_json", "ReportModel"]
```

</FILE>

---

<FILE path="src/scanner/reporting/jinja_report.py">

```python
from __future__ import annotations

import json
import logging
import os
import sys
from dataclasses import dataclass, field
from datetime import datetime, timezone
from pathlib import Path

from jinja2 import (
    ChoiceLoader,
    Environment,
    FileSystemLoader,
    PackageLoader,
    TemplateNotFound,
    select_autoescape,
)

logger = logging.getLogger(__name__)


@dataclass
class Occurrence:
    url: str

    source_file: str | None

    selector: str | None

    html_snippet: str | None

    screenshot_path: str | Path | None

    screenshot_filename: str | None = None

    def __post_init__(self):
        """Extract filename from screenshot_path for template use"""

        if self.screenshot_path:
            try:
                self.screenshot_filename = Path(self.screenshot_path).name

            except Exception:
                self.screenshot_filename = str(self.screenshot_path)


@dataclass
class RuleGroup:
    id: str

    impact: str | None = None

    description: str | None = None

    help: str | None = None

    helpUrl: str | None = None

    count: int = 0

    occurrences: list[Occurrence] = field(default_factory=list)

    @property
    def impact_class(self) -> str:
        """Return CSS class based on impact level"""

        if not self.impact:
            return "impact-unknown"

        return f"impact-{self.impact.lower()}"


@dataclass
class ReportModel:
    title: str

    generated_at: str

    pages_scanned: int

    total_violations: int

    by_rule: list[RuleGroup]

    raw_files: list[str]

    def validate(self) -> bool:
        """Validate the report model has reasonable values"""

        if self.pages_scanned < 0:
            return False

        if self.total_violations < 0:
            return False

        if len(self.by_rule) > 0 and self.total_violations == 0:
            return False

        return True


def _iter_reports(results_dir: Path):
    """Generator that yields filename and parsed JSON for each report file"""

    if not results_dir.exists():
        logger.warning("Results directory does not exist: %s", results_dir)

        return

    for p in sorted(results_dir.glob("*.json")):
        try:
            with p.open("r", encoding="utf-8") as f:
                data = json.load(f)

                yield p.name, data

        except json.JSONDecodeError as e:
            logger.error("Invalid JSON in %s: %s", p, e)

            continue

        except Exception as e:
            logger.error("Error reading %s: %s", p, e)

            continue


def _impact_sort_key(impact: str | None, rule_id: str) -> tuple:
    """Sort key for rule groups: critical > serious > moderate > minor > unknown"""

    impact_order = {
        "critical": 0,
        "serious": 1,
        "moderate": 2,
        "minor": 3,
        "unknown": 4,
        None: 5,
    }

    return (impact_order.get(impact.lower() if impact else None, 5), rule_id)


def _build_model(results_dir: Path, title: str) -> ReportModel:
    """Build the report model from JSON files in the results directory"""

    groups: dict[str, RuleGroup] = {}

    pages_scanned = 0

    total_violations = 0

    raw_files: list[str] = []

    for fname, report in _iter_reports(results_dir):
        raw_files.append(fname)

        pages_scanned += 1

        violations = (report or {}).get("violations", [])

        for v in violations:
            total_violations += 1

            rid = v.get("id") or "unknown"

            # Create or get existing rule group

            if rid not in groups:
                groups[rid] = RuleGroup(
                    id=rid,
                    impact=v.get("impact"),
                    description=v.get("description"),
                    help=v.get("help"),
                    helpUrl=v.get("helpUrl"),
                )

            grp = groups[rid]

            # Extract violation details

            selector = None

            html_snippet = None

            nodes = v.get("nodes") or []

            if nodes:
                n0 = nodes[0]

                target = n0.get("target") or []

                selector = target[0] if len(target) > 0 else None

                html_snippet = n0.get("html")

            # Get source_file from report if available

            source_file = None

            if "source_file" in report:
                source_file = report["source_file"]

            elif "scanned_url" in report and "file://" in str(report["scanned_url"]):
                # Try to extract filename from file:// URL

                try:
                    url_parts = str(report["scanned_url"]).split("file://")[-1]

                    source_file = Path(url_parts).name

                except Exception:
                    source_file = None

            # Create occurrence with screenshot handling

            screenshot_path = v.get("screenshot_path")

            occ = Occurrence(
                url=report.get("scanned_url") or report.get("url") or "",
                source_file=source_file,
                selector=selector,
                html_snippet=html_snippet,
                screenshot_path=screenshot_path,
            )

            grp.count += 1

            grp.occurrences.append(occ)

    # Sort rule groups by impact (critical first) then by ID

    sorted_groups = sorted(
        groups.values(), key=lambda g: _impact_sort_key(g.impact, g.id)
    )

    model = ReportModel(
        title=title,
        generated_at=datetime.now(timezone.utc).strftime("%Y-%m-%d %H:%M:%SZ"),
        pages_scanned=pages_scanned,
        total_violations=total_violations,
        by_rule=sorted_groups,
        raw_files=raw_files,
    )

    return model


def _get_jinja_env() -> Environment:
    """

    Create a Jinja environment that works both when installed as a package

    and when running from a source checkout.

    """

    # Source-tree templates path: scanner/templates

    src_templates_dir = Path(__file__).resolve().parent.parent / "templates"

    loader = ChoiceLoader(
        [
            # Prefer installed package resources (editable or built installs)
            PackageLoader("scanner", "templates"),
            # Fallback to filesystem loader in a source tree
            FileSystemLoader(str(src_templates_dir)),
        ]
    )

    env = Environment(
        loader=loader,
        autoescape=select_autoescape(["html", "xml"]),
        trim_blocks=True,
        lstrip_blocks=True,
    )

    return env


def build_report(
    results_dir: Path,
    output_html: Path,
    title: str = "Accessibility Report",
    overwrite: bool = True,
) -> Path:
    """Aggregate JSON artifacts in ``results_dir`` and render a single HTML report.


    Args:

        results_dir: Directory containing JSON scan results

        output_html: Path where HTML report will be saved

        title: Title for the report

        overwrite: Whether to overwrite existing report (default: True)


    Returns:

        Path to the generated HTML report


    Raises:

        FileNotFoundError: If template cannot be found

        PermissionError: If cannot write to output path

        RuntimeError: If report generation fails

    """

    if not overwrite and output_html.exists():
        logger.info(
            "Report already exists and overwrite=False, skipping: %s", output_html
        )

        return output_html

    results_dir = results_dir.resolve()

    output_html.parent.mkdir(parents=True, exist_ok=True)

    try:
        model = _build_model(results_dir, title)

        # Validate model

        if not model.validate():
            logger.warning("Generated report model failed validation")

        # Set up Jinja2 environment

        env = _get_jinja_env()

        # Load template

        try:
            tpl = env.get_template("a11y_report.html.j2")

        except TemplateNotFound as e:
            raise FileNotFoundError(f"Template not found: {e}") from e

        # Render template
        # Compute a relative web path from the report file location to the results directory
        # so screenshots work when opening the report directly from the filesystem
        # (e.g., file:///.../data/reports/latest.html -> ../results/*).
        base_dir = output_html.parent.resolve()
        rel = os.path.relpath(results_dir, base_dir)
        # Normalize to POSIX-style separators for browsers
        results_web_base = rel.replace(os.sep, "/")

        html = tpl.render(model=model, results_web_base=results_web_base)

        # Write to file

        try:
            output_html.write_text(html, encoding="utf-8")

            logger.info("HTML report generated: %s", output_html)

        except PermissionError as e:
            raise PermissionError(f"Cannot write to {output_html}: {e}") from e

        except Exception as e:
            raise RuntimeError(f"Failed to write report: {e}") from e

        return output_html

    except Exception as e:
        logger.error("Failed to build report: %s", e)

        raise RuntimeError(f"Report generation failed: {e}") from e


def validate_report_json(json_path: Path) -> bool:
    """Validate that a JSON file has the expected structure for reporting"""

    try:
        with open(json_path, encoding="utf-8") as f:
            data = json.load(f)

        # Check for required fields

        if not isinstance(data, dict):
            return False

        # Should have either violations array or be empty

        if "violations" in data and not isinstance(data["violations"], list):
            return False

        # Should have URL info

        if "scanned_url" not in data and "url" not in data:
            return False

        return True

    except Exception:
        return False


if __name__ == "__main__":
    # Manual debug: build a report from ./data/results into ./data/reports/latest.html

    logging.basicConfig(level=logging.INFO)

    base = Path(".")

    results_dir = base / "data" / "results"

    out = base / "data" / "reports" / "latest.html"

    if not results_dir.exists() or not any(results_dir.glob("*.json")):
        print(f"Warning: No JSON files found in {results_dir}")

    try:
        result_path = build_report(results_dir, out)

        print(f"✅ Report successfully generated: {result_path}")

    except Exception as e:
        print(f"❌ Report generation failed: {e}")

        sys.exit(1)
```

</FILE>

---

### Entering Directory: 'src/scanner/services/'

<FILE path="src/scanner/services/__init__.py">

```python
"""Service layer for a11y-scanner."""
```

</FILE>

---

<FILE path="src/scanner/services/html_discovery_service.py">

```python
# src/scanner/services/html_discovery_service.py
import logging
from pathlib import Path

logger = logging.getLogger(__name__)


class HtmlDiscoveryService:
    """Service that discovers HTML files under a given directory."""

    def __init__(self, scan_dir: Path):
        if not isinstance(scan_dir, Path):
            raise TypeError("scan_dir must be a Path object")
        self.scan_dir = scan_dir
        logger.debug(
            "HtmlDiscoveryService initialized with scan_dir: %s",
            self.scan_dir,
        )

    def discover_html_files(self) -> list[dict[str, Path]]:
        """Recursively discover all HTML files relative to scan_dir."""
        logger.info(
            "Recursively discovering HTML files in: %s",
            self.scan_dir,
        )
        if not self.scan_dir.is_dir():
            logger.error(
                "Scan directory does not exist or is not a directory: %s",
                self.scan_dir,
            )
            return []

        html_paths: list[dict[str, Path]] = []
        for pattern in ("*.html", "*.htm"):
            for abs_path in self.scan_dir.rglob(pattern):
                if not abs_path.is_file():
                    continue

                try:
                    relative_path = abs_path.relative_to(self.scan_dir)
                    entry = {
                        "absolute": abs_path.resolve(),
                        "relative": relative_path,
                    }
                    html_paths.append(entry)
                    logger.debug(
                        "Found HTML: Rel=%s,\nAbs=%s",
                        relative_path,
                        abs_path.resolve(),
                    )
                except ValueError:
                    logger.warning(
                        "Could not determine relative path\nfor %s against base %s. "
                        "Skipping.",
                        abs_path,
                        self.scan_dir,
                    )

        count = len(html_paths)
        logger.info(
            "Found %d HTML file(s) in %s",
            count,
            self.scan_dir,
        )

        if count:
            sample_limit = 5
            sample = [str(e["relative"]) for e in html_paths[:sample_limit]]
            logger.debug("Sample relative paths: %s", sample)

            if count > sample_limit:
                logger.debug(
                    "... and %d more.",
                    count - sample_limit,
                )

        return html_paths
```

</FILE>

---

<FILE path="src/scanner/services/http_service.py">

```python
# src/scanner/services/http_service.py
import http.server
import logging
import socket
import threading
from pathlib import Path

logger = logging.getLogger(__name__)


class Handler(http.server.SimpleHTTPRequestHandler):
    """A request handler that serves files from a specific directory."""

    def __init__(self, *args, directory: Path, **kwargs) -> None:
        # The directory argument is mandatory for our use case
        super().__init__(*args, directory=str(directory), **kwargs)


class HttpService:
    """A service to manage a simple, local HTTP server in a background thread."""

    def __init__(self):
        self._server: http.server.ThreadingHTTPServer | None = None
        self._thread: threading.Thread | None = None
        self.host = "localhost"
        self.port = 0  # Port 0 means the OS will pick an available port
        self.base_url = ""

    def start(self, directory: Path):
        """Starts the HTTP server in a background thread."""
        if self._server:
            logger.warning("Server is already running. Ignoring start request.")
            return

        # Use a context manager to find a free port
        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
            s.bind((self.host, 0))
            self.port = s.getsockname()[1]  # Get the port assigned by the OS
            logger.info("Found available port: %d", self.port)

        self.base_url = f"http://{self.host}:{self.port}"

        # The handler needs the directory to serve from. functools.partial is
        # a clean way to pass the 'directory' argument to the Handler's constructor.
        def handler_factory(*args, **kwargs):
            return Handler(*args, directory=directory, **kwargs)

        self._server = http.server.ThreadingHTTPServer(
            (self.host, self.port), handler_factory
        )

        self._thread = threading.Thread(target=self._server.serve_forever, daemon=True)
        self._thread.start()
        logger.info(
            "HTTP server started at %s, serving files from %s",
            self.base_url,
            directory,
        )

    def stop(self):
        """Stops the HTTP server and waits for the thread to join."""
        if self._server and self._thread:
            logger.info("Shutting down HTTP server...")
            self._server.shutdown()
            self._thread.join(timeout=5)  # Wait for the thread to finish
            if self._thread.is_alive():
                logger.error("Server thread did not shut down cleanly.")
            self._server.server_close()
            logger.info("HTTP server shut down.")
        self._server = None
        self._thread = None
        self.base_url = ""
```

</FILE>

---

<FILE path="src/scanner/services/playwright_axe_service.py">

```python
import json
import logging
import os
import uuid
from pathlib import Path
from typing import Any

from axe_playwright_python.sync_playwright import Axe
from playwright.sync_api import Browser, BrowserContext, Page, sync_playwright

from scanner.utils import sanitize_for_json

logger = logging.getLogger(__name__)


class PlaywrightAxeService:
    """
    Runs axe-core audits against pages using Playwright.
    Now safer against selector injection and supports disabling screenshots via env:
      - Set A11Y_NO_SCREENSHOTS=1 to skip screenshot capture.
    """

    def __init__(self):
        self._playwright = None
        self._browser: Browser | None = None
        self._context: BrowserContext | None = None
        self._managed = False
        # Feature flag: allow disabling screenshots in sensitive environments
        self._screenshots_enabled = os.environ.get("A11Y_NO_SCREENSHOTS", "0") != "1"

    def __enter__(self):
        self.start()
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        self.stop()

    def start(self):
        if self._browser is not None:
            logger.warning("Browser already started, ignoring start() call")
            return
        logger.info("Starting managed Playwright browser (reusable mode)")
        self._playwright = sync_playwright().start()
        self._browser = self._playwright.chromium.launch(headless=True)
        self._context = self._browser.new_context(
            viewport={"width": 1280, "height": 720}
        )
        self._managed = True
        logger.info("Playwright browser started successfully")

    def stop(self):
        if self._context:
            self._context.close()
            self._context = None
        if self._browser:
            self._browser.close()
            self._browser = None
        if self._playwright:
            self._playwright.stop()
            self._playwright = None
        self._managed = False
        logger.info("Playwright browser stopped")

    def _capture_violation_screenshot(
        self, page: Page, violation: dict[str, Any], results_dir: Path
    ) -> str | None:
        """
        Capture a screenshot with intelligent RGB-inverse highlighting.

        Strategy:
        1. Locate element and get its average background color
        2. Calculate RGB inverse for maximum contrast
        3. Apply obnoxious multi-layer highlighting in inverse color
        4. Capture with intelligent sizing (min 200px width, context padding)
        5. Fall back to viewport screenshot if element capture fails
        """
        if not self._screenshots_enabled:
            return None

        nodes = violation.get("nodes", [])
        if not nodes:
            return None
        node = nodes[0]
        targets = node.get("target", [])
        if not targets:
            return None

        selector = targets[0]
        screenshot_filename = f"violation-{violation['id']}-{uuid.uuid4()}.png"
        screenshot_path = results_dir / screenshot_filename

        try:
            locator = page.locator(selector).first

            # Scroll element into view
            try:
                locator.scroll_into_view_if_needed(timeout=2000)
            except Exception:
                pass  # Continue even if scroll fails

            # Choose a maximally-visible highlight color based on element's brightness
            try:
                avg_brightness = locator.evaluate("""
                    (el) => {
                        const styles = window.getComputedStyle(el);
                        const bgColor = styles.backgroundColor;

                        // Parse RGB from computed style
                        const match = bgColor.match(/rgba?\\((\\d+),\\s*(\\d+),\\s*(\\d+)/);
                        if (!match) return 128;

                        const r = parseInt(match[1]);
                        const g = parseInt(match[2]);
                        const b = parseInt(match[3]);

                        // Calculate perceived brightness (0-255)
                        return (r * 0.299 + g * 0.587 + b * 0.114);
                    }
                """)

                # Choose OBNOXIOUS color based on brightness
                if avg_brightness > 128:
                    # Light background → Use dark, saturated color
                    highlight_color = "rgb(255, 0, 255)"  # Bright magenta
                else:
                    # Dark background → Use bright, saturated color
                    highlight_color = "rgb(0, 255, 255)"  # Bright cyan

            except Exception:
                # Fallback to bright magenta
                highlight_color = "rgb(255, 0, 255)"

            # Apply OBNOXIOUS multi-layer highlighting
            locator.evaluate(f"""
                (el) => {{
                    const highlightColor = '{highlight_color}';

                    // Multi-layer obnoxious highlighting
                    el.style.outline = `8px solid ${{highlightColor}}`;
                    el.style.outlineOffset = '4px';
                    el.style.boxShadow = `
                        0 0 0 12px ${{highlightColor}}40,
                        0 0 0 16px ${{highlightColor}}30,
                        0 0 30px 10px ${{highlightColor}}60,
                        inset 0 0 0 3px ${{highlightColor}}
                    `;
                    el.style.position = 'relative';
                    el.style.zIndex = '999999';

                    // Add pulsing animation for extra obnoxiousness
                    el.style.animation = 'a11y-pulse 1s ease-in-out infinite';

                    // Inject animation keyframes
                    if (!document.getElementById('a11y-highlight-style')) {{
                        const style = document.createElement('style');
                        style.id = 'a11y-highlight-style';
                        style.textContent = `
                            @keyframes a11y-pulse {{
                                0%, 100% {{ filter: brightness(1); }}
                                50% {{ filter: brightness(1.3); }}
                            }}
                        `;
                        document.head.appendChild(style);
                    }}
                }}
            """)

            # Wait for styling to apply and animation to start
            page.wait_for_timeout(300)

            # Intelligent screenshot sizing
            try:
                # Get element bounding box
                box = locator.bounding_box()
                if box:
                    # Ensure minimum dimensions with generous padding for highlights
                    min_width = 300
                    min_height = 150
                    # Large padding to capture outline (12px) + box-shadow glow (30px) + context (60px)
                    padding = 100

                    # Calculate capture area with padding
                    width = max(box["width"] + padding * 2, min_width)
                    height = max(box["height"] + padding * 2, min_height)

                    # Center the element in the capture
                    x = max(0, box["x"] - padding)
                    y = max(0, box["y"] - padding)

                    # Use viewport clip for better context
                    page.screenshot(
                        path=str(screenshot_path),
                        clip={"x": x, "y": y, "width": width, "height": height}
                    )
                else:
                    # Fallback to element screenshot
                    locator.screenshot(path=str(screenshot_path))

                logger.info(
                    "Captured highlighted screenshot for violation '%s' (highlight color: %s) at %s",
                    violation["id"],
                    highlight_color,
                    screenshot_path,
                )
                return str(screenshot_path)

            except Exception as element_error:
                logger.debug(
                    "Element screenshot failed for '%s', using viewport: %s",
                    selector,
                    element_error,
                )
                # Try viewport screenshot
                page.screenshot(path=str(screenshot_path), full_page=False)
                logger.info(
                    "Captured viewport screenshot for violation '%s' at %s",
                    violation["id"],
                    screenshot_path,
                )
                return str(screenshot_path)

        except Exception as e:
            logger.error(
                "Failed to capture screenshot for selector '%s': %s",
                selector, e
            )
            return None

    def scan_url(
        self, url: str, output_path: Path, source_file: str | None = None
    ) -> list[dict[str, Any]]:
        logger.info("Scanning %s with axe-playwright-python", url)
        axe = Axe()
        results_dir = output_path.parent
        results_dir.mkdir(parents=True, exist_ok=True)

        if self._managed and self._context:
            page = self._context.new_page()
            try:
                violations = self._scan_page(
                    page, url, output_path, source_file, axe, results_dir
                )
            finally:
                page.close()
        else:
            with sync_playwright() as p:
                browser = p.chromium.launch(headless=True)
                context = browser.new_context(viewport={"width": 1280, "height": 720})
                page = context.new_page()
                try:
                    violations = self._scan_page(
                        page, url, output_path, source_file, axe, results_dir
                    )
                finally:
                    browser.close()

        return violations

    def _scan_page(
        self,
        page: Page,
        url: str,
        output_path: Path,
        source_file: str | None,
        axe: Axe,
        results_dir: Path,
    ) -> list[dict[str, Any]]:
        page.goto(url, wait_until="networkidle")
        results = axe.run(page)
        violations = results.response.get("violations", [])
        if violations:
            logger.warning(
                "Found %d accessibility violations at %s", len(violations), url
            )
            for violation in violations:
                screenshot_path = self._capture_violation_screenshot(
                    page, violation, results_dir
                )
                violation["screenshot_path"] = screenshot_path
        else:
            logger.info("No accessibility violations found at %s", url)

        full_report = sanitize_for_json(dict(results.response))
        full_report["scanned_url"] = url
        if source_file:
            full_report["source_file"] = source_file

        with open(output_path, "w", encoding="utf-8") as f:
            json.dump(full_report, f, indent=2)

        logger.info("Full scan report saved to %s", output_path)
        return violations
```

</FILE>

---

<FILE path="src/scanner/services/zip_service.py">

```python
import logging
import os
import sys
from pathlib import Path
from zipfile import ZipFile

logger = logging.getLogger(__name__)


class ZipService:
    """Service to detect a single .zip in a directory and extract it."""

    def __init__(self, *, unzip_dir: Path, scan_dir: Path):
        """
        Args:
            unzip_dir: Directory to search for zip files.
            scan_dir: Directory where zip contents will be extracted.
        """
        self.unzip_dir = unzip_dir
        self.scan_dir = scan_dir

    def detect_zip(self) -> Path:
        """Search unzip_dir for a .zip file and return its Path."""
        logger.info("Checking %s for any valid zip files", self.unzip_dir)
        zips = list(self.unzip_dir.glob("*.zip"))
        logger.info("Found the following zip(s): %s", zips)

        if not zips:
            raise FileNotFoundError(f"No zip files found in {self.unzip_dir}")

        zip_path = zips[0]
        logger.info("Zip file detected: %s", zip_path)
        return zip_path

    def _is_safe_path(self, base_path: Path, target_path: Path) -> bool:
        """
        Check if target_path is safe to extract (prevents Zip Slip).
        Returns False if the path tries to escape the base directory.
        """
        try:
            # Resolve both paths to absolute, normalized forms
            base_abs = base_path.resolve()
            target_abs = target_path.resolve()

            # Check if target is within base (common_path should equal base)
            common = Path(os.path.commonpath([base_abs, target_abs]))
            return common == base_abs
        except (ValueError, OSError):
            return False

    def _sanitize_archive_member(self, member_name: str) -> str | None:
        """
        Sanitize a zip member name, rejecting dangerous paths.
        Returns None if the member should be skipped.
        """
        # Reject absolute paths
        if os.path.isabs(member_name):
            logger.warning("Rejecting absolute path in archive: %s", member_name)
            return None

        # Reject paths with parent directory references
        if ".." in Path(member_name).parts:
            logger.warning("Rejecting path with '..' in archive: %s", member_name)
            return None

        # Normalize the path
        normalized = os.path.normpath(member_name)

        # Double-check no traversal after normalization
        if normalized.startswith("..") or os.path.isabs(normalized):
            logger.warning("Rejecting unsafe normalized path: %s", normalized)
            return None

        return normalized

    def unzip(self, zip_path: Path, destination: Path) -> None:
        """
        Extract zip_path into the destination directory with Zip Slip protection.
        Only extracts members with safe, relative paths.
        """
        logger.info("Attempting extraction of %s to %s", zip_path, destination)

        # Ensure destination directory exists
        destination.mkdir(parents=True, exist_ok=True)

        try:
            with ZipFile(zip_path, "r") as archive:
                file_list = archive.namelist()
                logger.debug(
                    "Zip contains %d files/directories",
                    len(file_list),
                )

                # Safe extraction with path validation
                extracted_count = 0
                skipped_count = 0

                for member in archive.infolist():
                    # Sanitize the member name
                    safe_name = self._sanitize_archive_member(member.filename)
                    if safe_name is None:
                        skipped_count += 1
                        continue

                    # Compute the target path
                    target_path = destination / safe_name

                    # Verify it's within the destination (double-check)
                    if not self._is_safe_path(destination, target_path):
                        logger.warning(
                            "Rejecting path that escapes destination: %s",
                            member.filename,
                        )
                        skipped_count += 1
                        continue

                    # Extract the member
                    if member.is_dir():
                        target_path.mkdir(parents=True, exist_ok=True)
                    else:
                        # Ensure parent directory exists
                        target_path.parent.mkdir(parents=True, exist_ok=True)

                        # Extract file content
                        with archive.open(member) as source:
                            content = source.read()
                            target_path.write_bytes(content)

                    extracted_count += 1

                logger.info(
                    "Extraction completed: %d files extracted, %d skipped",
                    extracted_count,
                    skipped_count,
                )

                if skipped_count > 0:
                    logger.warning(
                        "%d files were skipped due to unsafe paths", skipped_count
                    )

                dirs = [n for n in file_list if n.endswith("/")]
                if dirs:
                    logger.debug(
                        "Zip contains %d directories: %s",
                        len(dirs),
                        dirs[:5],
                    )
        except OSError as error:
            raise RuntimeError(f"Failed to extract {zip_path}") from error

    def run(self) -> None:
        """Detect a zip, unzip it, and log the extracted items."""
        try:
            zip_path = self.detect_zip()
            self.unzip(zip_path, self.scan_dir)

            extracted_items = list(self.scan_dir.glob("**/*"))
            logger.info(
                "Extracted %d items to %s",
                len(extracted_items),
                self.scan_dir,
            )

            for extracted in extracted_items[:10]:
                logger.info("Extracted item: %s", extracted)

            if not any(self.scan_dir.iterdir()):
                raise RuntimeError("Extraction resulted in empty directory")
        except FileNotFoundError as fnf:
            logger.error("No zip found: %s", fnf)
            raise
        except Exception as error:
            logger.error("Zip extraction failed: %s", error)
            raise


if __name__ == "__main__":
    # Standalone invocation for testing/development
    from scanner.core.logging_setup import setup_logging
    from scanner.core.settings import Settings

    setup_logging()
    settings = Settings()

    logger.info("Running ZipService in standalone mode")
    logger.info("Settings: %s", settings)

    service = ZipService(
        unzip_dir=settings.unzip_dir,
        scan_dir=settings.scan_dir,
    )

    try:
        service.run()
        for path in settings.scan_dir.iterdir():
            logger.info("Extracted: %s", path)
        sys.exit(0)
    except Exception as error:
        logger.error("ZipService failed: %s", error)
        sys.exit(1)
```

</FILE>

---

### Entering Directory: 'src/scanner/templates/'

<FILE path="src/scanner/templates/__init__.py">

```python
# empty
```

</FILE>

---

<FILE path="src/scanner/templates/a11y_report.html.j2">

```
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <title>{{ model.title }}</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <style>
    :root {
      --bg: #0a0e1a;
      --bg-gradient: radial-gradient(ellipse 1400px 900px at 50% 0%, #0f1828 0%, #0a0e1a 60%);
      --panel: #0f1419;
      --card: #0d1117;
      --card-hover: #161b22;
      --text: #e6edf3;
      --text-secondary: #7d8590;
      --text-muted: #6e7681;
      --accent: #58a6ff;
      --accent-muted: #1f6feb;
      --ok: #3fb950;
      --warn: #d29922;
      --bad: #f85149;
      --critical: #ff4444;
      --serious: #ff8c00;
      --moderate: #ffa500;
      --minor: #ffd700;
      --border: #21262d;
      --border-muted: #30363d;
      --code-bg: #0d1117;
      --code-border: #21262d;
      --shadow: rgba(1,4,9,0.5);
    }

    * { box-sizing: border-box; margin: 0; padding: 0; }

    body {
      font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", "Noto Sans", Helvetica, Arial, sans-serif, "Apple Color Emoji", "Segoe UI Emoji";
      background: var(--bg);
      background-image: var(--bg-gradient);
      background-attachment: fixed;
      color: var(--text);
      line-height: 1.6;
      padding: 1.5rem;
      min-height: 100vh;
    }

    .container {
      max-width: 1200px;
      margin: 0 auto;
    }

    header {
      background: var(--card);
      border: 1px solid var(--border);
      border-radius: 12px;
      padding: 2rem;
      margin-bottom: 1.5rem;
      box-shadow: 0 8px 32px var(--shadow);
      position: sticky;
      top: 1rem;
      z-index: 100;
      backdrop-filter: blur(12px);
      background: rgba(13, 17, 23, 0.95);
    }

    h1 {
      font-size: 2rem;
      font-weight: 600;
      margin-bottom: 0.5rem;
      color: var(--text);
      letter-spacing: -0.03em;
    }

    .meta {
      color: var(--text-muted);
      font-size: 0.875rem;
    }

    .card {
      background: var(--card);
      border: 1px solid var(--border);
      border-radius: 12px;
      padding: 1.5rem;
      margin-bottom: 1.5rem;
      box-shadow: 0 4px 16px var(--shadow);
    }

    .section-title {
      font-size: 1.25rem;
      font-weight: 600;
      color: var(--accent);
      margin-bottom: 1.25rem;
      padding-bottom: 0.75rem;
      border-bottom: 1px solid var(--border);
    }

    .summary {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
      gap: 1rem;
    }

    .kpi {
      background: var(--panel);
      border: 1px solid var(--border-muted);
      border-radius: 10px;
      padding: 1.25rem;
      transition: all 0.2s ease;
    }

    .kpi:hover {
      border-color: var(--accent-muted);
      transform: translateY(-2px);
      box-shadow: 0 4px 12px rgba(88, 166, 255, 0.1);
    }

    .kpi .label {
      color: var(--text-secondary);
      font-size: 0.875rem;
      font-weight: 500;
      margin-bottom: 0.5rem;
      text-transform: uppercase;
      letter-spacing: 0.05em;
    }

    .kpi .value {
      font-size: 2.5rem;
      font-weight: 700;
      line-height: 1;
    }

    .status-ok { color: var(--ok); }
    .status-warn { color: var(--warn); }
    .status-bad { color: var(--bad); }

    .raw-files {
      margin-top: 1.5rem;
      padding-top: 1.5rem;
      border-top: 1px solid var(--border);
    }

    .raw-files-title {
      font-size: 0.875rem;
      font-weight: 600;
      color: var(--text-secondary);
      margin-bottom: 0.75rem;
      text-transform: uppercase;
      letter-spacing: 0.05em;
    }

    .raw-list {
      display: flex;
      flex-wrap: wrap;
      gap: 0.5rem;
    }

    .raw-list a {
      display: inline-flex;
      align-items: center;
      background: var(--panel);
      border: 1px solid var(--border-muted);
      color: var(--accent);
      padding: 0.375rem 0.75rem;
      border-radius: 6px;
      font-size: 0.8125rem;
      font-family: ui-monospace, SFMono-Regular, "SF Mono", Menlo, Consolas, "Liberation Mono", monospace;
      text-decoration: none;
      transition: all 0.15s ease;
    }

    .raw-list a:hover {
      background: var(--card-hover);
      border-color: var(--accent);
    }

    .rules {
      display: grid;
      gap: 1.25rem;
    }

    .rule {
      background: var(--panel);
      border: 2px solid var(--border);
      border-radius: 10px;
      padding: 1.5rem;
      transition: all 0.2s ease;
    }

    .rule:hover {
      box-shadow: 0 4px 16px rgba(0, 0, 0, 0.3);
    }

    .impact-critical {
      border-left: 4px solid var(--critical);
    }

    .impact-serious {
      border-left: 4px solid var(--serious);
    }

    .impact-moderate {
      border-left: 4px solid var(--moderate);
    }

    .impact-minor {
      border-left: 4px solid var(--minor);
    }

    .rule-header {
      display: flex;
      align-items: center;
      gap: 0.75rem;
      flex-wrap: wrap;
      margin-bottom: 1rem;
    }

    .rule-id {
      font-size: 1.125rem;
      font-weight: 600;
      color: var(--text);
      font-family: ui-monospace, SFMono-Regular, "SF Mono", Menlo, Consolas, "Liberation Mono", monospace;
    }

    .badge {
      display: inline-flex;
      align-items: center;
      padding: 0.25rem 0.75rem;
      border-radius: 6px;
      font-size: 0.75rem;
      font-weight: 600;
      text-transform: uppercase;
      letter-spacing: 0.05em;
    }

    .badge-impact {
      background: rgba(248, 113, 113, 0.15);
      color: var(--bad);
      border: 1px solid rgba(248, 113, 113, 0.3);
    }

    .impact-critical .badge-impact {
      background: rgba(255, 68, 68, 0.15);
      color: var(--critical);
      border: 1px solid rgba(255, 68, 68, 0.4);
    }

    .impact-serious .badge-impact {
      background: rgba(255, 140, 0, 0.15);
      color: var(--serious);
      border: 1px solid rgba(255, 140, 0, 0.3);
    }

    .impact-moderate .badge-impact {
      background: rgba(255, 165, 0, 0.15);
      color: var(--moderate);
      border: 1px solid rgba(255, 165, 0, 0.3);
    }

    .impact-minor .badge-impact {
      background: rgba(255, 215, 0, 0.15);
      color: var(--minor);
      border: 1px solid rgba(255, 215, 0, 0.3);
    }

    .badge-count {
      background: rgba(88, 166, 255, 0.15);
      color: var(--accent);
      border: 1px solid rgba(88, 166, 255, 0.3);
    }

    .badge-link {
      background: rgba(88, 166, 255, 0.1);
      color: var(--accent);
      border: 1px solid var(--border-muted);
      text-decoration: none;
      transition: all 0.15s ease;
    }

    .badge-link:hover {
      background: rgba(88, 166, 255, 0.2);
      border-color: var(--accent);
    }

    .rule-desc {
      color: var(--text-secondary);
      margin-bottom: 1.25rem;
      line-height: 1.6;
    }

    .occ-list {
      display: grid;
      gap: 1rem;
    }

    .occ {
      background: var(--card);
      border: 1px solid var(--border-muted);
      border-radius: 8px;
      padding: 1rem;
    }

    .occ-meta {
      display: flex;
      flex-direction: column;
      gap: 0.5rem;
      margin-bottom: 0.75rem;
    }

    .occ-meta-row {
      display: flex;
      align-items: center;
      gap: 0.5rem;
      flex-wrap: wrap;
      font-size: 0.875rem;
    }

    .occ-label {
      color: var(--text-muted);
      font-weight: 600;
      min-width: 70px;
    }

    .occ-value {
      color: var(--text);
    }

    .occ-value a {
      color: var(--accent);
      text-decoration: none;
    }

    .occ-value a:hover {
      text-decoration: underline;
    }

    .occ-value code {
      background: var(--code-bg);
      border: 1px solid var(--code-border);
      padding: 0.125rem 0.375rem;
      border-radius: 4px;
      font-family: ui-monospace, SFMono-Regular, "SF Mono", Menlo, Consolas, "Liberation Mono", monospace;
      font-size: 0.8125rem;
      color: #79c0ff;
    }

    .snippet {
      margin-top: 0.75rem;
    }

    .snippet-label {
      color: var(--text-muted);
      font-size: 0.8125rem;
      font-weight: 600;
      margin-bottom: 0.375rem;
      text-transform: uppercase;
      letter-spacing: 0.05em;
    }

    pre {
      background: var(--code-bg);
      border: 1px solid var(--code-border);
      border-radius: 6px;
      padding: 0.75rem;
      overflow-x: auto;
      font-family: ui-monospace, SFMono-Regular, "SF Mono", Menlo, Consolas, "Liberation Mono", monospace;
      font-size: 0.8125rem;
      line-height: 1.5;
    }

    pre code {
      color: #e6edf3;
      background: none;
      border: none;
      padding: 0;
    }

    .screenshot {
      margin-top: 1rem;
      background: var(--code-bg);
      border: 1px solid var(--border-muted);
      border-radius: 8px;
      padding: 0.75rem;
    }

    .screenshot-label {
      color: var(--text-muted);
      font-size: 0.8125rem;
      font-weight: 600;
      margin-bottom: 0.5rem;
      text-transform: uppercase;
      letter-spacing: 0.05em;
    }

    .screenshot img {
      display: block;
      max-width: 100%;
      height: auto;
      border-radius: 6px;
      border: 1px solid var(--border);
      image-rendering: crisp-edges;
      image-rendering: -webkit-optimize-contrast;
    }

    footer {
      text-align: center;
      padding: 2rem 1rem;
      color: var(--text-muted);
      font-size: 0.875rem;
    }

    footer a {
      color: var(--accent);
      text-decoration: none;
    }

    footer a:hover {
      text-decoration: underline;
    }

    @media (max-width: 768px) {
      body {
        padding: 1rem;
      }

      header {
        padding: 1.5rem;
        position: static;
      }

      h1 {
        font-size: 1.5rem;
      }

      .summary {
        grid-template-columns: 1fr;
      }

      .kpi .value {
        font-size: 2rem;
      }
    }
  </style>
</head>
<body>
  <div class="container">
    <header>
      <h1>{{ model.title }}</h1>
      <div class="meta">Generated {{ model.generated_at }}</div>
    </header>

    <section class="card">
      <div class="section-title">Summary</div>
      <div class="summary">
        <div class="kpi">
          <div class="label">Pages Scanned</div>
          <div class="value">{{ model.pages_scanned }}</div>
        </div>
        <div class="kpi">
          <div class="label">Total Violations</div>
          <div class="value {% if model.total_violations == 0 %}status-ok{% elif model.total_violations < 10 %}status-warn{% else %}status-bad{% endif %}">
            {{ model.total_violations }}
          </div>
        </div>
        <div class="kpi">
          <div class="label">Raw Artifacts</div>
          <div class="value">{{ model.raw_files|length }}</div>
        </div>
      </div>

      {% if model.raw_files %}
      <div class="raw-files">
        <div class="raw-files-title">Raw JSON Reports</div>
        <div class="raw-list">
          {% for f in model.raw_files %}
          <a href="{{ results_web_base }}/{{ f }}" target="_blank" rel="noopener">{{ f }}</a>
          {% endfor %}
        </div>
      </div>
      {% endif %}
    </section>

    {% if model.total_violations == 0 %}
    <section class="card">
      <div class="section-title">Violations</div>
      <p class="rule-desc">✅ No accessibility violations found! Great work!</p>
    </section>
    {% else %}
    <section class="card">
      <div class="section-title">Violations by Rule ({{ model.by_rule|length }} rules)</div>
      <div class="rules">
        {% for grp in model.by_rule %}
        <article class="rule {{ grp.impact_class }}">
          <div class="rule-header">
            <span class="rule-id">{{ grp.id }}</span>
            {% if grp.impact %}
            <span class="badge badge-impact">{{ grp.impact }}</span>
            {% else %}
            <span class="badge badge-impact">unknown</span>
            {% endif %}
            <span class="badge badge-count">{{ grp.count }} occurrence{{ 's' if grp.count != 1 else '' }}</span>
            {% if grp.helpUrl %}
            <a class="badge badge-link" href="{{ grp.helpUrl }}" target="_blank" rel="noopener">Documentation →</a>
            {% endif %}
          </div>

          {% if grp.description %}
          <div class="rule-desc">{{ grp.description }}</div>
          {% elif grp.help %}
          <div class="rule-desc">{{ grp.help }}</div>
          {% endif %}

          <div class="occ-list">
            {% for occ in grp.occurrences %}
            <div class="occ">
              <div class="occ-meta">
                <div class="occ-meta-row">
                  <span class="occ-label">Page:</span>
                  <span class="occ-value">
                    {% if occ.source_file %}
                      {{ occ.source_file }}
                    {% else %}
                      <a href="{{ occ.url }}" target="_blank" rel="noopener">{{ occ.url }}</a>
                    {% endif %}
                  </span>
                </div>
                {% if occ.selector %}
                <div class="occ-meta-row">
                  <span class="occ-label">Selector:</span>
                  <span class="occ-value"><code>{{ occ.selector }}</code></span>
                </div>
                {% endif %}
              </div>

              {% if occ.html_snippet %}
              <div class="snippet">
                <div class="snippet-label">HTML Snippet</div>
                <pre><code>{{ occ.html_snippet | e }}</code></pre>
              </div>
              {% endif %}

              {% if occ.screenshot_filename %}
              <div class="screenshot">
                <div class="screenshot-label">Visual Reference</div>
                <img src="{{ results_web_base }}/{{ occ.screenshot_filename }}" alt="Screenshot showing {{ grp.id }} violation" loading="lazy">
              </div>
              {% endif %}
            </div>
            {% endfor %}
          </div>
        </article>
        {% endfor %}
      </div>
    </section>
    {% endif %}

    <footer>
      <strong>a11y-scanner</strong> • Powered by <a href="https://github.com/dequelabs/axe-core" target="_blank" rel="noopener">axe-core</a> + <a href="https://playwright.dev" target="_blank" rel="noopener">Playwright</a>
    </footer>
  </div>
</body>
</html>
```

</FILE>

---

### Entering Directory: 'src/scanner/utils/'

<FILE path="src/scanner/utils/__init__.py">

```python
"""Utility functions for a11y-scanner."""

from .json_utils import sanitize_for_json

__all__ = ["sanitize_for_json"]
```

</FILE>

---

<FILE path="src/scanner/utils/json_utils.py">

```python
"""JSON serialization utilities for handling non-standard Python objects."""

from typing import Any


def sanitize_for_json(obj: Any) -> Any:
    """
    Recursively convert Python/JavaScript objects to JSON-serializable types.

    This function handles objects that can't be directly serialized to JSON,
    including Playwright/JavaScript objects like Error types that may appear
    in axe-core scan results.

    Args:
        obj: Any Python object to sanitize for JSON serialization

    Returns:
        A JSON-serializable version of the object

    Examples:
        >>> sanitize_for_json({"valid": "data"})
        {'valid': 'data'}

        >>> sanitize_for_json({"nested": {"error": TypeError("test")}})
        {'nested': {'error': {'error': 'test', 'type': 'TypeError'}}}
    """
    if obj is None or isinstance(obj, (str, int, float, bool)):
        return obj

    if isinstance(obj, dict):
        return {k: sanitize_for_json(v) for k, v in obj.items()}

    if isinstance(obj, (list, tuple)):
        return [sanitize_for_json(item) for item in obj]

    # Handle JavaScript Error objects and other non-serializable types
    if hasattr(obj, "__class__") and "Error" in obj.__class__.__name__:
        return {"error": str(obj), "type": obj.__class__.__name__}

    # Try to convert to string as fallback
    try:
        return str(obj)
    except Exception:
        return f"<non-serializable: {type(obj).__name__}>"
```

</FILE>

---

### Entering Directory: 'src/scanner/web/'

<FILE path="src/scanner/web/__init__.py">

```python
"""FastAPI web server for a11y-scanner."""
```

</FILE>

---

<FILE path="src/scanner/web/server.py">

```python
from __future__ import annotations

import ipaddress
import os
import shutil
import socket
from pathlib import Path
from urllib.parse import urlparse

from fastapi import FastAPI, File, HTTPException, Request, UploadFile
from fastapi.responses import HTMLResponse, JSONResponse
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel, HttpUrl, field_validator

from scanner.core.logging_setup import setup_logging
from scanner.core.settings import Settings
from scanner.pipeline import Pipeline
from scanner.reporting.jinja_report import build_report
from scanner.services.html_discovery_service import HtmlDiscoveryService
from scanner.services.http_service import HttpService
from scanner.services.playwright_axe_service import PlaywrightAxeService
from scanner.services.zip_service import ZipService

IN_CONTAINER_ENV = "A11Y_SCANNER_IN_CONTAINER"
IN_CONTAINER_VALUE = "1"

# Optional auth: set A11Y_API_TOKEN to require X-API-Key or Bearer <token>
API_TOKEN_ENV = "A11Y_API_TOKEN"

MAX_UPLOAD_SIZE = 100 * 1024 * 1024
ALLOWED_MIME_TYPES = {
    "application/zip",
    "application/x-zip-compressed",
    "application/x-zip",
}

app = FastAPI(title="a11y-scanner API", version="0.1.0")
setup_logging()
settings = Settings()

for d in (
    settings.data_dir,
    settings.unzip_dir,
    settings.results_dir,
    settings.scan_dir,
):
    d.mkdir(parents=True, exist_ok=True)

reports_dir = settings.data_dir / "reports"
reports_dir.mkdir(parents=True, exist_ok=True)

app.mount("/results", StaticFiles(directory=settings.results_dir), name="results")
app.mount("/reports", StaticFiles(directory=reports_dir), name="reports")


class UrlsIn(BaseModel):
    urls: list[HttpUrl]

    @field_validator("urls")
    @classmethod
    def validate_urls(cls, v):
        if not v:
            raise ValueError("At least one URL must be provided")
        if len(v) > 50:
            raise ValueError("Maximum 50 URLs allowed per request")
        return v


def _require_container():
    if os.environ.get(IN_CONTAINER_ENV) != IN_CONTAINER_VALUE:
        raise HTTPException(status_code=400, detail="Must run inside container")


def _require_auth(request: Request):
    """
    If A11Y_API_TOKEN is set, require X-API-Key or Authorization: Bearer <token>.
    If not set, auth is not enforced (use only on trusted networks).
    """
    expected = os.environ.get(API_TOKEN_ENV)
    if not expected:
        return
    header_val = request.headers.get("x-api-key")
    if not header_val:
        auth = request.headers.get("authorization", "")
        if auth.lower().startswith("bearer "):
            header_val = auth[7:].strip()
    if header_val != expected:
        raise HTTPException(status_code=401, detail="Unauthorized")


def _clean_dir(p: Path):
    p.mkdir(parents=True, exist_ok=True)
    for child in p.iterdir():
        if child.is_dir():
            shutil.rmtree(child, ignore_errors=True)
        else:
            try:
                child.unlink(missing_ok=True)
            except Exception:
                pass


def _validate_public_http_url(url_str: str) -> None:
    """
    Best-effort SSRF mitigation:
      - Only http/https (already enforced by HttpUrl).
      - Resolve host → IP(s); require ALL resolved IPs to be global (public).
      - Block obvious loopback hostnames.
    Note: Redirects at runtime may still point to private nets; additional
    network-level egress controls are recommended for defense in depth.
    """
    parsed = urlparse(url_str)
    host = parsed.hostname
    if not host:
        raise HTTPException(status_code=400, detail=f"Invalid URL host: {url_str}")

    lower = host.lower()
    if lower in {"localhost"}:
        raise HTTPException(status_code=400, detail=f"Blocked host: {host}")

    try:
        infos = socket.getaddrinfo(host, None)
    except socket.gaierror:
        raise HTTPException(status_code=400, detail=f"DNS resolution failed for {host}")

    if not infos:
        raise HTTPException(status_code=400, detail=f"Could not resolve host: {host}")

    for _family, _socktype, _proto, _canon, sockaddr in infos:
        ip = sockaddr[0]
        try:
            ip_obj = ipaddress.ip_address(ip)
        except ValueError:
            raise HTTPException(
                status_code=400, detail=f"Invalid resolved IP for {host}: {ip}"
            )

        # Strict: every resolved address must be globally routable.
        if not ip_obj.is_global:
            raise HTTPException(
                status_code=400,
                detail=f"Blocked non-public address for {host}: {ip}",
            )


@app.get("/healthz")
async def healthz():
    return {"status": "ok"}


@app.get("/", response_class=HTMLResponse)
async def index():
    return """
    <h1>a11y-scanner API</h1>
    <ul>
      <li>POST <code>/api/scan/zip</code> with form field <code>file</code> (.zip of a static site)</li>
      <li>POST <code>/api/scan/url</code> with JSON like <code>{"urls":["https://example.com/"]}</code></li>
    </ul>
    <p><strong>Security:</strong> For private networks only by default. Set <code>A11Y_API_TOKEN</code> to require an API key. The server denies non-public destinations for URL scans.</p>
    <p>Artifacts: <a href="/reports" target="_blank">/reports</a> and <a href="/results" target="_blank">/results</a>.</p>
    """


@app.post("/api/scan/zip")
async def scan_zip(request: Request, file: UploadFile = File(...)):
    _require_container()
    _require_auth(request)

    if file.content_type not in ALLOWED_MIME_TYPES:
        raise HTTPException(
            status_code=400,
            detail=f"Invalid file type: {file.content_type}. Only ZIP files are allowed.",
        )
    if not file.filename or not file.filename.lower().endswith(".zip"):
        raise HTTPException(status_code=400, detail="File must have a .zip extension")

    content = await file.read()
    if len(content) > MAX_UPLOAD_SIZE:
        raise HTTPException(
            status_code=413,
            detail=f"File too large. Maximum size is {MAX_UPLOAD_SIZE / (1024 * 1024):.0f} MB",
        )
    if len(content) == 0:
        raise HTTPException(status_code=400, detail="Uploaded file is empty")

    _clean_dir(settings.scan_dir)
    _clean_dir(settings.results_dir)

    target = settings.unzip_dir / "site.zip"
    try:
        target.write_bytes(content)
    except Exception as e:
        raise HTTPException(
            status_code=500, detail=f"Failed to save uploaded file: {str(e)}"
        )

    try:
        zip_service = ZipService(
            unzip_dir=settings.unzip_dir, scan_dir=settings.scan_dir
        )
        html_service = HtmlDiscoveryService(scan_dir=settings.scan_dir)
        http_service = HttpService()
        axe_service = PlaywrightAxeService()
        pipeline = Pipeline(
            settings=settings,
            zip_service=zip_service,
            html_service=html_service,
            http_service=http_service,
            axe_service=axe_service,
        )
        violations = pipeline.run()
    except FileNotFoundError as e:
        raise HTTPException(status_code=400, detail=f"Invalid ZIP file: {str(e)}")
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Scan failed: {str(e)}")

    output_html = reports_dir / "latest.html"
    try:
        build_report(
            settings.results_dir, output_html, title="Accessibility Report (ZIP)"
        )
    except Exception as e:
        raise HTTPException(
            status_code=500, detail=f"Failed to generate report: {str(e)}"
        )

    return JSONResponse(
        {
            "violations": len(violations),
            "pages_scanned": len(list(settings.results_dir.glob("*.json"))),
            "report_url": "/reports/latest.html",
            "results_url": "/results/",
            "status": "success",
            "message": f"Scan complete. Found {len(violations)} violations.",
        }
    )


@app.post("/api/scan/url")
async def scan_url(request: Request, payload: UrlsIn):
    _require_container()
    _require_auth(request)

    # Additional SSRF guardrails beyond HttpUrl validation
    for url in payload.urls:
        url_str = str(url)
        if not url_str.startswith(("http://", "https://")):
            raise HTTPException(
                status_code=400,
                detail=f"Invalid URL: {url_str}. URLs must start with http:// or https://",
            )
        _validate_public_http_url(url_str)

    _clean_dir(settings.results_dir)

    try:
        count = 0
        scanned_urls: list[str] = []
        # Reuse a single browser for all URLs (faster, less resource use)
        with PlaywrightAxeService() as axe:
            for url in payload.urls:
                url_str = str(url)
                safe_name = (
                    url_str.replace("https://", "")
                    .replace("http://", "")
                    .replace("/", "_")
                    .replace("?", "_")
                )
                report_path = settings.results_dir / f"{safe_name}.json"
                try:
                    v = axe.scan_url(url_str, report_path, source_file=safe_name)
                    count += len(v)
                    scanned_urls.append(url_str)
                except Exception as e:
                    scanned_urls.append(f"{url_str} (failed: {str(e)})")
                    continue
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Scan failed: {str(e)}")

    output_html = reports_dir / "latest.html"
    try:
        build_report(
            settings.results_dir, output_html, title="Accessibility Report (Live URLs)"
        )
    except Exception as e:
        raise HTTPException(
            status_code=500, detail=f"Failed to generate report: {str(e)}"
        )

    return JSONResponse(
        {
            "violations": count,
            "urls_scanned": len(payload.urls),
            "scanned_urls": scanned_urls,
            "report_url": "/reports/latest.html",
            "results_url": "/results/",
            "status": "success",
            "message": f"Scanned {len(scanned_urls)} URLs. Found {count} violations.",
        }
    )


def run():
    import uvicorn

    uvicorn.run(app, host="0.0.0.0", port=8008)


if __name__ == "__main__":
    run()
```

</FILE>

---

### Entering Directory: 'tests/'

<FILE path="tests/test_api.py">

```python
import zipfile
from io import BytesIO
from unittest.mock import MagicMock, patch

import pytest
from fastapi.testclient import TestClient

from scanner.web.server import app


@pytest.fixture
def client():
    """Fixture to provide a FastAPI TestClient."""
    return TestClient(app)


@pytest.fixture
def mock_container_env(monkeypatch):
    """Mock the container environment variable."""
    monkeypatch.setenv("A11Y_SCANNER_IN_CONTAINER", "1")


@pytest.fixture
def sample_zip():
    """Create a sample ZIP file in memory."""
    buffer = BytesIO()
    with zipfile.ZipFile(buffer, "w", zipfile.ZIP_DEFLATED) as zf:
        zf.writestr("index.html", "<html><body><h1>Test</h1></body></html>")
        zf.writestr("about.html", "<html><body><h1>About</h1></body></html>")
    buffer.seek(0)
    return buffer


def test_healthz(client):
    """Test the health check endpoint."""
    response = client.get("/healthz")
    assert response.status_code == 200
    assert response.json() == {"status": "ok"}


def test_index(client):
    """Test the index endpoint returns HTML."""
    response = client.get("/")
    assert response.status_code == 200
    assert "a11y-scanner API" in response.text
    assert "/api/scan/zip" in response.text
    assert "/api/scan/url" in response.text


def test_scan_zip_requires_container(client):
    """Test that scan_zip endpoint requires container environment."""
    response = client.post(
        "/api/scan/zip",
        files={"file": ("test.zip", b"dummy content", "application/zip")},
    )
    assert response.status_code == 400
    assert "Must run inside container" in response.json()["detail"]


def test_scan_zip_invalid_mime_type(client, mock_container_env, sample_zip):
    """Test that scan_zip rejects non-ZIP MIME types."""
    with patch("scanner.web.server.Pipeline"):
        response = client.post(
            "/api/scan/zip",
            files={"file": ("test.txt", sample_zip.getvalue(), "text/plain")},
        )
        assert response.status_code == 400
        assert "Invalid file type" in response.json()["detail"]


def test_scan_zip_invalid_extension(client, mock_container_env, sample_zip):
    """Test that scan_zip rejects files without .zip extension."""
    with patch("scanner.web.server.Pipeline"):
        response = client.post(
            "/api/scan/zip",
            files={"file": ("test.txt", sample_zip.getvalue(), "application/zip")},
        )
        assert response.status_code == 400
        assert ".zip extension" in response.json()["detail"]


def test_scan_zip_empty_file(client, mock_container_env):
    """Test that scan_zip rejects empty files."""
    with patch("scanner.web.server.Pipeline"):
        response = client.post(
            "/api/scan/zip",
            files={"file": ("test.zip", b"", "application/zip")},
        )
        assert response.status_code == 400
        assert "empty" in response.json()["detail"]


def test_scan_zip_too_large(client, mock_container_env):
    """Test that scan_zip rejects files exceeding size limit."""
    # Create a file larger than MAX_UPLOAD_SIZE (100 MB)
    large_content = b"x" * (101 * 1024 * 1024)
    with patch("scanner.web.server.Pipeline"):
        response = client.post(
            "/api/scan/zip",
            files={"file": ("test.zip", large_content, "application/zip")},
        )
        assert response.status_code == 413
        assert "too large" in response.json()["detail"]


def test_scan_zip_success(client, mock_container_env, sample_zip, tmp_path):
    """Test successful ZIP scan."""
    with patch("scanner.web.server.settings") as mock_settings:
        # Configure mock settings
        mock_settings.unzip_dir = tmp_path / "unzip"
        mock_settings.scan_dir = tmp_path / "scan"
        mock_settings.results_dir = tmp_path / "results"
        mock_settings.data_dir = tmp_path / "data"
        for d in [
            mock_settings.unzip_dir,
            mock_settings.scan_dir,
            mock_settings.results_dir,
        ]:
            d.mkdir(parents=True, exist_ok=True)

        with patch("scanner.web.server.Pipeline") as mock_pipeline_class:
            # Mock pipeline run
            mock_pipeline = MagicMock()
            mock_pipeline.run.return_value = [{"id": "image-alt", "impact": "critical"}]
            mock_pipeline_class.return_value = mock_pipeline

            with patch("scanner.web.server.build_report"):
                response = client.post(
                    "/api/scan/zip",
                    files={
                        "file": ("test.zip", sample_zip.getvalue(), "application/zip")
                    },
                )

                assert response.status_code == 200
                data = response.json()
                assert data["status"] == "success"
                assert "violations" in data
                assert "report_url" in data
                assert data["report_url"] == "/reports/latest.html"


def test_scan_url_requires_container(client):
    """Test that scan_url endpoint requires container environment."""
    response = client.post("/api/scan/url", json={"urls": ["https://example.com"]})
    assert response.status_code == 400
    assert "Must run inside container" in response.json()["detail"]


def test_scan_url_invalid_url(client, mock_container_env):
    """Test that scan_url rejects invalid URLs."""
    with patch("scanner.web.server.PlaywrightAxeService"):
        response = client.post(
            "/api/scan/url", json={"urls": ["not-a-url", "ftp://example.com"]}
        )
        # Pydantic validation returns 422 for invalid URL format
        assert response.status_code == 422
        assert "detail" in response.json()


def test_scan_url_success(client, mock_container_env, tmp_path):
    """Test successful URL scan."""
    # Mock the entire settings module reference
    with (
        patch("scanner.web.server.settings") as mock_settings,
        patch("scanner.web.server._clean_dir"),
    ):
        mock_settings.results_dir = tmp_path / "results"
        mock_settings.data_dir = tmp_path / "data"
        mock_settings.results_dir.mkdir(parents=True, exist_ok=True)

        with patch("scanner.web.server.PlaywrightAxeService") as mock_axe_class:
            # Mock axe service
            mock_axe = MagicMock()
            mock_axe.scan_url.return_value = [
                {"id": "color-contrast", "impact": "serious"}
            ]
            mock_axe_class.return_value = mock_axe

            with (
                patch("scanner.web.server.build_report"),
                patch("scanner.web.server.reports_dir", tmp_path / "reports"),
            ):
                (tmp_path / "reports").mkdir(parents=True, exist_ok=True)

                response = client.post(
                    "/api/scan/url",
                    json={"urls": ["https://example.com", "https://test.com"]},
                )

                assert response.status_code == 200
                data = response.json()
                assert data["status"] == "success"
                assert "violations" in data
                assert "urls_scanned" in data
                assert data["urls_scanned"] == 2
                assert "scanned_urls" in data
                assert len(data["scanned_urls"]) == 2


def test_scan_url_partial_failure(client, mock_container_env, tmp_path):
    """Test URL scan with some URLs failing."""
    with (
        patch("scanner.web.server.settings") as mock_settings,
        patch("scanner.web.server._clean_dir"),
    ):
        mock_settings.results_dir = tmp_path / "results"
        mock_settings.data_dir = tmp_path / "data"
        mock_settings.results_dir.mkdir(parents=True, exist_ok=True)

        with patch("scanner.web.server.PlaywrightAxeService") as mock_axe_class:
            # Mock axe service - first succeeds, second fails
            mock_axe = MagicMock()
            mock_axe.scan_url.side_effect = [
                [{"id": "color-contrast", "impact": "serious"}],
                Exception("Network error"),
            ]
            mock_axe_class.return_value = mock_axe

            with (
                patch("scanner.web.server.build_report"),
                patch("scanner.web.server.reports_dir", tmp_path / "reports"),
            ):
                (tmp_path / "reports").mkdir(parents=True, exist_ok=True)

                response = client.post(
                    "/api/scan/url",
                    json={"urls": ["https://example.com", "https://bad.com"]},
                )

                assert response.status_code == 200
                data = response.json()
                assert data["status"] == "success"
                # Should have scanned both URLs (one succeeded, one failed)
                assert data["urls_scanned"] == 2
                assert len(data["scanned_urls"]) == 2
                # Second URL should show failure
                assert "bad.com" in data["scanned_urls"][1]
```

</FILE>

---

<FILE path="tests/test_html_discovery_service.py">

```python
from pathlib import Path

import pytest

from scanner.services.html_discovery_service import HtmlDiscoveryService


@pytest.mark.parametrize(
    "test_dir, expected_rel_paths",
    [
        ("1", {"index.html", "about.html"}),
        (
            "2",
            {
                "hehe.htm",
                "lol.html",
                "test.html",
                "nest/ll.html",
                "nest/ll.htm",
                "nest/tl.htm",
            },
        ),
        ("3", {"mor_test.html", "test.html"}),
    ],
)
def test_discover_html_files_absolute_and_relative(test_dir, expected_rel_paths):
    base_dir = Path(__file__).parent / "assets" / "html_sets" / test_dir
    assert base_dir.exists(), f"Test directory does not exist: {base_dir}"

    service = HtmlDiscoveryService(scan_dir=base_dir)
    discovered = service.discover_html_files()

    found_rel = {str(entry["relative"]) for entry in discovered}
    assert found_rel == expected_rel_paths, f"Relative paths mismatch in {test_dir}"

    for entry in discovered:
        rel = entry["relative"]
        abs_path = entry["absolute"]

        # Assert absolute path is correct
        expected_abs = base_dir / rel
        assert abs_path == expected_abs.resolve(), f"Absolute path mismatch for {rel}"
        assert abs_path.exists(), f"Absolute path doesn't exist: {abs_path}"
        assert abs_path.is_file(), f"Path is not a file: {abs_path}"
```

</FILE>

---

<FILE path="tests/test_http_service.py">

```python
import time
from pathlib import Path

import pytest
import requests

from scanner.services.http_service import HttpService


@pytest.fixture
def http_service():
    """Fixture to create and automatically clean up an HttpService instance."""
    service = HttpService()
    yield service
    # Teardown: ensure the server is stopped after the test runs
    service.stop()


def test_http_server_serves_files(http_service: HttpService, tmp_path: Path):
    """
    Verify that the HttpService can start, serve a file, and stop.
    """
    content = "<html><body>Test Page</body></html>"
    test_file = tmp_path / "index.html"
    test_file.write_text(content)

    http_service.start(directory=tmp_path)
    assert http_service.base_url, "Server should have a base_url after starting"
    time.sleep(0.1)  # Give the server a moment to start up in the background

    url_to_test = f"{http_service.base_url}/index.html"

    try:
        response = requests.get(url_to_test, timeout=5)
        response.raise_for_status()

        assert response.text == content
        assert response.headers["Content-Type"] == "text/html"

    except requests.RequestException as e:
        pytest.fail(f"HTTP request failed: {e}")

    http_service.stop()

    with pytest.raises(requests.ConnectionError):
        requests.get(url_to_test, timeout=1)
```

</FILE>

---

<FILE path="tests/test_pipeline.py">

```python
import zipfile
from pathlib import Path
from unittest.mock import MagicMock

import pytest

from scanner.core.settings import Settings
from scanner.pipeline import Pipeline


def create_test_zip(zip_path: Path, files: dict[str, str]):
    """Helper to create a zip file for testing."""
    zip_path.parent.mkdir(parents=True, exist_ok=True)
    with zipfile.ZipFile(zip_path, "w") as zf:
        for file_name, content in files.items():
            zf.writestr(file_name, content)


@pytest.fixture
def mock_services() -> dict:
    """Provides a dictionary of mocked services for injection."""
    return {
        "zip_service": MagicMock(),
        "html_service": MagicMock(),
        "http_service": MagicMock(),
        "axe_service": MagicMock(),
    }


def test_pipeline_happy_path(tmp_path: Path, mock_services: dict):
    """
    Tests the full pipeline orchestration on a happy path using mocked services.
    """
    # 1. Setup
    # Configure the return values of our mocks
    mock_services["html_service"].discover_html_files.return_value = [
        {"relative": Path("index.html")}
    ]
    mock_services["http_service"].base_url = "http://localhost:8000"

    # --- THE FIX IS HERE ---
    # We now mock the return value of `scan_url` because that's what the pipeline
    # uses to get the results directly.
    mock_violations = [{"id": "image-alt", "impact": "critical"}]
    mock_services["axe_service"].scan_url.return_value = mock_violations

    # Create fake directory structure
    settings = Settings(root_path=tmp_path)
    settings.scan_dir.mkdir(parents=True, exist_ok=True)
    settings.results_dir.mkdir(parents=True, exist_ok=True)

    # 2. Action
    # Instantiate the pipeline with our temporary settings and MOCKED services
    pipeline = Pipeline(settings=settings, **mock_services)
    final_results = pipeline.run()

    # 3. Verification
    # Verify that the services were called as expected
    mock_services["zip_service"].run.assert_called_once()
    mock_services["html_service"].discover_html_files.assert_called_once()
    mock_services["http_service"].start.assert_called_once_with(
        directory=settings.scan_dir
    )

    # Verify AxeService.scan_url was called correctly
    mock_services["axe_service"].scan_url.assert_called_once()
    call_args, _ = mock_services["axe_service"].scan_url.call_args
    scanned_url = call_args[0]
    report_path = call_args[1]
    assert scanned_url == "http://localhost:8000/index.html"
    assert report_path == settings.results_dir / "index.html.json"

    # Verify the final result is what the mocked scan_url returned,
    # but with the added context from the pipeline.
    expected_result = [
        {
            "id": "image-alt",
            "impact": "critical",
            "scanned_url": "http://localhost:8000/index.html",
            "source_file": "index.html",
        }
    ]
    assert final_results == expected_result

    # Verify the HTTP server was stopped
    mock_services["http_service"].stop.assert_called_once()


def test_pipeline_no_html_files_found(tmp_path: Path, mock_services: dict):
    """
    Verify the pipeline exits gracefully if no HTML files are discovered.
    """
    # 1. Setup
    mock_services["html_service"].discover_html_files.return_value = []
    settings = Settings(root_path=tmp_path)

    # 2. Action
    pipeline = Pipeline(settings=settings, **mock_services)
    result = pipeline.run()

    # 3. Verification
    assert result == []
    mock_services["zip_service"].run.assert_called_once()
    mock_services["http_service"].start.assert_not_called()
    mock_services["axe_service"].scan_url.assert_not_called()
    mock_services[
        "http_service"
    ].stop.assert_called_once()  # Should still be called in finally
```

</FILE>

---

<FILE path="tests/test_reporting.py">

```python
import json
import tempfile
from pathlib import Path

import pytest

from scanner.reporting.jinja_report import (
    Occurrence,
    ReportModel,
    RuleGroup,
    build_report,
    validate_report_json,
)


@pytest.fixture
def sample_report_data():
    """Sample report data for testing"""

    return {
        "scanned_url": "http://localhost:8000/index.html",
        "source_file": "index.html",
        "violations": [
            {
                "id": "image-alt",
                "impact": "critical",
                "description": "Images must have alternate text",
                "help": "Provide appropriate alt text for images",
                "helpUrl": "https://example.com/help",
                "nodes": [
                    {"target": ["img[src='logo.png']"], "html": "<img src='logo.png'>"}
                ],
                "screenshot_path": "screenshot1.png",
            }
        ],
    }


@pytest.fixture
def temp_dirs():
    """Create temporary directories for testing"""

    with tempfile.TemporaryDirectory() as temp_dir:

        temp_path = Path(temp_dir)

        results_dir = temp_path / "results"

        reports_dir = temp_path / "reports"

        results_dir.mkdir()

        reports_dir.mkdir()

        yield results_dir, reports_dir


def test_occurrence_post_init():
    """Test that Occurrence.__post_init__ correctly extracts filename"""

    # Test with string path

    occ = Occurrence(
        url="http://example.com",
        source_file="index.html",
        selector="img",
        html_snippet="<img>",
        screenshot_path="/path/to/screenshot.png",
    )

    assert occ.screenshot_filename == "screenshot.png"

    # Test with None

    occ2 = Occurrence(
        url="http://example.com",
        source_file="index.html",
        selector="img",
        html_snippet="<img>",
        screenshot_path=None,
    )

    assert occ2.screenshot_filename is None

    # Test with Path object

    occ3 = Occurrence(
        url="http://example.com",
        source_file="index.html",
        selector="img",
        html_snippet="<img>",
        screenshot_path=Path("/path/to/another.png"),
    )

    assert occ3.screenshot_filename == "another.png"


def test_rule_group_impact_class():
    """Test RuleGroup.impact_class property"""

    # Test with different impact levels

    assert RuleGroup(id="test", impact="critical").impact_class == "impact-critical"

    assert RuleGroup(id="test", impact="serious").impact_class == "impact-serious"

    assert RuleGroup(id="test", impact="moderate").impact_class == "impact-moderate"

    assert RuleGroup(id="test", impact="minor").impact_class == "impact-minor"

    assert RuleGroup(id="test", impact="unknown").impact_class == "impact-unknown"

    assert RuleGroup(id="test", impact=None).impact_class == "impact-unknown"


def test_report_model_validation():
    """Test ReportModel.validate() method"""

    # Valid model

    model = ReportModel(
        title="Test",
        generated_at="2023-01-01T00:00:00Z",
        pages_scanned=1,
        total_violations=1,
        by_rule=[],
        raw_files=[],
    )

    assert model.validate() is True

    # Invalid: negative pages

    model.pages_scanned = -1

    assert model.validate() is False

    # Invalid: negative violations

    model.pages_scanned = 1

    model.total_violations = -1

    assert model.validate() is False

    # Edge case: zero violations with rule groups

    model.total_violations = 0

    model.by_rule = [RuleGroup(id="test", impact="critical")]

    assert model.validate() is False  # Should be False if rules exist but 0 violations

    # Valid: zero violations with no rule groups

    model.by_rule = []

    assert model.validate() is True


def test_validate_report_json(temp_dirs, sample_report_data):
    """Test validate_report_json function"""

    results_dir, _ = temp_dirs

    # Test valid JSON

    valid_file = results_dir / "valid.json"

    with open(valid_file, "w") as f:

        json.dump(sample_report_data, f)

    assert validate_report_json(valid_file) is True

    # Test invalid JSON (not a dict)

    invalid_file = results_dir / "invalid.json"

    with open(invalid_file, "w") as f:

        f.write('["not", "a", "dict"]')

    assert validate_report_json(invalid_file) is False

    # Test missing URL info

    invalid_data = {"violations": []}  # No URL info

    invalid_file2 = results_dir / "invalid2.json"

    with open(invalid_file2, "w") as f:

        json.dump(invalid_data, f)

    assert validate_report_json(invalid_file2) is False


def test_build_report_success(temp_dirs, sample_report_data):
    """Test successful report generation"""

    results_dir, reports_dir = temp_dirs

    # Create sample report file

    report_file = results_dir / "sample.json"

    with open(report_file, "w") as f:

        json.dump(sample_report_data, f)

    # Generate report

    output_file = reports_dir / "report.html"

    result = build_report(results_dir, output_file, title="Test Report")

    # Verify result

    assert result == output_file

    assert output_file.exists()

    assert output_file.stat().st_size > 0

    # Check content

    content = output_file.read_text()

    assert "Test Report" in content

    assert "image-alt" in content

    assert "Pages Scanned" in content

    assert "Total Violations" in content


def test_build_report_no_results_dir(temp_dirs):
    """Test build_report with non-existent results directory"""

    _, reports_dir = temp_dirs

    non_existent_dir = Path("/non/existent/directory")

    output_file = reports_dir / "report.html"

    # Should not raise an error, but generate an empty report

    result = build_report(non_existent_dir, output_file)

    assert result == output_file

    assert output_file.exists()


def test_build_report_no_json_files(temp_dirs):
    """Test build_report with no JSON files in results directory"""

    results_dir, reports_dir = temp_dirs

    output_file = reports_dir / "report.html"

    # Generate report with empty results directory

    result = build_report(results_dir, output_file, title="Empty Report")

    assert result == output_file

    assert output_file.exists()

    # Check that it's a valid HTML file with "No accessibility violations"

    content = output_file.read_text()

    assert "Empty Report" in content

    assert "No accessibility violations" in content
```

</FILE>

---

<FILE path="tests/test_settings.py">

```python
from pathlib import Path

from scanner.core.settings import Settings


def test_settings_default_uses_relative_paths():
    """
    Verify that by default, Settings uses relative paths from the current directory.
    This is important for portability and interaction with CLI tools.
    """
    settings = Settings()

    # The base path should be a relative representation of the current directory.
    assert settings.base_path == Path(".")

    # All other paths should be built relative to that.
    assert settings.data_dir == Path("data")
    assert settings.scan_dir == Path("data/scan")
    assert settings.unzip_dir == Path("data/unzip")
    assert settings.results_dir == Path("data/results")
    assert settings.port == 8000


def test_settings_with_custom_base_path_uses_absolute_path(tmp_path: Path):
    """
    Verify that when a root_path is provided (common in tests), it is
    resolved to an absolute path.
    """
    settings = Settings(root_path=tmp_path)

    assert settings.base_path == tmp_path.resolve()
    assert settings.data_dir == tmp_path.resolve() / "data"
    assert settings.scan_dir == tmp_path.resolve() / "data" / "scan"
    assert settings.unzip_dir == tmp_path.resolve() / "data" / "unzip"
    assert settings.results_dir == tmp_path.resolve() / "data" / "results"
```

</FILE>

---

<FILE path="tests/test_zip_service.py">

```python
import zipfile
from pathlib import Path

import pytest

from scanner.services.zip_service import ZipService


def create_test_zip(zip_path: Path, files: dict[str, str]):
    """
    Creates a zip file at `zip_path` with a dictionary of filename -> contents.
    """
    with zipfile.ZipFile(zip_path, "w") as zf:
        for file_name, content in files.items():
            zf.writestr(file_name, content)


def test_zip_extraction(tmp_path: Path):
    # Setup: directories for unzip input and scan output
    unzip_dir = tmp_path / "unzip"
    scan_dir = tmp_path / "scan"
    unzip_dir.mkdir()
    scan_dir.mkdir()

    # Create a zip file in the unzip_dir
    zip_file = unzip_dir / "test.zip"
    create_test_zip(
        zip_file,
        {
            "index.html": "<html><body>Hello</body></html>",
            "about.html": "<html><body>About</body></html>",
        },
    )

    # Run ZipService
    service = ZipService(unzip_dir=unzip_dir, scan_dir=scan_dir)
    service.run()

    # Assert: files are extracted into scan_dir
    extracted_files = list(scan_dir.glob("*.html"))
    extracted_names = {f.name for f in extracted_files}

    assert "index.html" in extracted_names
    assert "about.html" in extracted_names
    assert len(extracted_files) == 2


def test_missing_zip_file(tmp_path: Path):
    unzip_dir = tmp_path / "unzip"
    scan_dir = tmp_path / "scan"
    unzip_dir.mkdir()
    scan_dir.mkdir()

    service = ZipService(unzip_dir=unzip_dir, scan_dir=scan_dir)

    with pytest.raises(FileNotFoundError):
        service.run()


def test_zip_slip_protection(tmp_path: Path):
    """Test that Zip Slip attack paths are properly blocked."""
    unzip_dir = tmp_path / "unzip"
    scan_dir = tmp_path / "scan"
    unzip_dir.mkdir()
    scan_dir.mkdir()

    # Create a malicious zip with path traversal attempts
    zip_file = unzip_dir / "malicious.zip"
    with zipfile.ZipFile(zip_file, "w") as zf:
        # Safe file
        zf.writestr("safe.html", "<html>Safe</html>")
        # Attempt to escape with ../
        zf.writestr("../evil.html", "<html>Evil</html>")
        # Attempt with absolute path
        zf.writestr("/etc/passwd", "hacked")
        # Nested traversal
        zf.writestr("nested/../../bad.html", "<html>Bad</html>")

    # Run ZipService
    service = ZipService(unzip_dir=unzip_dir, scan_dir=scan_dir)
    service.run()

    # Assert: only safe files are extracted
    extracted_files = list(scan_dir.glob("**/*"))
    extracted_names = {f.name for f in extracted_files if f.is_file()}

    # Only safe.html should be extracted
    assert "safe.html" in extracted_names
    assert "evil.html" not in extracted_names
    assert "passwd" not in extracted_names
    assert "bad.html" not in extracted_names

    # Verify malicious files didn't escape the scan_dir
    parent_dir = scan_dir.parent
    assert not (parent_dir / "evil.html").exists()
    assert not (parent_dir / "bad.html").exists()
    assert not Path("/etc/passwd_from_test").exists()
```

</FILE>

---

### Entering Directory: 'tests/services/'

<FILE path="tests/services/test_playwright_axe_service.py">

```python
from pathlib import Path

import pytest

from scanner.services.http_service import HttpService
from scanner.services.playwright_axe_service import PlaywrightAxeService


@pytest.fixture
def http_service():
    """Fixture to create and automatically clean up an HttpService instance."""
    service = HttpService()
    yield service
    service.stop()


def test_scan_url_captures_screenshot_of_violation(
    http_service: HttpService, tmp_path: Path
):
    """
    Verify that when a violation is found, a screenshot is taken,
    and the path to it is added to the violation dictionary.
    """
    # 1. SETUP
    scan_dir = tmp_path / "scan"
    results_dir = tmp_path / "results"
    scan_dir.mkdir()
    results_dir.mkdir()

    html_content = """
    <!DOCTYPE html>
    <html lang="en">
    <head><title>Test Page</title></head>
    <body>
        <main>
            <h1>Missing Alt Text</h1>
            <img src="test.jpg">
        </main>
    </body>
    </html>
    """
    test_html_file = scan_dir / "index.html"
    test_html_file.write_text(html_content)

    http_service.start(directory=scan_dir)
    url_to_scan = f"{http_service.base_url}/index.html"
    report_path = results_dir / "report.json"

    # 2. ACTION
    service = PlaywrightAxeService()
    violations = service.scan_url(url_to_scan, report_path)

    # 3. VERIFICATION
    # Find the specific violation we are interested in.
    image_alt_violation = next((v for v in violations if v["id"] == "image-alt"), None)
    assert image_alt_violation is not None, "The 'image-alt' violation was not found."

    # **THE KEY CHECK**: Assert that a screenshot path has been added
    assert "screenshot_path" in image_alt_violation
    screenshot_path_str = image_alt_violation["screenshot_path"]
    assert screenshot_path_str is not None

    # Assert that the screenshot file actually exists
    screenshot_path = Path(screenshot_path_str)
    assert screenshot_path.exists()
    assert screenshot_path.is_file()

    # Assert the screenshot is saved in the correct directory
    assert results_dir in screenshot_path.parents
```

</FILE>

